{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Hedging of Long-Term Derivatives\n",
    "This notebook presents an example of implementation of the deep hedging algorithm for the risk management of long-term contingent claims as presented in Carbonneau (2020).\n",
    "- The deep hedging algorithm of Buehler et al. (2019) is applied to train neural networks to approximate optimal global hedging strategies.\n",
    "- Results contained in this notebook replicate Table $5$ and $7$ of Carbonneau (2020) for the Black-Scholes dynamics.\n",
    "    - Table 5: benchmarking of quadratic deep hedging (QDH) and semi-quadratic deep hedging (SQDH) with:\n",
    "        - the underlying on a monthly and yearly basis;\n",
    "        - two ATM yearly call and put options;\n",
    "        - six yearly options (3 calls of moneynesses [1.0, 1.1, 1.2] and 3 puts of moneynesses [1.0, 0.9, 0.8]);\n",
    "    - Table 7: computes the average equity exposure across the different hedging instruments;\n",
    "\n",
    "- For a complete description of the algorithm, the reader is referred to section 3 of Carbonneau (2020).  \n",
    "\n",
    "Important note: some parts of the code are inspired by the following implementation of the deep hedging algorithm: \n",
    "    - https://github.com/alexandrecarbonneau/Equal-risk-pricing-with-deep-hedging (from my paper Carbonneau and Godin (2020)).\n",
    "    - https://nbviewer.jupyter.org/urls/people.math.ethz.ch/~jteichma/lecture_ml_web/lecture_3.ipynb \n",
    "    - https://github.com/mgroncki/DataScienceNotebooks/blob/master/DeepHedging/DeepHedging_Part1.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "np.seterr(divide = 'ignore') \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from scipy import stats\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Deep hedging class\n",
    "- This class implements the deep hedging algorithm of Buehler et al. (2019) with a long-short term memory (LSTM) as described in section 3.3 of Carbonneau (2020). \n",
    "- Can be applied for hedging with the underlying (monthly and yearly basis), with two options or with six options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepAgent(object):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    nbs_point_traj       : if [S_0,...,S_T], nbs_point_traj = T+1\n",
    "    batch_size           : Size of the batch\n",
    "    nbs_input            : Nbs of features of the neural networks\n",
    "        - This is prior to adding V_{t} at each-timestep\n",
    "    loss_type            : Loss function applied on the rewards {MSE, SMSE}\n",
    "    nbs_assets           : Number of hedging instruments\n",
    "    hidden_layers        : Number of LSTM cells\n",
    "    nbs_units            : Fixed number of units per layer\n",
    "    lr                   : Learning rate\n",
    "    prepro_risky_assets  : preprocessing of risky asset prices {Log, Nothing}.\n",
    "    hedging_instruments  : {\"Stock\", \"ATM call and put\", \"Six options\"}\n",
    "    name                 : Model name to be saved\n",
    "    freq_obs             : observation frequency of market {Monthly, Yearly}\n",
    "    \"\"\"\n",
    "    def __init__(self, nbs_point_traj, batch_size, nbs_input, loss_type, nbs_assets, \n",
    "                 nbs_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments, freq_obs, \n",
    "                 name='model'):\n",
    "    \n",
    "        tf.reset_default_graph()\n",
    "        self.nbs_point_traj            = nbs_point_traj\n",
    "        self.batch_size                = batch_size\n",
    "        self.loss_type                 = loss_type\n",
    "        self.nbs_assets                = nbs_assets\n",
    "        self.nbs_layers                = nbs_layers\n",
    "        self.nbs_units                 = nbs_units\n",
    "        self.lr                        = lr\n",
    "        self.hedging_instruments       = hedging_instruments\n",
    "        self.freq_obs                  = freq_obs\n",
    "            \n",
    "        # 1) Placeholders - Stock price is normalized\n",
    "        # self.input = [S_t, O_t,...,T-t]\n",
    "        #   - S_t: price of the underlying (always included no mather what)\n",
    "        #   - O_t: prices of options (not always included)\n",
    "        self.input       = tf.placeholder(tf.float32, [nbs_point_traj, batch_size, nbs_input])  \n",
    "        self.disc_tensor = tf.placeholder(tf.float32, [nbs_point_traj, batch_size, 1])   # To discount from 't' to 0.\n",
    "        self.V_0         = tf.placeholder(tf.float32, [batch_size])                      # Initial portoflio value\n",
    "        \n",
    "        # Delta: number of shares held in each instrument\n",
    "        self.strategy    = tf.zeros(shape = [nbs_point_traj-1, batch_size, nbs_assets], dtype=tf.float32)\n",
    "    \n",
    "        # 2) Unormalized risky asset prices\n",
    "        if(self.hedging_instruments == \"Stock\"):\n",
    "            self.unorm_risky_asset_price = self.inverse_processing(self.input[:,:,0], prepro_risky_assets) # all risky assets\n",
    "            self.underlying_unorm_prices = self.unorm_risky_asset_price\n",
    "        else:\n",
    "            self.unorm_risky_asset_price = self.inverse_processing(self.input[:,:,:-1], prepro_risky_assets) \n",
    "            self.underlying_unorm_prices = self.unorm_risky_asset_price[:,:,0]    \n",
    "        \n",
    "        # 3) Unormalized hedging instrument prices\n",
    "        # - self.unorm_hedging_inst_price_b: price process of the hedging instruments at the BEGINNING of each period \n",
    "        # - self.unorm_hedging_inst_price_e: price process of the hedging instruments at the END of each period\n",
    "        if(self.nbs_assets ==1):\n",
    "            if(self.hedging_instruments == \"Stock\"):\n",
    "                self.unorm_hedging_inst_price_b = tf.expand_dims(self.underlying_unorm_prices[0:-1,:], axis=2)\n",
    "                \n",
    "                # For stock: end of price is the same as the beginning of the next period\n",
    "                self.unorm_hedging_inst_price_e = tf.expand_dims(self.underlying_unorm_prices[1:,:], axis=2)\n",
    "\n",
    "        elif(self.nbs_assets > 1):\n",
    "            if(self.hedging_instruments == \"ATM call and put\" or self.hedging_instruments == \"Six options\"):\n",
    "                self.unorm_hedging_inst_price_b = self.unorm_risky_asset_price[0:-1,:,1:]                    \n",
    "                self.unorm_hedging_inst_price_e = self.payoff_liquid_inst_func()\n",
    "\n",
    "        # 4) Discounted difference prices of the hedging instruments ONLY \n",
    "        unorm_discount_hedging_inst_price_b = self.unorm_hedging_inst_price_b*self.disc_tensor[0:-1,:,:]\n",
    "        unorm_discount_hedging_inst_price_e = self.unorm_hedging_inst_price_e*self.disc_tensor[1:,:,:]\n",
    "        inc_disc_ret                        = unorm_discount_hedging_inst_price_e - unorm_discount_hedging_inst_price_b\n",
    "        \n",
    "        # 5) Compute the hedging strategy for each time-step with the LSTM\n",
    "        lstm = tf.contrib.cudnn_rnn.CudnnLSTM(num_layers = self.nbs_layers, num_units  = self.nbs_units)\n",
    "            \n",
    "        # 5.1) Output layer\n",
    "        W_o = tf.get_variable(name='W_o', shape=[self.nbs_assets, self.nbs_units], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b_o = tf.get_variable(name='b_o', shape=[self.nbs_assets], initializer=tf.constant_initializer(0.))\n",
    "\n",
    "        # 5.2) Portfolio value - updated at each time-step\n",
    "        V_t = self.V_0/self.V_0 # [batch_size]\n",
    "            \n",
    "        # 5.3) Compute hedging strategies for all time-steps\n",
    "        for t in range(self.nbs_point_traj-1): \n",
    "            input_t = tf.expand_dims(tf.concat([self.input[t,:,:], tf.expand_dims(V_t, axis = 1)], axis=1), axis = 0)\n",
    "            \n",
    "            if(t==0):\n",
    "                h1, final_state = lstm(input_t)\n",
    "                    \n",
    "                # With an LSTM, the output is of shape [1, BS, 1], no need to expand_dims self.strategy\n",
    "                self.strategy   = tf.tensordot(h1, W_o, axes=[[2], [1]]) + b_o\n",
    "                        \n",
    "            else:\n",
    "                h1, final_state = lstm(input_t, initial_state = final_state)\n",
    "                output          = tf.tensordot(h1, W_o, axes=[[2], [1]]) + b_o\n",
    "\n",
    "                # Store the resulting strategy in self.strategy\n",
    "                self.strategy   = tf.concat([self.strategy, output], axis = 0)\n",
    "     \n",
    "            # Compute the value for the next time-period\n",
    "            factor  = tf.div(self.disc_tensor[t,:,0],self.disc_tensor[t+1,:,0]) # equal exp(rh)   \n",
    "            \n",
    "            # Update hedging portfolio value\n",
    "            V_t_pre = tf.multiply(self.V_0, V_t)\n",
    "            V_t     = tf.divide(V_t_pre*factor + tf.reduce_sum(self.strategy[t,:,:]*(self.unorm_hedging_inst_price_e[t,:,:] - self.unorm_hedging_inst_price_b[t,:,:]*tf.expand_dims(factor, axis=1)), axis=1), self.V_0)\n",
    "            \n",
    "        # 6) Compute the payoff of the GMMB (i.e. lookback put option)\n",
    "        # obs freq == yearly; payoff freq == yearly;\n",
    "        if(self.freq_obs == 'Yearly'):\n",
    "            self.payoff = tf.maximum(tf.reduce_max(self.underlying_unorm_prices[:-1,:],axis=0) - self.underlying_unorm_prices[-1,:],0)        \n",
    "        \n",
    "        # obs freq == monthly; payoff freq == yearly;\n",
    "        elif(self.freq_obs == 'Monthly'):\n",
    "            idx               = np.array(np.arange(0,int(10*12),12))  \n",
    "            stock_yearly      = tf.gather(self.underlying_unorm_prices, idx)\n",
    "            self.payoff       = tf.maximum(tf.reduce_max(stock_yearly,axis=0) - self.underlying_unorm_prices[-1,:],0)                    \n",
    "        \n",
    "        # 7) Compute hedging errors\n",
    "        cumulative_factor  = tf.reciprocal(self.disc_tensor[-1,:,0])  # Project from 0 to T\n",
    "        self.disc_gain     = tf.reduce_sum(inc_disc_ret*self.strategy, axis=[0,2])\n",
    "        self.hedging_err   = self.payoff - cumulative_factor*(self.disc_gain + self.V_0)\n",
    "        \n",
    "        # 8) Compute the cost function (loss function) over the batch of hedging errors \n",
    "        if (self.loss_type == \"MSE\"):\n",
    "            self.loss = tf.reduce_mean(tf.square(self.hedging_err))     \n",
    "        elif (self.loss_type == \"SMSE\"):\n",
    "            self.loss = tf.reduce_mean(tf.square(tf.nn.relu(self.hedging_err)))\n",
    "        \n",
    "        # 9) SGD step with the adam optimizer\n",
    "        optimizer  = tf.train.AdamOptimizer(learning_rate = lr)  \n",
    "        self.train = optimizer.minimize(self.loss)\n",
    "        \n",
    "        # 10) Save the model\n",
    "        self.saver      = tf.train.Saver()\n",
    "        self.model_name = name\n",
    "\n",
    "    # Given a type of preprocessing for all risky assets, output the unormalized risky asset prices\n",
    "    def inverse_processing(self, paths, prepro_risky_assets):\n",
    "        if (prepro_risky_assets == \"Log\"):\n",
    "            paths = tf.exp(paths)\n",
    "        return paths\n",
    "        \n",
    "    def loss_out_optim(self, hedging_err, loss_type):\n",
    "        if (loss_type == \"MSE\"):\n",
    "            loss = np.mean(np.square(hedging_err)) \n",
    "        elif (loss_type == \"SMSE\"):\n",
    "            loss = np.mean(np.square(np.where(hedging_err>0,hedging_err,0)))\n",
    "        return loss\n",
    "\n",
    "    # Compute payoff of options used as hedging instruments\n",
    "    def payoff_liquid_inst_func(self):\n",
    "        if(self.hedging_instruments == \"ATM call and put\"):\n",
    "            # Two ATM call and put options at each time-step\n",
    "            payoff_call = tf.expand_dims(tf.maximum(self.underlying_unorm_prices[1:,:] - self.underlying_unorm_prices[0:-1,:], 0), axis=2)\n",
    "            payoff_put  = tf.expand_dims(tf.maximum(self.underlying_unorm_prices[0:-1,:] - self.underlying_unorm_prices[1:,:],0), axis=2)\n",
    "            \n",
    "            # Compilation\n",
    "            payoff = tf.concat([payoff_call, payoff_put], axis=2) \n",
    "        \n",
    "        elif(self.hedging_instruments == \"Six options\"):\n",
    "            # 3 calls: [1.00, 1.1, 1.2]*S_t for the strike price at each time-step\n",
    "            payoff_call_atm   = tf.expand_dims(tf.maximum(self.underlying_unorm_prices[1:,:] - self.underlying_unorm_prices[0:-1,:], 0), axis=2)\n",
    "            payoff_call_OTM_1 = tf.expand_dims(tf.maximum(self.underlying_unorm_prices[1:,:] - 1.1*self.underlying_unorm_prices[0:-1,:], 0), axis=2)\n",
    "            payoff_call_OTM_2 = tf.expand_dims(tf.maximum(self.underlying_unorm_prices[1:,:] - 1.2*self.underlying_unorm_prices[0:-1,:], 0), axis=2)\n",
    "            \n",
    "            # 3 puts : [1.00, 0.9, 0.8]*S_t for the strike price at each time-step\n",
    "            payoff_put_atm   = tf.expand_dims(tf.maximum(self.underlying_unorm_prices[0:-1,:] - self.underlying_unorm_prices[1:,:],0), axis=2)\n",
    "            payoff_put_OTM_1 = tf.expand_dims(tf.maximum(0.9*self.underlying_unorm_prices[0:-1,:] - self.underlying_unorm_prices[1:,:],0), axis=2)\n",
    "            payoff_put_OTM_2 = tf.expand_dims(tf.maximum(0.8*self.underlying_unorm_prices[0:-1,:] - self.underlying_unorm_prices[1:,:],0), axis=2)\n",
    "            \n",
    "            # Compilation\n",
    "            payoff = tf.concat([payoff_call_atm, payoff_call_OTM_1, payoff_call_OTM_2, payoff_put_atm, payoff_put_OTM_1, payoff_put_OTM_2], axis=2)            \n",
    "        \n",
    "        return(payoff)\n",
    "    \n",
    "    # ---------------------------------------------------------------------------------------# \n",
    "    # Function to call the deep hedging algorithm batch-wise\n",
    "    # - Monitor performance on train and valid set on all epochs;\n",
    "    # - Select parameter values which minimize loss on valid set;\n",
    "    # Function adapted from https://github.com/mgroncki/DataScienceNotebooks/blob/master/DeepHedging/DeepHedging_Part1.ipynb \n",
    "    \"\"\"\n",
    "    Input:\n",
    "     - paths_X     : tensor of features of dimension [n_timesteps+1, n_sims, nbs_features]\n",
    "     - V_0         : vector of initial capital investment of dimension [N_batch]\n",
    "         - could differ for each path, but for num. exp. always fixed\n",
    "     - disc_batch  : tensor of discount factors of dimension [n_timesteps+1, N_batch, 1]\n",
    "         - could fifer for each path, but for num. exp. always fixed\n",
    "     - epochs      : total number of epochs to run\n",
    "    \"\"\" \n",
    "    def train_deephedging(self, paths_train, V_0_batch, disc_batch, paths_valid, sess, epochs):\n",
    "        \n",
    "        sample_size_train = paths_train.shape[1]         \n",
    "        sample_size_valid = paths_valid.shape[1]\n",
    "        batch_size        = self.batch_size    \n",
    "        idx_train         = np.arange(sample_size_train) \n",
    "        idx_valid         = np.arange(sample_size_valid)\n",
    "        start             = dt.datetime.now()            \n",
    "        self.loss_epochs  = 9999999*np.ones((epochs,2))  # store the loss at the end of each epoch for the train|valid \n",
    "        valid_loss_best   = 999999999                    # record best loss on valid set\n",
    "        epoch             = 0 \n",
    "        \n",
    "        # 0) Loop while we haven't reached the max. epoch\n",
    "        while (epoch < epochs):\n",
    "            \n",
    "            # Save the hedging errors for each batch      \n",
    "            hedging_err_train = []\n",
    "            hedging_err_valid = []\n",
    "            np.random.shuffle(idx_train)  # randomize the dataset (useful if training set not already randomized)\n",
    "            \n",
    "            # 1) loop over sample size (train) to do one complete epoch\n",
    "            for i in range(int(sample_size_train/batch_size)):\n",
    "                \n",
    "                # indexes of the paths for the batch\n",
    "                indices = idx_train[i*batch_size : (i+1)*batch_size]\n",
    "\n",
    "                # Training step\n",
    "                _, hedging_err = sess.run([self.train, self.hedging_err], \n",
    "                                               {self.input        : paths_train[:,indices,:],\n",
    "                                                self.V_0          : V_0_batch,\n",
    "                                                self.disc_tensor  : disc_batch})\n",
    "            \n",
    "                # append hedging errors on train set for this batch\n",
    "                hedging_err_train.append(hedging_err)\n",
    "            \n",
    "            # 2) Evaluate performance on the valid set - we don't train\n",
    "            for i in range(int(sample_size_valid/batch_size)):\n",
    "                indices_valid = idx_valid[i*batch_size : (i+1)*batch_size]                \n",
    "                hedging_err_v = sess.run([self.hedging_err], \n",
    "                                            {self.input       : paths_valid[:,indices_valid,:],\n",
    "                                            self.V_0          : V_0_batch,\n",
    "                                            self.disc_tensor  : disc_batch})    \n",
    "                    \n",
    "                hedging_err_valid.append(hedging_err_v)\n",
    "                        \n",
    "            # 3) Store the loss on the train and valid sets after each epoch\n",
    "            self.loss_epochs[epoch,0] = self.loss_out_optim(np.concatenate(hedging_err_train), self.loss_type)\n",
    "            self.loss_epochs[epoch,1] = self.loss_out_optim(np.reshape(np.concatenate(hedging_err_valid, axis=1), sample_size_valid), \n",
    "                                                                self.loss_type)\n",
    "                 \n",
    "            # 4) Test if best epoch so far on valid set; if so, save model parameters.\n",
    "            if(self.loss_epochs[epoch,1] < valid_loss_best):\n",
    "                valid_loss_best = self.loss_epochs[epoch,1]\n",
    "                self.saver.save(sess, r\"/Users/alexa/Github files/Long-term hedging paper example/Models/%s/models.ckpt\" % self.model_name)\n",
    "\n",
    "\n",
    "            # 5) Print statistics during the optimization \n",
    "            if (epoch+1) % 1 == 0:\n",
    "                print('Time elapsed:', dt.datetime.now()-start)\n",
    "                print('Epoch %d, %s, Train: %.3f Valid: %.3f' % (epoch+1, self.loss_type, \n",
    "                                                            self.loss_epochs[epoch,0], self.loss_epochs[epoch,1]))   \n",
    "            epoch+=1  # increment the epoch\n",
    "                \n",
    "        # 6) End of training\n",
    "        print(\"---Finished training results---\")\n",
    "        print('Time elapsed:', dt.datetime.now()-start)    \n",
    "  \n",
    "        # 7) Return the loss per epoch on the train and valid set\n",
    "        return self.loss_epochs\n",
    "    \n",
    "    # function to be called for training neural networks\n",
    "    def training(self, paths_train, V_0_batch, disc_batch, paths_valid, sess, epochs, init=True):\n",
    "        \n",
    "        if init:\n",
    "            # for the training part, you reset all of your parameters\n",
    "            sess.run(tf.global_variables_initializer()) \n",
    "        loss_epoch = self.train_deephedging(paths_train, V_0_batch, disc_batch, paths_valid, sess, epochs)\n",
    "        return loss_epoch\n",
    "     \n",
    "    # function to predict hedging strategies on test-set (no training)\n",
    "    def predict(self, paths, V_0_batch, disc_batch, sess, loss_type):\n",
    "        sample_size = paths.shape[1]\n",
    "        batch_size=self.batch_size    \n",
    "        idx = np.arange(sample_size)  \n",
    "        start = dt.datetime.now()     \n",
    "        \n",
    "        # Save the hedging errors for each batch      \n",
    "        hedging_err_pred = [] \n",
    "        strategy_pred = []\n",
    "            \n",
    "        for i in range(int(sample_size/batch_size)):\n",
    "                \n",
    "            # indexes of the paths of the batch\n",
    "            indices               = idx[i*batch_size : (i+1)*batch_size]         \n",
    "            \n",
    "            # Compute hedging strategies for the batch  \n",
    "            _, strategy = sess.run([self.hedging_err, self.strategy], \n",
    "                                                 {self.input        : paths[:,indices,:],\n",
    "                                                  self.V_0          : V_0_batch,\n",
    "                                                  self.disc_tensor  : disc_batch})  \n",
    "            \n",
    "            # append hedging positions for the batch\n",
    "            strategy_pred.append(strategy)\n",
    "            \n",
    "        return np.concatenate(strategy_pred,axis=1)   \n",
    "         \n",
    "    def restore(self, sess, checkpoint):\n",
    "        self.saver.restore(sess, checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Construction of the train-valid-test sets for all cases (monthly|yearly underlying + two options + six options)\n",
    "- A) Simulation of 500K paths under the Black-Scholes model with the parameters [sigma, mu] = [0.15, 0.10] on a yearly scale. \n",
    "- B) Compute option prices at each time-step for all paths\n",
    "    - two options: ATM calls and puts;\n",
    "    - six options: {S_t, 1.1S_t, 1.2S_t} for calls and {S_t, 0.9S_t, 0.8S_t} for puts\n",
    "- C) Split into train-valid-test sets with 350K, 75K and 75K paths.\n",
    "- D) Normalize with [log(S_n/S_0), log(Z_n/Z_0)] datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BS_d1(S, dt, r, sigma, strike):\n",
    "    return (np.log(S/strike) + (r+sigma**2/2)*dt) / (sigma*np.sqrt(dt))\n",
    "\n",
    "# Style : +1 for call, -1 for put\n",
    "def BlackScholes_price(S, T, r, sigma, strike, style, t=0):\n",
    "    dt = T-t\n",
    "    Phi = stats.norm(loc=0, scale=1).cdf\n",
    "    d1 = BS_d1(S, dt, r, sigma, strike)\n",
    "    d2 = d1 - sigma*np.sqrt(dt)\n",
    "    return style*S*Phi(style*d1) - style*strike*np.exp(-r*dt)*Phi(style*d2)\n",
    "\n",
    "# Style : +1 for call, -1 for put\n",
    "def BS_delta(S, T, r, sigma, strike, style, t=0):\n",
    "    dt = T-t\n",
    "    d1 = BS_d1(S, dt, r, sigma, strike)\n",
    "    Phi = stats.norm(loc=0, scale=1).cdf\n",
    "    delta_call = Phi(d1)\n",
    "    if(style == 1):\n",
    "        result = delta_call\n",
    "    else:\n",
    "        result = delta_call - 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "[sigma, mu]        = [0.15, 0.10] # Yearly parameters\n",
    "S_0                = 100     # Initial stock price\n",
    "T                  = 10      # Time-to-maturity of the GMMB (lookback option)\n",
    "n_sims             = 500000  # Total number of paths to simulate\n",
    "n_timesteps_month  = 12*T    # Monthly time-steps\n",
    "n_timesteps_year   = T       # Yearly time-steps\n",
    "r                  = 0.03    # Annualized continuous risk-free rate\n",
    "\n",
    "# A) Simulation of BSM dataset - monthly step-size\n",
    "seed                 = 43\n",
    "h                    = T / n_timesteps_month  # step-size\n",
    "stdnorm_random_variates = np.random.randn(n_sims, n_timesteps_month)\n",
    "Price_mat_month         = S_0 * np.cumprod(np.exp((mu-sigma**2/2)*h+sigma*np.sqrt(h)*stdnorm_random_variates), axis=1)\n",
    "Price_mat_month         = np.reshape(np.transpose(np.c_[np.ones(n_sims)*S_0, Price_mat_month]), (n_timesteps_month+1, n_sims))\n",
    "\n",
    "# B) Compute the Z_n process for monthly time-steps where Z_0 = S_0, Z_n = max(S_n, Z_n-1) for all time-steps \n",
    "Z_mat_month          = np.zeros((n_timesteps_month+1, n_sims))\n",
    "Z_mat_month[0,:]     = S_0\n",
    "for t in range(n_timesteps_month):\n",
    "    # Need to update ONLY if we are at time t = {11,23,35,...,}\n",
    "    if((t+1)%12==0):\n",
    "        condition          = np.greater_equal(Price_mat_month[t+1,:], Z_mat_month[t,:])\n",
    "        Z_mat_month[t+1,:] = np.where(condition, Price_mat_month[t+1,:], Z_mat_month[t,:])\n",
    "    \n",
    "    else:\n",
    "        Z_mat_month[t+1,:] = Z_mat_month[t,:]\n",
    "    \n",
    "# C) Yearly step-size\n",
    "idx            = np.arange(0,int(T*12) + 12,12)\n",
    "Price_mat_year = np.zeros((n_timesteps_year+1,n_sims)) \n",
    "Price_mat_year = Price_mat_month[idx,:]\n",
    "\n",
    "# D) Yearly Z_n process\n",
    "Z_mat_year       = np.zeros((n_timesteps_year+1, n_sims))\n",
    "Z_mat_year[0,:]  = S_0\n",
    "for t in range(n_timesteps_year):\n",
    "    condition          = np.greater_equal(Price_mat_year[t+1,:], Z_mat_year[t,:])\n",
    "    Z_mat_year[t+1,:]  = np.where(condition, Price_mat_year[t+1,:], Z_mat_year[t,:])\n",
    "    \n",
    "# E) Price ATM yearly call and put options at each time-step for all paths\n",
    "Opt_2_ATM_price          = np.zeros((n_timesteps_year+1, 500000,2))\n",
    "Opt_2_ATM_price[:,:,0] = BlackScholes_price(Price_mat_year, 1, r, sigma, Price_mat_year, 1)  # Call option price\n",
    "Opt_2_ATM_price[:,:,1] = BlackScholes_price(Price_mat_year, 1, r, sigma, Price_mat_year, -1) # Put option price\n",
    "\n",
    "# F) Price six options \n",
    "# - Order: [C(K = S_t), C(K = 1.1S_t), C(K = 1.2S_t), P(K = S_t), P(K = 0.9S_t), P(K=0.8S_t)]\n",
    "Opt_6_price          = np.zeros((n_timesteps_year+1, 500000,6))\n",
    "Opt_6_price[:,:,0] = BlackScholes_price(Price_mat_year, 1, r, sigma, Price_mat_year, 1)      # ATM Call option price\n",
    "Opt_6_price[:,:,1] = BlackScholes_price(Price_mat_year, 1, r, sigma, 1.1*Price_mat_year, 1)  # OTM Call option price\n",
    "Opt_6_price[:,:,2] = BlackScholes_price(Price_mat_year, 1, r, sigma, 1.2*Price_mat_year, 1)  # DOTM Call option price\n",
    "Opt_6_price[:,:,3] = BlackScholes_price(Price_mat_year, 1, r, sigma, Price_mat_year, -1)     # ATM Put option price\n",
    "Opt_6_price[:,:,4] = BlackScholes_price(Price_mat_year, 1, r, sigma, 0.9*Price_mat_year, -1) # OTM Put option price\n",
    "Opt_6_price[:,:,5] = BlackScholes_price(Price_mat_year, 1, r, sigma, 0.8*Price_mat_year, -1) # DOTM Put option price\n",
    "\n",
    "# G) Split into train-valid-test sets\n",
    "# G.1) Monthly underlying: [S_t, Z_t]\n",
    "train_stock_month_input        = np.zeros((n_timesteps_month+1, 350000,2))\n",
    "valid_stock_month_input        = np.zeros((n_timesteps_month+1, 75000,2))\n",
    "test_stock_month_input         = np.zeros((n_timesteps_month+1, 75000,2))\n",
    "train_stock_month_input[:,:,0] = Price_mat_month[:,0:350000]  \n",
    "train_stock_month_input[:,:,1] = Z_mat_month[:,0:350000] \n",
    "valid_stock_month_input[:,:,0] = Price_mat_month[:,350000:425000]\n",
    "valid_stock_month_input[:,:,1] = Z_mat_month[:,350000:425000] \n",
    "test_stock_month_input[:,:,0]  = Price_mat_month[:,425000:]\n",
    "test_stock_month_input[:,:,1]  = Z_mat_month[:,425000:] \n",
    "\n",
    "# G.2) Yearly underlying: [S_t, Z_t]\n",
    "train_stock_year_input        = np.zeros((n_timesteps_year+1, 350000,2))\n",
    "valid_stock_year_input        = np.zeros((n_timesteps_year+1, 75000,2))\n",
    "test_stock_year_input         = np.zeros((n_timesteps_year+1, 75000,2))\n",
    "train_stock_year_input[:,:,0] = Price_mat_year[:,0:350000]  \n",
    "train_stock_year_input[:,:,1] = Z_mat_year[:,0:350000] \n",
    "valid_stock_year_input[:,:,0] = Price_mat_year[:,350000:425000]\n",
    "valid_stock_year_input[:,:,1] = Z_mat_year[:,350000:425000] \n",
    "test_stock_year_input[:,:,0]  = Price_mat_year[:,425000:]\n",
    "test_stock_year_input[:,:,1]  = Z_mat_year[:,425000:]\n",
    "\n",
    "# G.3) Two opts - [S_t, C_t, P_t, Z_t] where S_t = stock price, C_t = call price, P_t = put price\n",
    "train_two_opts_input = np.zeros((n_timesteps_year+1, 350000,4))\n",
    "valid_two_opts_input = np.zeros((n_timesteps_year+1, 75000,4))\n",
    "test_two_opts_input  = np.zeros((n_timesteps_year+1, 75000,4))\n",
    "\n",
    "train_two_opts_input[:,:,0]   = train_stock_year_input[:,:,0]\n",
    "train_two_opts_input[:,:,1:3] = Opt_2_ATM_price[:,0:350000,:]\n",
    "train_two_opts_input[:,:,-1]  = train_stock_year_input[:,:,-1]\n",
    "\n",
    "valid_two_opts_input[:,:,0]   = valid_stock_year_input[:,:,0]\n",
    "valid_two_opts_input[:,:,1:3] = Opt_2_ATM_price[:,350000:425000,:]\n",
    "valid_two_opts_input[:,:,-1]  = valid_stock_year_input[:,:,-1]\n",
    "\n",
    "test_two_opts_input[:,:,0]   = test_stock_year_input[:,:,0]\n",
    "test_two_opts_input[:,:,1:3] = Opt_2_ATM_price[:,425000:,:]\n",
    "test_two_opts_input[:,:,-1]  = test_stock_year_input[:,:,-1]\n",
    "\n",
    "# G.4) Six opts - [S_t, C_t, 1.1C_t, 1.2C_t, P_t, 0.9P_t, 0.8P_t, Z_t]\n",
    "train_six_opts_input = np.zeros((n_timesteps_year+1, 350000,8))\n",
    "valid_six_opts_input = np.zeros((n_timesteps_year+1, 75000,8))\n",
    "test_six_opts_input  = np.zeros((n_timesteps_year+1, 75000,8))\n",
    "\n",
    "train_six_opts_input[:,:,0]   = train_stock_year_input[:,:,0]\n",
    "train_six_opts_input[:,:,1:7] = Opt_6_price[:,0:350000,:]\n",
    "train_six_opts_input[:,:,-1]  = train_stock_year_input[:,:,-1]\n",
    "\n",
    "valid_six_opts_input[:,:,0]   = valid_stock_year_input[:,:,0]\n",
    "valid_six_opts_input[:,:,1:7] = Opt_6_price[:,350000:425000,:]\n",
    "valid_six_opts_input[:,:,-1]  = valid_stock_year_input[:,:,-1]\n",
    "\n",
    "test_six_opts_input[:,:,0]   = test_stock_year_input[:,:,0]\n",
    "test_six_opts_input[:,:,1:7] = Opt_6_price[:,425000:,:]\n",
    "test_six_opts_input[:,:,-1]  = test_stock_year_input[:,:,-1]\n",
    "\n",
    "# Preprocessing of all risky aset prices as {log(S_n/S_0), log(Z_n/S_0)}\n",
    "# - Also store initial risky asset prices (i.e. at time-0) for all cases\n",
    "prepro_risky_assets = \"Log\"\n",
    "if (prepro_risky_assets == \"Log\"):\n",
    "    train_stock_month_input = np.log(train_stock_month_input)\n",
    "    valid_stock_month_input = np.log(valid_stock_month_input)\n",
    "    test_stock_month_input  = np.log(test_stock_month_input)\n",
    "    \n",
    "    train_stock_year_input = np.log(train_stock_year_input)\n",
    "    valid_stock_year_input = np.log(valid_stock_year_input)\n",
    "    test_stock_year_input  = np.log(test_stock_year_input)\n",
    "    \n",
    "    train_two_opts_input = np.log(train_two_opts_input)\n",
    "    valid_two_opts_input = np.log(valid_two_opts_input)\n",
    "    test_two_opts_input  = np.log(test_two_opts_input)\n",
    "    \n",
    "    train_six_opts_input = np.log(train_six_opts_input)\n",
    "    valid_six_opts_input = np.log(valid_six_opts_input)\n",
    "    test_six_opts_input  = np.log(test_six_opts_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Hyperparameters of neural networks as in Section 4.1.2 of the paper\n",
    "- Initial portfolio value under the BSM model: 17.68894582328168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size    = 1000   # batch size\n",
    "epochs        = 150    # number of epochs\n",
    "hidden_layers = 2      # number of hidden layers (output layer not included, for a total of three layers)\n",
    "nbs_units     = 24     # neurons per layer  \n",
    "price         = 17.68894582328168  # Initial portfolio value\n",
    "V_0_train     = np.ones(train_stock_year_input.shape[1])*price  # initial portfolio value\n",
    "V_0_valid     = np.ones(valid_stock_year_input.shape[1])*price\n",
    "V_0_test      = np.ones(test_stock_year_input.shape[1])*price\n",
    "V_0_batch     = np.ones(batch_size)*price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Tensor of discount factors\n",
    "- disc_mat: (n_timesteps+1 x n_sims x 1) tensor of cumulative discount rates (discount from t to 0), i.e. $\\exp(-rh*n)$ \n",
    "    - Will be split into disc_mat_train and disc_mat_test for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly tensors\n",
    "disc_mat_month              = np.zeros((n_timesteps_month+1, 500000, 1))\n",
    "disc_train_month            = np.zeros((n_timesteps_month+1, 350000, 1))\n",
    "disc_valid_month            = np.zeros((n_timesteps_month+1, 75000, 1))\n",
    "disc_test_month             = np.zeros((n_timesteps_month+1, 75000, 1))\n",
    "discount_vect_month         = np.ones(disc_mat_month.shape[0])   \n",
    "h                           = T / n_timesteps_month\n",
    "discount_vect_month[1:]     = np.exp(-r*h)              # [1,exp(-rh), exp(-rh),....,exp(-rh)]\n",
    "discount_vect_month         = np.cumprod(discount_vect_month) # [1,exp(-rh), exp(-r2h),....,exp(-rNh)]\n",
    "disc_mat_month              = np.reshape(np.repeat(discount_vect_month, 500000), (n_timesteps_month+1, 500000,1))\n",
    "disc_train_month            = disc_mat_month[:,0:350000,:]\n",
    "disc_valid_month            = disc_mat_month[:,350000:425000,:]\n",
    "disc_test_month             = disc_mat_month[:,425000::,:]\n",
    "disc_batch_month            = disc_mat_month[:,0:batch_size,:]  # for convenience when only batch-size is needed\n",
    "disc_mat_month              = []\n",
    "\n",
    "# yearly tensors\n",
    "disc_mat_year              = np.zeros((n_timesteps_year+1, 500000, 1))\n",
    "disc_train_year            = np.zeros((n_timesteps_year+1, 350000, 1))\n",
    "disc_valid_year            = np.zeros((n_timesteps_year+1, 75000, 1))\n",
    "disc_test_year             = np.zeros((n_timesteps_year+1, 75000, 1))\n",
    "discount_vect_year         = np.ones(disc_mat_year.shape[0])   \n",
    "h                           = T / n_timesteps_year\n",
    "discount_vect_year[1:]     = np.exp(-r*h)              # [1,exp(-rh), exp(-rh),....,exp(-rh)]\n",
    "discount_vect_year         = np.cumprod(discount_vect_year) # [1,exp(-rh), exp(-r2h),....,exp(-rNh)]\n",
    "disc_mat_year              = np.reshape(np.repeat(discount_vect_year, 500000), (n_timesteps_year+1, 500000,1))\n",
    "disc_train_year            = disc_mat_year[:,0:350000,:]\n",
    "disc_valid_year            = disc_mat_year[:,350000:425000,:]\n",
    "disc_test_year             = disc_mat_year[:,425000::,:]\n",
    "disc_batch_year            = disc_mat_year[:,0:batch_size,:]  # for convenience when only batch-size is needed\n",
    "disc_mat_year              = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Function to compute hedging statistics as in Table 3 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------#\n",
    "#---------------         Functions to compute the hedging statistics         ---------------------#\n",
    "#-------------------------------------------------------------------------------------------------#\n",
    "\"\"\"\n",
    "deltas              : delta strategy path-wise\n",
    "paths               : risky asset prices path-wise \n",
    "disc_paths          : discount factors path-wise\n",
    "hedging_instruments : {\"Stock\", \"ATM call and put\", \"Six options\"}\n",
    "prepro_risky_assets : which pre-processing for risky assets {\"Log\", \"Nothing\"}\n",
    "V_0                 : initial price investment, can be a vector of the dimension for each paths\n",
    "freq_obs            : {'Monthly', 'Yearly'} \n",
    "\"\"\"\n",
    "def hedging_stats(deltas, paths, disc_paths, V_0, loss_type, model_name, prepro_risky_assets, hedging_instruments, \n",
    "                  freq_obs):\n",
    "    # 1) Number of hedging instruments\n",
    "    nbs_assets = deltas.shape[2]\n",
    "\n",
    "    # 2) Store prices of the underlying unormalized\n",
    "    if(hedging_instruments == \"Stock\"):\n",
    "        unorm_risky_asset_price = inverse_processing(paths[:,:,0], prepro_risky_assets) # all risky assets\n",
    "        underlying_unorm_prices = unorm_risky_asset_price\n",
    "    else:\n",
    "        # all risky assets except Z_{n} process\n",
    "        unorm_risky_asset_price = inverse_processing(paths[:,:,0:-1], prepro_risky_assets) \n",
    "        underlying_unorm_prices = unorm_risky_asset_price[:,:,0]   \n",
    "\n",
    "    # 3) Store the unormalized hedging instrument price beginning and ending values (see paper section 2)\n",
    "    if(hedging_instruments == \"Stock\"):\n",
    "        unorm_hedging_inst_price_b = np.expand_dims(underlying_unorm_prices[0:-1,:], axis=2)\n",
    "        unorm_hedging_inst_price_e = np.expand_dims(underlying_unorm_prices[1:,:], axis=2)\n",
    "\n",
    "    elif(hedging_instruments == \"ATM call and put\" or hedging_instruments == \"Six options\"):\n",
    "        unorm_hedging_inst_price_b = unorm_risky_asset_price[0:-1,:,1:]\n",
    "        unorm_hedging_inst_price_e = payoff_liquid_inst_func(hedging_instruments, underlying_unorm_prices, nbs_assets)\n",
    "\n",
    "    # 4) Store the unormalized hedging instrument prices discounted at time \"0\"    \n",
    "    unorm_discount_hedging_inst_price_b = unorm_hedging_inst_price_b*disc_paths[0:-1,:,:]\n",
    "    unorm_discount_hedging_inst_price_e = unorm_hedging_inst_price_e*disc_paths[1:,:,:]\n",
    "    inc_disc_ret                        = unorm_discount_hedging_inst_price_e - unorm_discount_hedging_inst_price_b\n",
    "        \n",
    "    # 5) Compute the payoff of the lookback option to hedge\n",
    "    if(freq_obs == \"Yearly\"):\n",
    "        liability_payoff = np.maximum(np.amax(underlying_unorm_prices[:-1,:],axis=0) - underlying_unorm_prices[-1,:],0)\n",
    "    elif(freq_obs == \"Monthly\"):\n",
    "        idx              = np.array(np.arange(0,int(10*12),12))\n",
    "        liability_payoff = np.maximum(np.amax(underlying_unorm_prices[idx,:],axis=0) - underlying_unorm_prices[-1,:],0)\n",
    "    else:\n",
    "        print(\"There's an error somehwere!\")\n",
    "    \n",
    "    # 6) Compute the hedging error\n",
    "    # There's an ordering in the double np.sum:\n",
    "    # - np.sum(deltas*inc_disc_ret, axis = 0).shape = [nbs of paths x nbs_assets], you sum over time-steps\n",
    "    # - np.sum(np.sum(deltas*inc_disc_ret, axis = 0), axis = 1), you sum afterwards over the assets\n",
    "    disc_hedging_gain = np.sum(np.sum(deltas*inc_disc_ret, axis = 0), axis = 1) # as of T\n",
    "    cumulative_factor = np.reciprocal(disc_paths[-1,:,0]) \n",
    "    hedging_err       = liability_payoff - cumulative_factor*(disc_hedging_gain + V_0)\n",
    "    \n",
    "    # 7) Compute hedging statistics as presented in Table 3 of paper\n",
    "    mean_hedging_err = np.mean(hedging_err)\n",
    "    CVaR_95          = np.mean(np.sort(hedging_err)[int(0.95*hedging_err.shape[0]):])\n",
    "    CVaR_99          = np.mean(np.sort(hedging_err)[int(0.99*hedging_err.shape[0]):])\n",
    "    VaR_95           = np.sort(hedging_err)[int(0.95*hedging_err.shape[0])]\n",
    "    VaR_99           = np.sort(hedging_err)[int(0.99*hedging_err.shape[0])]\n",
    "    MSE              = np.mean(np.square(hedging_err))\n",
    "    semi_MSE         = np.mean(np.square(np.where(hedging_err>0,hedging_err,0)))\n",
    "    skew_            = skew(hedging_err)\n",
    "    \n",
    "    # 8) Present hedging statistics\n",
    "    if (loss_type == \"MSE\"):\n",
    "        loss = MSE\n",
    "    elif (loss_type == \"SMSE\"):\n",
    "        loss = semi_MSE\n",
    "    print('Model was trained with the loss function: %s' %(loss_type))\n",
    "    print('Initial investment', V_0[0])\n",
    "    print('Mean Hedging error:', mean_hedging_err)\n",
    "    print('CVaR_95: %.4f, CVaR_99: %.4f' % (CVaR_95, CVaR_99))\n",
    "    print('VaR_95: %.4f, VaR_99: %.4f' % (VaR_95, VaR_99))\n",
    "    print('MSE: %.4f, RMSE: %.4f' % (MSE, np.sqrt(MSE)))\n",
    "    print('Semi-MSE: %.4f, Semi-RMSE: %.4f' %(semi_MSE, np.sqrt(semi_MSE)))\n",
    "    print('Skew: %.4f' %(skew_))\n",
    "    \n",
    "def payoff_liquid_inst_func(hedging_instruments, underlying_unorm_prices, nbs_assets): \n",
    "    if (hedging_instruments == \"ATM call and put\"):\n",
    "        payoff_call = np.expand_dims(np.maximum(underlying_unorm_prices[1:,:] - underlying_unorm_prices[0:-1,:], 0), axis=2)\n",
    "        payoff_put = np.expand_dims(np.maximum(underlying_unorm_prices[0:-1,:] - underlying_unorm_prices[1:,:], 0), axis=2)\n",
    "\n",
    "        # Compilation\n",
    "        payoff = np.concatenate([payoff_call, payoff_put], axis=2)\n",
    "        \n",
    "    elif(hedging_instruments == \"Six options\"):\n",
    "        # 3 calls: [1.00, 1.1, 1.2]*S_t for the strike price at each time-step\n",
    "        payoff_call_atm   = np.expand_dims(np.maximum(underlying_unorm_prices[1:,:] - underlying_unorm_prices[0:-1,:], 0), axis=2)\n",
    "        payoff_call_OTM_1 = np.expand_dims(np.maximum(underlying_unorm_prices[1:,:] - 1.1*underlying_unorm_prices[0:-1,:], 0), axis=2)\n",
    "        payoff_call_OTM_2 = np.expand_dims(np.maximum(underlying_unorm_prices[1:,:] - 1.2*underlying_unorm_prices[0:-1,:], 0), axis=2)\n",
    "\n",
    "        # 3 puts : [1.00, 0.9, 0.8]*S_t for the strike price at each time-step\n",
    "        payoff_put_atm   = np.expand_dims(np.maximum(underlying_unorm_prices[0:-1,:] - underlying_unorm_prices[1:,:],0), axis=2)\n",
    "        payoff_put_OTM_1 = np.expand_dims(np.maximum(0.9*underlying_unorm_prices[0:-1,:] - underlying_unorm_prices[1:,:],0), axis=2)\n",
    "        payoff_put_OTM_2 = np.expand_dims(np.maximum(0.8*underlying_unorm_prices[0:-1,:] - underlying_unorm_prices[1:,:],0), axis=2)\n",
    "\n",
    "        # Compilation\n",
    "        payoff = np.concatenate([payoff_call_atm, payoff_call_OTM_1, payoff_call_OTM_2, payoff_put_atm, payoff_put_OTM_1, payoff_put_OTM_2], axis=2)\n",
    "\n",
    "    return(payoff)\n",
    "\n",
    "def inverse_processing(paths, prepro_risky_assets):\n",
    "    if (prepro_risky_assets == \"Log\"):\n",
    "        paths = np.exp(paths)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Training of LSTM - Monthly underlying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: learning rate=0.0100, LSTM cells=2, neurons=24\n",
      "---Training for quadratic deep hedging start---\n",
      "Time elapsed: 0:00:56.231877\n",
      "Epoch 1, MSE, Train: 369.616 Valid: 223.829\n",
      "Time elapsed: 0:01:42.018264\n",
      "Epoch 2, MSE, Train: 109.583 Valid: 66.962\n",
      "Time elapsed: 0:02:27.805683\n",
      "Epoch 3, MSE, Train: 59.468 Valid: 58.846\n",
      "Time elapsed: 0:03:13.751107\n",
      "Epoch 4, MSE, Train: 51.970 Valid: 44.899\n",
      "Time elapsed: 0:03:57.979132\n",
      "Epoch 5, MSE, Train: 63.148 Valid: 46.237\n",
      "Time elapsed: 0:04:43.510471\n",
      "Epoch 6, MSE, Train: 47.304 Valid: 40.548\n",
      "Time elapsed: 0:05:28.275626\n",
      "Epoch 7, MSE, Train: 44.994 Valid: 63.252\n",
      "Time elapsed: 0:06:14.155027\n",
      "Epoch 8, MSE, Train: 44.892 Valid: 39.960\n",
      "Time elapsed: 0:06:59.558368\n",
      "Epoch 9, MSE, Train: 44.228 Valid: 38.339\n",
      "Time elapsed: 0:07:45.200723\n",
      "Epoch 10, MSE, Train: 41.342 Valid: 37.697\n",
      "Time elapsed: 0:08:29.202706\n",
      "Epoch 11, MSE, Train: 39.515 Valid: 47.230\n",
      "Time elapsed: 0:09:14.366952\n",
      "Epoch 12, MSE, Train: 38.321 Valid: 35.272\n",
      "Time elapsed: 0:10:00.211353\n",
      "Epoch 13, MSE, Train: 38.540 Valid: 34.550\n",
      "Time elapsed: 0:10:44.491399\n",
      "Epoch 14, MSE, Train: 33.841 Valid: 40.408\n",
      "Time elapsed: 0:11:28.893473\n",
      "Epoch 15, MSE, Train: 32.915 Valid: 37.295\n",
      "Time elapsed: 0:12:14.322779\n",
      "Epoch 16, MSE, Train: 33.225 Valid: 31.666\n",
      "Time elapsed: 0:12:59.774091\n",
      "Epoch 17, MSE, Train: 34.136 Valid: 28.621\n",
      "Time elapsed: 0:13:44.198162\n",
      "Epoch 18, MSE, Train: 29.246 Valid: 29.185\n",
      "Time elapsed: 0:14:28.824294\n",
      "Epoch 19, MSE, Train: 31.427 Valid: 28.657\n",
      "Time elapsed: 0:15:14.273605\n",
      "Epoch 20, MSE, Train: 31.714 Valid: 27.674\n",
      "Time elapsed: 0:15:58.618666\n",
      "Epoch 21, MSE, Train: 31.280 Valid: 28.749\n",
      "Time elapsed: 0:16:42.905705\n",
      "Epoch 22, MSE, Train: 51.296 Valid: 75.011\n",
      "Time elapsed: 0:17:26.662641\n",
      "Epoch 23, MSE, Train: 47.184 Valid: 40.194\n",
      "Time elapsed: 0:18:10.795654\n",
      "Epoch 24, MSE, Train: 37.763 Valid: 39.038\n",
      "Time elapsed: 0:18:54.931667\n",
      "Epoch 25, MSE, Train: 37.244 Valid: 34.824\n",
      "Time elapsed: 0:19:39.022670\n",
      "Epoch 26, MSE, Train: 35.919 Valid: 34.023\n",
      "Time elapsed: 0:20:23.083666\n",
      "Epoch 27, MSE, Train: 35.641 Valid: 33.581\n",
      "Time elapsed: 0:21:07.077647\n",
      "Epoch 28, MSE, Train: 35.205 Valid: 32.590\n",
      "Time elapsed: 0:21:51.437710\n",
      "Epoch 29, MSE, Train: 31.012 Valid: 30.023\n",
      "Time elapsed: 0:22:35.981817\n",
      "Epoch 30, MSE, Train: 30.519 Valid: 28.697\n",
      "Time elapsed: 0:23:19.929779\n",
      "Epoch 31, MSE, Train: 29.536 Valid: 30.348\n",
      "Time elapsed: 0:24:03.426656\n",
      "Epoch 32, MSE, Train: 28.915 Valid: 31.875\n",
      "Time elapsed: 0:24:47.268602\n",
      "Epoch 33, MSE, Train: 30.588 Valid: 28.308\n",
      "Time elapsed: 0:25:30.749467\n",
      "Epoch 34, MSE, Train: 33.510 Valid: 31.365\n",
      "Time elapsed: 0:26:15.051518\n",
      "Epoch 35, MSE, Train: 46.432 Valid: 53.833\n",
      "Time elapsed: 0:26:59.710650\n",
      "Epoch 36, MSE, Train: 41.712 Valid: 36.423\n",
      "Time elapsed: 0:27:43.855665\n",
      "Epoch 37, MSE, Train: 36.304 Valid: 33.521\n",
      "Time elapsed: 0:28:28.123709\n",
      "Epoch 38, MSE, Train: 35.974 Valid: 40.839\n",
      "Time elapsed: 0:29:12.822829\n",
      "Epoch 39, MSE, Train: 33.858 Valid: 76.784\n",
      "Time elapsed: 0:29:57.220902\n",
      "Epoch 40, MSE, Train: 34.517 Valid: 29.603\n",
      "Time elapsed: 0:30:41.387923\n",
      "Epoch 41, MSE, Train: 32.433 Valid: 32.635\n",
      "Time elapsed: 0:31:25.823004\n",
      "Epoch 42, MSE, Train: 32.684 Valid: 37.431\n",
      "Time elapsed: 0:32:09.906005\n",
      "Epoch 43, MSE, Train: 29.554 Valid: 29.049\n",
      "Time elapsed: 0:32:55.092256\n",
      "Epoch 44, MSE, Train: 28.682 Valid: 27.165\n",
      "Time elapsed: 0:33:39.006219\n",
      "Epoch 45, MSE, Train: 30.955 Valid: 27.291\n",
      "Time elapsed: 0:34:23.347279\n",
      "Epoch 46, MSE, Train: 27.184 Valid: 28.665\n",
      "Time elapsed: 0:35:09.482745\n",
      "Epoch 47, MSE, Train: 27.514 Valid: 25.829\n",
      "Time elapsed: 0:35:53.779795\n",
      "Epoch 48, MSE, Train: 31.662 Valid: 34.001\n",
      "Time elapsed: 0:36:37.843793\n",
      "Epoch 49, MSE, Train: 28.511 Valid: 26.647\n",
      "Time elapsed: 0:37:21.871781\n",
      "Epoch 50, MSE, Train: 30.832 Valid: 26.554\n",
      "Time elapsed: 0:38:05.908763\n",
      "Epoch 51, MSE, Train: 27.506 Valid: 26.636\n",
      "Time elapsed: 0:38:50.446877\n",
      "Epoch 52, MSE, Train: 27.060 Valid: 26.127\n",
      "Time elapsed: 0:39:34.721921\n",
      "Epoch 53, MSE, Train: 27.211 Valid: 26.752\n",
      "Time elapsed: 0:40:19.878166\n",
      "Epoch 54, MSE, Train: 26.641 Valid: 25.556\n",
      "Time elapsed: 0:41:03.851142\n",
      "Epoch 55, MSE, Train: 27.053 Valid: 31.492\n",
      "Time elapsed: 0:41:48.381245\n",
      "Epoch 56, MSE, Train: 26.343 Valid: 25.918\n",
      "Time elapsed: 0:42:32.551266\n",
      "Epoch 57, MSE, Train: 26.714 Valid: 27.176\n",
      "Time elapsed: 0:43:17.033358\n",
      "Epoch 58, MSE, Train: 26.577 Valid: 26.727\n",
      "Time elapsed: 0:44:01.187375\n",
      "Epoch 59, MSE, Train: 26.277 Valid: 26.718\n",
      "Time elapsed: 0:44:45.640461\n",
      "Epoch 60, MSE, Train: 26.550 Valid: 29.656\n",
      "Time elapsed: 0:45:30.046526\n",
      "Epoch 61, MSE, Train: 25.994 Valid: 31.092\n",
      "Time elapsed: 0:46:14.160543\n",
      "Epoch 62, MSE, Train: 26.255 Valid: 29.474\n",
      "Time elapsed: 0:46:58.269550\n",
      "Epoch 63, MSE, Train: 26.228 Valid: 28.966\n",
      "Time elapsed: 0:47:42.157507\n",
      "Epoch 64, MSE, Train: 25.874 Valid: 25.893\n",
      "Time elapsed: 0:48:27.919889\n",
      "Epoch 65, MSE, Train: 25.884 Valid: 25.390\n",
      "Time elapsed: 0:49:11.811848\n",
      "Epoch 66, MSE, Train: 26.387 Valid: 29.521\n",
      "Time elapsed: 0:49:56.222923\n",
      "Epoch 67, MSE, Train: 176.718 Valid: 160.220\n",
      "Time elapsed: 0:50:40.138886\n",
      "Epoch 68, MSE, Train: 72.578 Valid: 60.947\n",
      "Time elapsed: 0:51:24.569967\n",
      "Epoch 69, MSE, Train: 57.168 Valid: 53.348\n",
      "Time elapsed: 0:52:08.647967\n",
      "Epoch 70, MSE, Train: 51.205 Valid: 46.745\n",
      "Time elapsed: 0:52:52.748972\n",
      "Epoch 71, MSE, Train: 47.169 Valid: 51.552\n",
      "Time elapsed: 0:53:37.518129\n",
      "Epoch 72, MSE, Train: 45.731 Valid: 44.320\n",
      "Time elapsed: 0:54:22.004222\n",
      "Epoch 73, MSE, Train: 45.460 Valid: 43.273\n",
      "Time elapsed: 0:55:06.489314\n",
      "Epoch 74, MSE, Train: 42.474 Valid: 42.322\n",
      "Time elapsed: 0:55:50.497299\n",
      "Epoch 75, MSE, Train: 42.129 Valid: 51.362\n",
      "Time elapsed: 0:56:34.300236\n",
      "Epoch 76, MSE, Train: 41.776 Valid: 37.020\n",
      "Time elapsed: 0:57:18.923360\n",
      "Epoch 77, MSE, Train: 39.551 Valid: 44.433\n",
      "Time elapsed: 0:58:03.521478\n",
      "Epoch 78, MSE, Train: 39.319 Valid: 40.038\n",
      "Time elapsed: 0:58:47.848535\n",
      "Epoch 79, MSE, Train: 38.913 Valid: 41.009\n",
      "Time elapsed: 0:59:32.153586\n",
      "Epoch 80, MSE, Train: 38.261 Valid: 39.486\n",
      "Time elapsed: 1:00:16.220584\n",
      "Epoch 81, MSE, Train: 37.362 Valid: 34.559\n",
      "Time elapsed: 1:01:01.003744\n",
      "Epoch 82, MSE, Train: 35.966 Valid: 37.702\n",
      "Time elapsed: 1:01:45.190769\n",
      "Epoch 83, MSE, Train: 36.693 Valid: 35.013\n",
      "Time elapsed: 1:02:29.505823\n",
      "Epoch 84, MSE, Train: 36.600 Valid: 35.276\n",
      "Time elapsed: 1:03:12.953680\n",
      "Epoch 85, MSE, Train: 35.188 Valid: 33.631\n",
      "Time elapsed: 1:03:56.947661\n",
      "Epoch 86, MSE, Train: 35.223 Valid: 35.233\n",
      "Time elapsed: 1:04:40.952645\n",
      "Epoch 87, MSE, Train: 35.399 Valid: 32.998\n",
      "Time elapsed: 1:05:25.251695\n",
      "Epoch 88, MSE, Train: 34.507 Valid: 31.677\n",
      "Time elapsed: 1:06:09.024626\n",
      "Epoch 89, MSE, Train: 33.601 Valid: 40.841\n",
      "Time elapsed: 1:06:53.493715\n",
      "Epoch 90, MSE, Train: 33.761 Valid: 31.952\n",
      "Time elapsed: 1:07:37.929788\n",
      "Epoch 91, MSE, Train: 33.970 Valid: 33.120\n",
      "Time elapsed: 1:08:21.764741\n",
      "Epoch 92, MSE, Train: 33.549 Valid: 31.207\n",
      "Time elapsed: 1:09:05.818735\n",
      "Epoch 93, MSE, Train: 32.219 Valid: 33.018\n",
      "Time elapsed: 1:09:49.739701\n",
      "Epoch 94, MSE, Train: 32.923 Valid: 32.379\n",
      "Time elapsed: 1:10:34.277797\n",
      "Epoch 95, MSE, Train: 32.584 Valid: 34.970\n",
      "Time elapsed: 1:11:18.831913\n",
      "Epoch 96, MSE, Train: 33.162 Valid: 34.178\n",
      "Time elapsed: 1:12:03.353014\n",
      "Epoch 97, MSE, Train: 31.965 Valid: 38.799\n",
      "Time elapsed: 1:12:47.637060\n",
      "Epoch 98, MSE, Train: 31.869 Valid: 33.506\n",
      "Time elapsed: 1:13:32.281190\n",
      "Epoch 99, MSE, Train: 32.106 Valid: 38.306\n",
      "Time elapsed: 1:14:16.478216\n",
      "Epoch 100, MSE, Train: 32.608 Valid: 30.615\n",
      "Time elapsed: 1:15:00.653238\n",
      "Epoch 101, MSE, Train: 31.424 Valid: 29.506\n",
      "Time elapsed: 1:15:44.932284\n",
      "Epoch 102, MSE, Train: 32.578 Valid: 32.710\n",
      "Time elapsed: 1:16:29.356363\n",
      "Epoch 103, MSE, Train: 31.400 Valid: 33.058\n",
      "Time elapsed: 1:17:14.045501\n",
      "Epoch 104, MSE, Train: 32.005 Valid: 29.225\n",
      "Time elapsed: 1:17:58.259532\n",
      "Epoch 105, MSE, Train: 30.512 Valid: 30.440\n",
      "Time elapsed: 1:18:42.753627\n",
      "Epoch 106, MSE, Train: 30.160 Valid: 30.907\n",
      "Time elapsed: 1:19:27.255722\n",
      "Epoch 107, MSE, Train: 30.854 Valid: 29.693\n",
      "Time elapsed: 1:20:11.513764\n",
      "Epoch 108, MSE, Train: 30.894 Valid: 30.527\n",
      "Time elapsed: 1:20:58.174901\n",
      "Epoch 109, MSE, Train: 29.905 Valid: 30.949\n",
      "Time elapsed: 1:21:45.262826\n",
      "Epoch 110, MSE, Train: 29.978 Valid: 29.528\n",
      "Time elapsed: 1:22:31.807613\n",
      "Epoch 111, MSE, Train: 30.664 Valid: 32.651\n",
      "Time elapsed: 1:23:18.783687\n",
      "Epoch 112, MSE, Train: 29.707 Valid: 28.093\n",
      "Time elapsed: 1:24:05.136109\n",
      "Epoch 113, MSE, Train: 30.821 Valid: 27.587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 1:24:52.288209\n",
      "Epoch 114, MSE, Train: 29.922 Valid: 29.260\n",
      "Time elapsed: 1:25:38.468253\n",
      "Epoch 115, MSE, Train: 29.934 Valid: 27.865\n",
      "Time elapsed: 1:26:24.605389\n",
      "Epoch 116, MSE, Train: 28.977 Valid: 28.217\n",
      "Time elapsed: 1:27:11.589194\n",
      "Epoch 117, MSE, Train: 29.492 Valid: 30.378\n",
      "Time elapsed: 1:27:57.160691\n",
      "Epoch 118, MSE, Train: 29.449 Valid: 31.142\n",
      "Time elapsed: 1:28:42.656303\n",
      "Epoch 119, MSE, Train: 29.211 Valid: 30.368\n",
      "Time elapsed: 1:29:28.732899\n",
      "Epoch 120, MSE, Train: 28.836 Valid: 29.580\n",
      "Time elapsed: 1:30:14.926094\n",
      "Epoch 121, MSE, Train: 30.676 Valid: 28.069\n",
      "Time elapsed: 1:30:59.807294\n",
      "Epoch 122, MSE, Train: 29.578 Valid: 31.631\n",
      "Time elapsed: 1:31:44.935813\n",
      "Epoch 123, MSE, Train: 28.611 Valid: 32.399\n",
      "Time elapsed: 1:32:30.337113\n",
      "Epoch 124, MSE, Train: 29.101 Valid: 27.269\n",
      "Time elapsed: 1:33:16.008481\n",
      "Epoch 125, MSE, Train: 28.597 Valid: 31.461\n",
      "Time elapsed: 1:34:01.780873\n",
      "Epoch 126, MSE, Train: 28.740 Valid: 27.789\n",
      "Time elapsed: 1:34:47.016136\n",
      "Epoch 127, MSE, Train: 29.070 Valid: 31.106\n",
      "Time elapsed: 1:35:32.699500\n",
      "Epoch 128, MSE, Train: 28.874 Valid: 27.170\n",
      "Time elapsed: 1:36:18.272832\n",
      "Epoch 129, MSE, Train: 28.550 Valid: 27.212\n",
      "Time elapsed: 1:37:03.482088\n",
      "Epoch 130, MSE, Train: 28.609 Valid: 29.021\n",
      "Time elapsed: 1:37:48.648335\n",
      "Epoch 131, MSE, Train: 28.812 Valid: 29.797\n",
      "Time elapsed: 1:38:34.375709\n",
      "Epoch 132, MSE, Train: 27.999 Valid: 27.798\n",
      "Time elapsed: 1:39:19.877041\n",
      "Epoch 133, MSE, Train: 28.949 Valid: 28.694\n",
      "Time elapsed: 1:40:06.042515\n",
      "Epoch 134, MSE, Train: 27.441 Valid: 29.041\n",
      "Time elapsed: 1:40:51.679868\n",
      "Epoch 135, MSE, Train: 28.276 Valid: 26.669\n",
      "Time elapsed: 1:41:37.139174\n",
      "Epoch 136, MSE, Train: 27.804 Valid: 26.764\n",
      "Time elapsed: 1:42:21.888334\n",
      "Epoch 137, MSE, Train: 28.356 Valid: 28.137\n",
      "Time elapsed: 1:43:07.060589\n",
      "Epoch 138, MSE, Train: 28.002 Valid: 28.521\n",
      "Time elapsed: 1:43:52.753956\n",
      "Epoch 139, MSE, Train: 28.387 Valid: 28.020\n",
      "Time elapsed: 1:44:38.261280\n",
      "Epoch 140, MSE, Train: 27.545 Valid: 27.352\n",
      "Time elapsed: 1:45:23.813612\n",
      "Epoch 141, MSE, Train: 27.771 Valid: 30.325\n",
      "Time elapsed: 1:46:09.126901\n",
      "Epoch 142, MSE, Train: 27.513 Valid: 30.616\n",
      "Time elapsed: 1:46:54.976296\n",
      "Epoch 143, MSE, Train: 27.918 Valid: 26.083\n",
      "Time elapsed: 1:47:40.714680\n",
      "Epoch 144, MSE, Train: 27.156 Valid: 32.991\n",
      "Time elapsed: 1:48:26.116972\n",
      "Epoch 145, MSE, Train: 27.968 Valid: 30.082\n",
      "Time elapsed: 1:49:11.582295\n",
      "Epoch 146, MSE, Train: 27.569 Valid: 28.204\n",
      "Time elapsed: 1:49:56.916572\n",
      "Epoch 147, MSE, Train: 27.317 Valid: 28.634\n",
      "Time elapsed: 1:50:43.502514\n",
      "Epoch 148, MSE, Train: 27.494 Valid: 27.562\n",
      "Time elapsed: 1:51:29.945082\n",
      "Epoch 149, MSE, Train: 27.487 Valid: 28.087\n",
      "Time elapsed: 1:52:15.419399\n",
      "Epoch 150, MSE, Train: 27.094 Valid: 27.522\n",
      "---Finished training results---\n",
      "Time elapsed: 1:52:15.420399\n",
      "---Training for quadratic deep hedging end---\n",
      "INFO:tensorflow:Restoring parameters from /Users/alexa/Github files/Long-term hedging paper example/Models/Monthly_underlying_MSE/models.ckpt\n",
      "-------------------------------\n",
      "Results on the TRAIN SET:\n",
      "Model was trained with the loss function: MSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -0.7556610576087647\n",
      "CVaR_95: 11.7049, CVaR_99: 19.4475\n",
      "VaR_95: 7.1838, VaR_99: 14.2992\n",
      "MSE: 24.9761, RMSE: 4.9976\n",
      "Semi-MSE: 10.9504, Semi-RMSE: 3.3091\n",
      "Skew: 0.6092\n",
      "-------------------------------\n",
      "Results on the VALID SET:\n",
      "Model was trained with the loss function: MSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -0.7643902284657806\n",
      "CVaR_95: 11.8286, CVaR_99: 19.8784\n",
      "VaR_95: 7.2670, VaR_99: 14.4904\n",
      "MSE: 25.3901, RMSE: 5.0389\n",
      "Semi-MSE: 11.2149, Semi-RMSE: 3.3489\n",
      "Skew: 0.6659\n",
      "-------------------------------\n",
      "Results on the TEST SET:\n",
      "Model was trained with the loss function: MSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -0.7744511028962544\n",
      "CVaR_95: 11.7820, CVaR_99: 19.8624\n",
      "VaR_95: 7.1767, VaR_99: 14.4519\n",
      "MSE: 25.1345, RMSE: 5.0134\n",
      "Semi-MSE: 11.0030, Semi-RMSE: 3.3171\n",
      "Skew: 0.5496\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "END OF QUADRATIC DEEP HEDGING\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "Hyperparameters: learning rate=0.0017, LSTM cells=2, neurons=24\n",
      "---Training for semi-quadratic deep hedging start---\n",
      "Time elapsed: 0:00:57.040941\n",
      "Epoch 1, SMSE, Train: 50.407 Valid: 36.244\n",
      "Time elapsed: 0:01:44.098617\n",
      "Epoch 2, SMSE, Train: 36.891 Valid: 22.154\n",
      "Time elapsed: 0:02:31.421361\n",
      "Epoch 3, SMSE, Train: 16.213 Valid: 11.758\n",
      "Time elapsed: 0:03:17.170741\n",
      "Epoch 4, SMSE, Train: 12.803 Valid: 18.212\n",
      "Time elapsed: 0:04:04.210404\n",
      "Epoch 5, SMSE, Train: 9.216 Valid: 7.860\n",
      "Time elapsed: 0:04:50.557919\n",
      "Epoch 6, SMSE, Train: 7.186 Valid: 9.070\n",
      "Time elapsed: 0:05:37.376571\n",
      "Epoch 7, SMSE, Train: 5.241 Valid: 4.382\n",
      "Time elapsed: 0:06:23.107925\n",
      "Epoch 8, SMSE, Train: 16.192 Valid: 6.528\n",
      "Time elapsed: 0:07:08.293176\n",
      "Epoch 9, SMSE, Train: 5.048 Valid: 4.837\n",
      "Time elapsed: 0:07:54.896749\n",
      "Epoch 10, SMSE, Train: 5.387 Valid: 3.563\n",
      "Time elapsed: 0:08:42.362604\n",
      "Epoch 11, SMSE, Train: 4.522 Valid: 3.506\n",
      "Time elapsed: 0:09:29.228237\n",
      "Epoch 12, SMSE, Train: 3.741 Valid: 3.179\n",
      "Time elapsed: 0:10:14.517512\n",
      "Epoch 13, SMSE, Train: 3.258 Valid: 4.979\n",
      "Time elapsed: 0:11:01.191101\n",
      "Epoch 14, SMSE, Train: 3.335 Valid: 3.117\n",
      "Time elapsed: 0:11:47.827681\n",
      "Epoch 15, SMSE, Train: 3.822 Valid: 2.730\n",
      "Time elapsed: 0:12:34.551281\n",
      "Epoch 16, SMSE, Train: 2.776 Valid: 2.568\n",
      "Time elapsed: 0:13:19.913581\n",
      "Epoch 17, SMSE, Train: 3.066 Valid: 2.894\n",
      "Time elapsed: 0:14:07.386861\n",
      "Epoch 18, SMSE, Train: 2.623 Valid: 2.497\n",
      "Time elapsed: 0:14:54.301535\n",
      "Epoch 19, SMSE, Train: 6.659 Valid: 3.226\n",
      "Time elapsed: 0:15:39.520794\n",
      "Epoch 20, SMSE, Train: 4.125 Valid: 2.551\n",
      "Time elapsed: 0:16:24.649025\n",
      "Epoch 21, SMSE, Train: 2.591 Valid: 2.498\n",
      "Time elapsed: 0:17:11.217635\n",
      "Epoch 22, SMSE, Train: 2.558 Valid: 2.410\n",
      "Time elapsed: 0:17:56.537917\n",
      "Epoch 23, SMSE, Train: 8.410 Valid: 9.935\n",
      "Time elapsed: 0:18:41.837185\n",
      "Epoch 24, SMSE, Train: 3.846 Valid: 2.926\n",
      "Time elapsed: 0:19:26.064228\n",
      "Epoch 25, SMSE, Train: 19.234 Valid: 13.679\n",
      "Time elapsed: 0:20:10.431293\n",
      "Epoch 26, SMSE, Train: 5.905 Valid: 4.189\n",
      "Time elapsed: 0:20:54.713340\n",
      "Epoch 27, SMSE, Train: 3.851 Valid: 3.206\n",
      "Time elapsed: 0:21:38.755332\n",
      "Epoch 28, SMSE, Train: 3.589 Valid: 7.346\n",
      "Time elapsed: 0:22:23.017386\n",
      "Epoch 29, SMSE, Train: 3.176 Valid: 2.845\n",
      "Time elapsed: 0:23:07.183398\n",
      "Epoch 30, SMSE, Train: 2.990 Valid: 2.964\n",
      "Time elapsed: 0:23:51.129377\n",
      "Epoch 31, SMSE, Train: 2.977 Valid: 2.663\n",
      "Time elapsed: 0:24:35.161366\n",
      "Epoch 32, SMSE, Train: 3.678 Valid: 2.799\n",
      "Time elapsed: 0:25:20.891785\n",
      "Epoch 33, SMSE, Train: 2.857 Valid: 2.686\n",
      "Time elapsed: 0:26:05.772976\n",
      "Epoch 34, SMSE, Train: 2.680 Valid: 2.523\n",
      "Time elapsed: 0:26:51.446231\n",
      "Epoch 35, SMSE, Train: 2.580 Valid: 2.575\n",
      "Time elapsed: 0:27:37.448838\n",
      "Epoch 36, SMSE, Train: 2.692 Valid: 2.596\n",
      "Time elapsed: 0:28:24.208441\n",
      "Epoch 37, SMSE, Train: 2.505 Valid: 2.374\n",
      "Time elapsed: 0:29:09.077627\n",
      "Epoch 38, SMSE, Train: 5.342 Valid: 11.400\n",
      "Time elapsed: 0:29:53.309655\n",
      "Epoch 39, SMSE, Train: 3.970 Valid: 2.810\n",
      "Time elapsed: 0:30:37.586708\n",
      "Epoch 40, SMSE, Train: 3.321 Valid: 3.089\n",
      "Time elapsed: 0:31:21.686704\n",
      "Epoch 41, SMSE, Train: 2.894 Valid: 2.527\n",
      "Time elapsed: 0:32:05.716702\n",
      "Epoch 42, SMSE, Train: 6.687 Valid: 3.490\n",
      "Time elapsed: 0:32:50.437840\n",
      "Epoch 43, SMSE, Train: 3.096 Valid: 2.942\n",
      "Time elapsed: 0:33:34.710892\n",
      "Epoch 44, SMSE, Train: 2.718 Valid: 2.817\n",
      "Time elapsed: 0:34:19.238504\n",
      "Epoch 45, SMSE, Train: 2.625 Valid: 2.780\n",
      "Time elapsed: 0:35:03.498538\n",
      "Epoch 46, SMSE, Train: 2.536 Valid: 2.600\n",
      "Time elapsed: 0:35:48.135665\n",
      "Epoch 47, SMSE, Train: 2.825 Valid: 2.570\n",
      "Time elapsed: 0:36:32.571745\n",
      "Epoch 48, SMSE, Train: 2.587 Valid: 2.689\n",
      "Time elapsed: 0:37:17.413927\n",
      "Epoch 49, SMSE, Train: 2.551 Valid: 2.609\n",
      "Time elapsed: 0:38:02.869239\n",
      "Epoch 50, SMSE, Train: 2.556 Valid: 2.372\n",
      "Time elapsed: 0:38:47.110277\n",
      "Epoch 51, SMSE, Train: 2.400 Valid: 2.888\n",
      "Time elapsed: 0:39:31.524353\n",
      "Epoch 52, SMSE, Train: 4.423 Valid: 2.642\n",
      "Time elapsed: 0:40:16.023442\n",
      "Epoch 53, SMSE, Train: 2.331 Valid: 2.464\n",
      "Time elapsed: 0:41:01.383732\n",
      "Epoch 54, SMSE, Train: 2.347 Valid: 2.307\n",
      "Time elapsed: 0:41:46.134884\n",
      "Epoch 55, SMSE, Train: 2.603 Valid: 2.615\n",
      "Time elapsed: 0:42:30.681990\n",
      "Epoch 56, SMSE, Train: 2.394 Valid: 2.343\n",
      "Time elapsed: 0:43:16.295339\n",
      "Epoch 57, SMSE, Train: 2.539 Valid: 2.412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:44:02.075725\n",
      "Epoch 58, SMSE, Train: 2.442 Valid: 2.485\n",
      "Time elapsed: 0:44:47.531047\n",
      "Epoch 59, SMSE, Train: 2.898 Valid: 2.475\n",
      "Time elapsed: 0:45:32.489531\n",
      "Epoch 60, SMSE, Train: 2.304 Valid: 2.588\n",
      "Time elapsed: 0:46:16.373479\n",
      "Epoch 61, SMSE, Train: 2.257 Valid: 2.535\n",
      "Time elapsed: 0:47:01.739780\n",
      "Epoch 62, SMSE, Train: 2.424 Valid: 2.289\n",
      "Time elapsed: 0:47:45.878794\n",
      "Epoch 63, SMSE, Train: 2.368 Valid: 2.382\n",
      "Time elapsed: 0:48:30.364887\n",
      "Epoch 64, SMSE, Train: 2.214 Valid: 2.568\n",
      "Time elapsed: 0:49:15.646152\n",
      "Epoch 65, SMSE, Train: 2.343 Valid: 2.207\n",
      "Time elapsed: 0:49:59.764170\n",
      "Epoch 66, SMSE, Train: 12.958 Valid: 4.284\n",
      "Time elapsed: 0:50:44.044216\n",
      "Epoch 67, SMSE, Train: 3.282 Valid: 2.863\n",
      "Time elapsed: 0:51:28.079205\n",
      "Epoch 68, SMSE, Train: 2.813 Valid: 3.176\n",
      "Time elapsed: 0:52:12.054182\n",
      "Epoch 69, SMSE, Train: 2.711 Valid: 2.551\n",
      "Time elapsed: 0:52:56.224196\n",
      "Epoch 70, SMSE, Train: 2.507 Valid: 2.669\n",
      "Time elapsed: 0:53:40.700294\n",
      "Epoch 71, SMSE, Train: 2.504 Valid: 2.523\n",
      "Time elapsed: 0:54:24.902313\n",
      "Epoch 72, SMSE, Train: 2.403 Valid: 2.534\n",
      "Time elapsed: 0:55:09.674471\n",
      "Epoch 73, SMSE, Train: 2.596 Valid: 2.372\n",
      "Time elapsed: 0:55:54.032536\n",
      "Epoch 74, SMSE, Train: 2.320 Valid: 2.663\n",
      "Time elapsed: 0:56:39.104768\n",
      "Epoch 75, SMSE, Train: 3.344 Valid: 2.275\n",
      "Time elapsed: 0:57:23.756900\n",
      "Epoch 76, SMSE, Train: 2.254 Valid: 2.429\n",
      "Time elapsed: 0:58:07.634854\n",
      "Epoch 77, SMSE, Train: 2.245 Valid: 2.445\n",
      "Time elapsed: 0:58:51.403784\n",
      "Epoch 78, SMSE, Train: 2.251 Valid: 2.439\n",
      "Time elapsed: 0:59:34.991673\n",
      "Epoch 79, SMSE, Train: 2.527 Valid: 2.741\n",
      "Time elapsed: 1:00:18.746600\n",
      "Epoch 80, SMSE, Train: 2.263 Valid: 2.454\n",
      "Time elapsed: 1:01:02.733579\n",
      "Epoch 81, SMSE, Train: 2.217 Valid: 2.312\n",
      "Time elapsed: 1:01:46.764569\n",
      "Epoch 82, SMSE, Train: 2.243 Valid: 2.355\n",
      "Time elapsed: 1:02:30.623519\n",
      "Epoch 83, SMSE, Train: 3.550 Valid: 2.503\n",
      "Time elapsed: 1:03:14.751531\n",
      "Epoch 84, SMSE, Train: 2.223 Valid: 2.321\n",
      "Time elapsed: 1:03:58.605472\n",
      "Epoch 85, SMSE, Train: 2.182 Valid: 2.391\n",
      "Time elapsed: 1:04:42.783503\n",
      "Epoch 86, SMSE, Train: 2.251 Valid: 3.135\n",
      "Time elapsed: 1:05:27.907740\n",
      "Epoch 87, SMSE, Train: 2.354 Valid: 2.195\n",
      "Time elapsed: 1:06:11.647664\n",
      "Epoch 88, SMSE, Train: 3.179 Valid: 2.240\n",
      "Time elapsed: 1:06:55.593634\n",
      "Epoch 89, SMSE, Train: 2.107 Valid: 2.527\n",
      "Time elapsed: 1:07:39.433580\n",
      "Epoch 90, SMSE, Train: 2.147 Valid: 2.428\n",
      "Time elapsed: 1:08:24.503805\n",
      "Epoch 91, SMSE, Train: 2.159 Valid: 2.194\n",
      "Time elapsed: 1:09:08.737841\n",
      "Epoch 92, SMSE, Train: 2.372 Valid: 2.440\n",
      "Time elapsed: 1:09:52.826844\n",
      "Epoch 93, SMSE, Train: 2.124 Valid: 2.375\n",
      "Time elapsed: 1:10:36.544762\n",
      "Epoch 94, SMSE, Train: 2.357 Valid: 2.407\n",
      "Time elapsed: 1:11:20.243675\n",
      "Epoch 95, SMSE, Train: 2.218 Valid: 2.365\n",
      "Time elapsed: 1:12:04.144635\n",
      "Epoch 96, SMSE, Train: 3.639 Valid: 2.373\n",
      "Time elapsed: 1:12:49.423908\n",
      "Epoch 97, SMSE, Train: 2.100 Valid: 2.102\n",
      "Time elapsed: 1:13:33.195839\n",
      "Epoch 98, SMSE, Train: 2.069 Valid: 3.140\n",
      "Time elapsed: 1:14:17.027783\n",
      "Epoch 99, SMSE, Train: 2.130 Valid: 2.443\n",
      "Time elapsed: 1:15:00.936745\n",
      "Epoch 100, SMSE, Train: 2.494 Valid: 2.743\n",
      "Time elapsed: 1:15:45.079760\n",
      "Epoch 101, SMSE, Train: 2.220 Valid: 2.224\n",
      "Time elapsed: 1:16:29.162760\n",
      "Epoch 102, SMSE, Train: 2.197 Valid: 2.161\n",
      "Time elapsed: 1:17:13.538829\n",
      "Epoch 103, SMSE, Train: 2.441 Valid: 3.961\n",
      "Time elapsed: 1:17:57.748859\n",
      "Epoch 104, SMSE, Train: 2.397 Valid: 2.539\n",
      "Time elapsed: 1:18:41.310743\n",
      "Epoch 105, SMSE, Train: 2.396 Valid: 2.486\n",
      "Time elapsed: 1:19:25.085673\n",
      "Epoch 106, SMSE, Train: 7.787 Valid: 3.342\n",
      "Time elapsed: 1:20:08.876608\n",
      "Epoch 107, SMSE, Train: 2.828 Valid: 2.620\n",
      "Time elapsed: 1:20:52.894595\n",
      "Epoch 108, SMSE, Train: 2.800 Valid: 2.733\n",
      "Time elapsed: 1:21:36.885575\n",
      "Epoch 109, SMSE, Train: 2.396 Valid: 2.466\n",
      "Time elapsed: 1:22:20.768531\n",
      "Epoch 110, SMSE, Train: 2.405 Valid: 2.591\n",
      "Time elapsed: 1:23:04.848531\n",
      "Epoch 111, SMSE, Train: 2.434 Valid: 2.466\n",
      "Time elapsed: 1:23:48.579453\n",
      "Epoch 112, SMSE, Train: 14.746 Valid: 17.889\n",
      "Time elapsed: 1:24:32.582436\n",
      "Epoch 113, SMSE, Train: 7.647 Valid: 3.453\n",
      "Time elapsed: 1:25:16.301355\n",
      "Epoch 114, SMSE, Train: 4.538 Valid: 3.244\n",
      "Time elapsed: 1:25:59.936255\n",
      "Epoch 115, SMSE, Train: 2.896 Valid: 2.650\n",
      "Time elapsed: 1:26:43.965243\n",
      "Epoch 116, SMSE, Train: 2.623 Valid: 2.566\n",
      "Time elapsed: 1:27:27.855201\n",
      "Epoch 117, SMSE, Train: 2.444 Valid: 2.843\n",
      "Time elapsed: 1:28:11.687145\n",
      "Epoch 118, SMSE, Train: 2.565 Valid: 2.695\n",
      "Time elapsed: 1:28:55.551097\n",
      "Epoch 119, SMSE, Train: 2.461 Valid: 2.379\n",
      "Time elapsed: 1:29:39.035962\n",
      "Epoch 120, SMSE, Train: 2.467 Valid: 2.735\n",
      "Time elapsed: 1:30:23.177977\n",
      "Epoch 121, SMSE, Train: 2.532 Valid: 2.381\n",
      "Time elapsed: 1:31:07.321992\n",
      "Epoch 122, SMSE, Train: 2.362 Valid: 2.459\n",
      "Time elapsed: 1:31:51.644047\n",
      "Epoch 123, SMSE, Train: 2.448 Valid: 2.531\n",
      "Time elapsed: 1:32:35.992100\n",
      "Epoch 124, SMSE, Train: 2.551 Valid: 2.448\n",
      "Time elapsed: 1:33:20.515202\n",
      "Epoch 125, SMSE, Train: 2.408 Valid: 2.330\n",
      "Time elapsed: 1:34:04.679229\n",
      "Epoch 126, SMSE, Train: 2.358 Valid: 2.394\n",
      "Time elapsed: 1:34:48.808234\n",
      "Epoch 127, SMSE, Train: 2.197 Valid: 2.454\n",
      "Time elapsed: 1:35:32.727205\n",
      "Epoch 128, SMSE, Train: 4.829 Valid: 3.046\n",
      "Time elapsed: 1:36:16.784201\n",
      "Epoch 129, SMSE, Train: 2.253 Valid: 2.284\n",
      "Time elapsed: 1:37:00.980227\n",
      "Epoch 130, SMSE, Train: 2.180 Valid: 2.246\n",
      "Time elapsed: 1:37:44.801169\n",
      "Epoch 131, SMSE, Train: 2.167 Valid: 2.351\n",
      "Time elapsed: 1:38:28.871168\n",
      "Epoch 132, SMSE, Train: 2.183 Valid: 2.156\n",
      "Time elapsed: 1:39:12.686108\n",
      "Epoch 133, SMSE, Train: 2.250 Valid: 2.410\n",
      "Time elapsed: 1:39:56.902140\n",
      "Epoch 134, SMSE, Train: 2.198 Valid: 2.269\n",
      "Time elapsed: 1:40:40.929119\n",
      "Epoch 135, SMSE, Train: 2.223 Valid: 2.330\n",
      "Time elapsed: 1:41:24.810083\n",
      "Epoch 136, SMSE, Train: 2.298 Valid: 2.245\n",
      "Time elapsed: 1:42:09.390190\n",
      "Epoch 137, SMSE, Train: 2.305 Valid: 2.177\n",
      "Time elapsed: 1:42:54.059332\n",
      "Epoch 138, SMSE, Train: 3.855 Valid: 3.075\n",
      "Time elapsed: 1:43:38.099315\n",
      "Epoch 139, SMSE, Train: 2.377 Valid: 3.213\n",
      "Time elapsed: 1:44:21.658206\n",
      "Epoch 140, SMSE, Train: 2.221 Valid: 2.231\n",
      "Time elapsed: 1:45:05.915247\n",
      "Epoch 141, SMSE, Train: 2.106 Valid: 2.213\n",
      "Time elapsed: 1:45:50.230292\n",
      "Epoch 142, SMSE, Train: 2.247 Valid: 2.162\n",
      "Time elapsed: 1:46:34.457334\n",
      "Epoch 143, SMSE, Train: 2.065 Valid: 2.329\n",
      "Time elapsed: 1:47:18.488323\n",
      "Epoch 144, SMSE, Train: 3.607 Valid: 2.338\n",
      "Time elapsed: 1:48:03.518540\n",
      "Epoch 145, SMSE, Train: 2.074 Valid: 2.020\n",
      "Time elapsed: 1:48:47.879604\n",
      "Epoch 146, SMSE, Train: 2.168 Valid: 2.332\n",
      "Time elapsed: 1:49:32.409707\n",
      "Epoch 147, SMSE, Train: 2.051 Valid: 2.343\n",
      "Time elapsed: 1:50:16.912803\n",
      "Epoch 148, SMSE, Train: 2.204 Valid: 2.500\n",
      "Time elapsed: 1:51:00.922788\n",
      "Epoch 149, SMSE, Train: 2.174 Valid: 2.108\n",
      "Time elapsed: 1:51:45.257846\n",
      "Epoch 150, SMSE, Train: 2.112 Valid: 2.644\n",
      "---Finished training results---\n",
      "Time elapsed: 1:51:45.257846\n",
      "---Training for semi-quadratic deep hedging end---\n",
      "INFO:tensorflow:Restoring parameters from /Users/alexa/Github files/Long-term hedging paper example/Models/Monthly_underlying_SMSE/models.ckpt\n",
      "-------------------------------\n",
      "Results on the TRAIN SET:\n",
      "Model was trained with the loss function: SMSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -10.90600481714999\n",
      "CVaR_95: 5.1429, CVaR_99: 9.5999\n",
      "VaR_95: 2.5675, VaR_99: 6.4695\n",
      "MSE: 263.5057, RMSE: 16.2329\n",
      "Semi-MSE: 1.9481, Semi-RMSE: 1.3958\n",
      "Skew: -1.7888\n",
      "-------------------------------\n",
      "Results on the VALID SET:\n",
      "Model was trained with the loss function: SMSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -10.893741237006475\n",
      "CVaR_95: 5.1921, CVaR_99: 9.7982\n",
      "VaR_95: 2.5574, VaR_99: 6.4769\n",
      "MSE: 261.7470, RMSE: 16.1786\n",
      "Semi-MSE: 2.0201, Semi-RMSE: 1.4213\n",
      "Skew: -1.7566\n",
      "-------------------------------\n",
      "Results on the TEST SET:\n",
      "Model was trained with the loss function: SMSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -10.870671404217642\n",
      "CVaR_95: 5.2901, CVaR_99: 10.0169\n",
      "VaR_95: 2.6276, VaR_99: 6.5531\n",
      "MSE: 262.6346, RMSE: 16.2060\n",
      "Semi-MSE: 2.2564, Semi-RMSE: 1.5021\n",
      "Skew: -1.7750\n",
      " ----------------------- \n",
      "Average exposure QDH: -0.0896\n",
      " ----------------------- \n",
      "Average exposure SQDH: -0.0046\n"
     ]
    }
   ],
   "source": [
    "# Normalization \n",
    "nbs_assets                = 1\n",
    "hedging_instruments       = \"Stock\"\n",
    "freq_obs                  = \"Monthly\"\n",
    "\n",
    "# A) Part 1: MSE\n",
    "loss_type  = 'MSE'\n",
    "model_name = 'Monthly_underlying_MSE'\n",
    "lr         = 0.01   # learning rate of the Adam optimizer\n",
    "print(\"Hyperparameters: learning rate=%.4f, LSTM cells=%d, neurons=%d\" %(lr, hidden_layers, nbs_units))\n",
    "LSTM_underlying = DeepAgent(train_stock_month_input.shape[0], batch_size, train_stock_month_input.shape[2], \n",
    "        loss_type, nbs_assets, hidden_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments,\n",
    "        freq_obs, name = model_name)\n",
    "    \n",
    "# Start training \n",
    "start = dt.datetime.now()\n",
    "print('---Training for quadratic deep hedging start---')\n",
    "with tf.Session() as sess:           \n",
    "    loss_epoch = LSTM_underlying.training(train_stock_month_input, V_0_batch, disc_batch_month, valid_stock_month_input, \n",
    "                                          sess, epochs)\n",
    "    print('---Training for quadratic deep hedging end---')\n",
    "    \n",
    "# Compute measured risk exposure on train, valid and test set with the optimized LSTM\n",
    "model_predict = DeepAgent(test_stock_month_input.shape[0], batch_size, test_stock_month_input.shape[2], loss_type, \n",
    "        nbs_assets, hidden_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments, freq_obs, \n",
    "        name = model_name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Load the saved model\n",
    "    model_predict.restore(sess, r\"/Users/alexa/Github files/Long-term hedging paper example/Models/%s/models.ckpt\" % model_name)\n",
    "\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the TRAIN SET:\")\n",
    "    # Compute hedging strategies on the training set\n",
    "    deltas = model_predict.predict(train_stock_month_input, V_0_batch, disc_batch_month, sess, loss_type)    \n",
    "    hedging_stats(deltas, train_stock_month_input, disc_train_month, V_0_train, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the VALID SET:\")\n",
    "    # Compute hedging strategies on the valid set\n",
    "    deltas = model_predict.predict(valid_stock_month_input, V_0_batch, disc_batch_month, sess, loss_type)\n",
    "    hedging_stats(deltas, valid_stock_month_input, disc_valid_month, V_0_valid, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the TEST SET:\")\n",
    "    # Compute hedging strategies on the test set\n",
    "    deltas_MSE = model_predict.predict(test_stock_month_input, V_0_batch, disc_batch_month, sess, loss_type)\n",
    "    hedging_stats(deltas_MSE, test_stock_month_input, disc_test_month, V_0_test, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"END OF QUADRATIC DEEP HEDGING\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "# B) Part 2: SMSE\n",
    "loss_type  = 'SMSE'\n",
    "model_name = 'Monthly_underlying_SMSE'\n",
    "lr         = 0.01/6   # learning rate of the Adam optimizer\n",
    "print(\"Hyperparameters: learning rate=%.4f, LSTM cells=%d, neurons=%d\" %(lr, hidden_layers, nbs_units))\n",
    "LSTM_underlying = DeepAgent(train_stock_month_input.shape[0], batch_size, train_stock_month_input.shape[2], \n",
    "        loss_type, nbs_assets, hidden_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments, \n",
    "        freq_obs, name = model_name)\n",
    "    \n",
    "# Start training \n",
    "start = dt.datetime.now()\n",
    "print('---Training for semi-quadratic deep hedging start---')\n",
    "with tf.Session() as sess:           \n",
    "    loss_epoch = LSTM_underlying.training(train_stock_month_input, V_0_batch, disc_batch_month, valid_stock_month_input, \n",
    "                                          sess, epochs)\n",
    "    print('---Training for semi-quadratic deep hedging end---')\n",
    "    \n",
    "# Compute measured risk exposure on train, valid and test set with the optimized LSTM\n",
    "model_predict = DeepAgent(test_stock_month_input.shape[0], batch_size, test_stock_month_input.shape[2], loss_type, \n",
    "        nbs_assets, hidden_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments, freq_obs, \n",
    "        name = model_name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Load the saved model\n",
    "    model_predict.restore(sess, r\"/Users/alexa/Github files/Long-term hedging paper example/Models/%s/models.ckpt\" % model_name)\n",
    "\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the TRAIN SET:\")\n",
    "    # Compute hedging strategies on the training set\n",
    "    deltas = model_predict.predict(train_stock_month_input, V_0_batch, disc_batch_month, sess, loss_type)    \n",
    "    hedging_stats(deltas, train_stock_month_input, disc_train_month, V_0_train, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the VALID SET:\")\n",
    "    # Compute hedging strategies on the valid set\n",
    "    deltas = model_predict.predict(valid_stock_month_input, V_0_batch, disc_batch_month, sess, loss_type)\n",
    "    hedging_stats(deltas, valid_stock_month_input, disc_valid_month, V_0_valid, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the TEST SET:\")\n",
    "    # Compute hedging strategies on the test set\n",
    "    deltas_SMSE = model_predict.predict(test_stock_month_input, V_0_batch, disc_batch_month, sess, loss_type)\n",
    "    hedging_stats(deltas_SMSE, test_stock_month_input, disc_test_month, V_0_test, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "    \n",
    "# Compute average equity risk exposure\n",
    "stock_price_unorm = np.exp(test_stock_month_input[:,:,0])\n",
    "portfolio_exposure_QDH  = deltas_MSE\n",
    "portfolio_exposure_SQDH = deltas_SMSE\n",
    "print(\" ----------------------- \")\n",
    "print(\"Average exposure QDH: %.4f\" %(np.mean(portfolio_exposure_QDH)))\n",
    "print(\" ----------------------- \")\n",
    "print(\"Average exposure SQDH: %.4f\" %(np.mean(portfolio_exposure_SQDH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Training of LSTM - Yearly underlying\n",
    "This computes the hedging statistics as presented in Table 3 of the paper for under the penalties MSE and SMSE with the underlying on a yearly basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: learning rate=0.0100, LSTM cells=2, neurons=24\n",
      "---Training for quadratic deep hedging start---\n",
      "Time elapsed: 0:00:05.032142\n",
      "Epoch 1, MSE, Train: 319.718 Valid: 250.473\n",
      "Time elapsed: 0:00:09.282114\n",
      "Epoch 2, MSE, Train: 246.148 Valid: 248.483\n",
      "Time elapsed: 0:00:13.505073\n",
      "Epoch 3, MSE, Train: 235.294 Valid: 233.642\n",
      "Time elapsed: 0:00:17.746035\n",
      "Epoch 4, MSE, Train: 229.767 Valid: 227.711\n",
      "Time elapsed: 0:00:21.826962\n",
      "Epoch 5, MSE, Train: 226.734 Valid: 231.273\n",
      "Time elapsed: 0:00:26.071947\n",
      "Epoch 6, MSE, Train: 229.078 Valid: 227.491\n",
      "Time elapsed: 0:00:30.319911\n",
      "Epoch 7, MSE, Train: 226.813 Valid: 226.563\n",
      "Time elapsed: 0:00:34.568875\n",
      "Epoch 8, MSE, Train: 226.701 Valid: 226.118\n",
      "Time elapsed: 0:00:38.805836\n",
      "Epoch 9, MSE, Train: 224.563 Valid: 224.736\n",
      "Time elapsed: 0:00:42.895773\n",
      "Epoch 10, MSE, Train: 223.871 Valid: 225.845\n",
      "Time elapsed: 0:00:46.997704\n",
      "Epoch 11, MSE, Train: 223.308 Valid: 228.116\n",
      "Time elapsed: 0:00:51.122640\n",
      "Epoch 12, MSE, Train: 223.038 Valid: 229.258\n",
      "Time elapsed: 0:00:55.207566\n",
      "Epoch 13, MSE, Train: 224.663 Valid: 226.369\n",
      "Time elapsed: 0:00:59.289483\n",
      "Epoch 14, MSE, Train: 223.197 Valid: 226.845\n",
      "Time elapsed: 0:01:03.376420\n",
      "Epoch 15, MSE, Train: 223.845 Valid: 231.440\n",
      "Time elapsed: 0:01:07.467348\n",
      "Epoch 16, MSE, Train: 222.079 Valid: 225.789\n",
      "Time elapsed: 0:01:11.701368\n",
      "Epoch 17, MSE, Train: 221.728 Valid: 223.191\n",
      "Time elapsed: 0:01:15.955366\n",
      "Epoch 18, MSE, Train: 221.026 Valid: 222.686\n",
      "Time elapsed: 0:01:20.054296\n",
      "Epoch 19, MSE, Train: 222.131 Valid: 223.756\n",
      "Time elapsed: 0:01:24.154226\n",
      "Epoch 20, MSE, Train: 222.340 Valid: 227.818\n",
      "Time elapsed: 0:01:28.233151\n",
      "Epoch 21, MSE, Train: 222.020 Valid: 230.645\n",
      "Time elapsed: 0:01:32.337073\n",
      "Epoch 22, MSE, Train: 222.541 Valid: 224.746\n",
      "Time elapsed: 0:01:36.430011\n",
      "Epoch 23, MSE, Train: 220.876 Valid: 224.776\n",
      "Time elapsed: 0:01:40.673973\n",
      "Epoch 24, MSE, Train: 219.829 Valid: 222.174\n",
      "Time elapsed: 0:01:44.744897\n",
      "Epoch 25, MSE, Train: 220.557 Valid: 224.345\n",
      "Time elapsed: 0:01:48.838817\n",
      "Epoch 26, MSE, Train: 219.324 Valid: 223.064\n",
      "Time elapsed: 0:01:52.919752\n",
      "Epoch 27, MSE, Train: 218.120 Valid: 224.054\n",
      "Time elapsed: 0:01:57.017682\n",
      "Epoch 28, MSE, Train: 217.986 Valid: 227.863\n",
      "Time elapsed: 0:02:01.102609\n",
      "Epoch 29, MSE, Train: 220.448 Valid: 225.185\n",
      "Time elapsed: 0:02:05.329590\n",
      "Epoch 30, MSE, Train: 217.523 Valid: 221.668\n",
      "Time elapsed: 0:02:09.412526\n",
      "Epoch 31, MSE, Train: 219.801 Valid: 223.141\n",
      "Time elapsed: 0:02:13.632474\n",
      "Epoch 32, MSE, Train: 217.034 Valid: 221.142\n",
      "Time elapsed: 0:02:17.704399\n",
      "Epoch 33, MSE, Train: 219.132 Valid: 223.344\n",
      "Time elapsed: 0:02:21.936358\n",
      "Epoch 34, MSE, Train: 217.790 Valid: 220.943\n",
      "Time elapsed: 0:02:26.021294\n",
      "Epoch 35, MSE, Train: 217.445 Valid: 227.994\n",
      "Time elapsed: 0:02:30.100219\n",
      "Epoch 36, MSE, Train: 217.155 Valid: 223.807\n",
      "Time elapsed: 0:02:34.315166\n",
      "Epoch 37, MSE, Train: 217.166 Valid: 219.313\n",
      "Time elapsed: 0:02:38.402093\n",
      "Epoch 38, MSE, Train: 218.713 Valid: 220.785\n",
      "Time elapsed: 0:02:42.493031\n",
      "Epoch 39, MSE, Train: 217.218 Valid: 219.500\n",
      "Time elapsed: 0:02:46.562954\n",
      "Epoch 40, MSE, Train: 216.940 Valid: 221.160\n",
      "Time elapsed: 0:02:50.642879\n",
      "Epoch 41, MSE, Train: 216.638 Valid: 223.773\n",
      "Time elapsed: 0:02:54.709802\n",
      "Epoch 42, MSE, Train: 216.323 Valid: 220.677\n",
      "Time elapsed: 0:02:58.786719\n",
      "Epoch 43, MSE, Train: 216.233 Valid: 222.439\n",
      "Time elapsed: 0:03:02.870654\n",
      "Epoch 44, MSE, Train: 215.995 Valid: 219.477\n",
      "Time elapsed: 0:03:06.949579\n",
      "Epoch 45, MSE, Train: 219.456 Valid: 225.356\n",
      "Time elapsed: 0:03:11.028505\n",
      "Epoch 46, MSE, Train: 215.982 Valid: 219.913\n",
      "Time elapsed: 0:03:15.107430\n",
      "Epoch 47, MSE, Train: 218.842 Valid: 235.325\n",
      "Time elapsed: 0:03:19.193349\n",
      "Epoch 48, MSE, Train: 218.377 Valid: 224.182\n",
      "Time elapsed: 0:03:23.284285\n",
      "Epoch 49, MSE, Train: 215.975 Valid: 219.598\n",
      "Time elapsed: 0:03:27.362210\n",
      "Epoch 50, MSE, Train: 215.548 Valid: 219.655\n",
      "Time elapsed: 0:03:31.428133\n",
      "Epoch 51, MSE, Train: 216.343 Valid: 222.050\n",
      "Time elapsed: 0:03:35.517060\n",
      "Epoch 52, MSE, Train: 215.854 Valid: 221.456\n",
      "Time elapsed: 0:03:39.587984\n",
      "Epoch 53, MSE, Train: 216.534 Valid: 220.647\n",
      "Time elapsed: 0:03:43.692915\n",
      "Epoch 54, MSE, Train: 215.784 Valid: 220.092\n",
      "Time elapsed: 0:03:47.786844\n",
      "Epoch 55, MSE, Train: 215.599 Valid: 219.578\n",
      "Time elapsed: 0:03:51.875772\n",
      "Epoch 56, MSE, Train: 216.949 Valid: 220.865\n",
      "Time elapsed: 0:03:55.972701\n",
      "Epoch 57, MSE, Train: 217.650 Valid: 222.961\n",
      "Time elapsed: 0:04:00.063629\n",
      "Epoch 58, MSE, Train: 215.884 Valid: 221.409\n",
      "Time elapsed: 0:04:04.127552\n",
      "Epoch 59, MSE, Train: 215.949 Valid: 220.394\n",
      "Time elapsed: 0:04:08.218471\n",
      "Epoch 60, MSE, Train: 215.985 Valid: 219.909\n",
      "Time elapsed: 0:04:12.296397\n",
      "Epoch 61, MSE, Train: 218.084 Valid: 222.204\n",
      "Time elapsed: 0:04:16.384332\n",
      "Epoch 62, MSE, Train: 224.054 Valid: 220.766\n",
      "Time elapsed: 0:04:20.461248\n",
      "Epoch 63, MSE, Train: 218.752 Valid: 224.585\n",
      "Time elapsed: 0:04:24.549184\n",
      "Epoch 64, MSE, Train: 217.660 Valid: 221.935\n",
      "Time elapsed: 0:04:28.644114\n",
      "Epoch 65, MSE, Train: 227.597 Valid: 222.175\n",
      "Time elapsed: 0:04:32.726040\n",
      "Epoch 66, MSE, Train: 221.039 Valid: 220.358\n",
      "Time elapsed: 0:04:36.819968\n",
      "Epoch 67, MSE, Train: 216.805 Valid: 219.839\n",
      "Time elapsed: 0:04:40.915898\n",
      "Epoch 68, MSE, Train: 216.022 Valid: 220.348\n",
      "Time elapsed: 0:04:45.006817\n",
      "Epoch 69, MSE, Train: 215.992 Valid: 219.612\n",
      "Time elapsed: 0:04:49.249779\n",
      "Epoch 70, MSE, Train: 215.719 Valid: 219.247\n",
      "Time elapsed: 0:04:53.341717\n",
      "Epoch 71, MSE, Train: 216.135 Valid: 221.121\n",
      "Time elapsed: 0:04:57.562665\n",
      "Epoch 72, MSE, Train: 215.883 Valid: 219.246\n",
      "Time elapsed: 0:05:01.647601\n",
      "Epoch 73, MSE, Train: 215.695 Valid: 222.235\n",
      "Time elapsed: 0:05:05.714524\n",
      "Epoch 74, MSE, Train: 215.884 Valid: 220.970\n",
      "Time elapsed: 0:05:09.789448\n",
      "Epoch 75, MSE, Train: 215.860 Valid: 220.064\n",
      "Time elapsed: 0:05:13.874367\n",
      "Epoch 76, MSE, Train: 215.880 Valid: 220.038\n",
      "Time elapsed: 0:05:17.968304\n",
      "Epoch 77, MSE, Train: 215.706 Valid: 219.825\n",
      "Time elapsed: 0:05:22.059232\n",
      "Epoch 78, MSE, Train: 216.154 Valid: 220.598\n",
      "Time elapsed: 0:05:26.136165\n",
      "Epoch 79, MSE, Train: 215.949 Valid: 223.613\n",
      "Time elapsed: 0:05:30.223084\n",
      "Epoch 80, MSE, Train: 215.886 Valid: 220.592\n",
      "Time elapsed: 0:05:34.309011\n",
      "Epoch 81, MSE, Train: 215.719 Valid: 219.446\n",
      "Time elapsed: 0:05:38.380934\n",
      "Epoch 82, MSE, Train: 216.107 Valid: 220.328\n",
      "Time elapsed: 0:05:42.443856\n",
      "Epoch 83, MSE, Train: 215.973 Valid: 221.459\n",
      "Time elapsed: 0:05:46.513789\n",
      "Epoch 84, MSE, Train: 215.974 Valid: 220.401\n",
      "Time elapsed: 0:05:50.588704\n",
      "Epoch 85, MSE, Train: 215.808 Valid: 219.480\n",
      "Time elapsed: 0:05:54.666630\n",
      "Epoch 86, MSE, Train: 215.602 Valid: 220.437\n",
      "Time elapsed: 0:05:58.752557\n",
      "Epoch 87, MSE, Train: 216.136 Valid: 219.913\n",
      "Time elapsed: 0:06:02.827472\n",
      "Epoch 88, MSE, Train: 215.518 Valid: 221.361\n",
      "Time elapsed: 0:06:06.912399\n",
      "Epoch 89, MSE, Train: 215.429 Valid: 222.294\n",
      "Time elapsed: 0:06:10.985332\n",
      "Epoch 90, MSE, Train: 215.330 Valid: 221.828\n",
      "Time elapsed: 0:06:15.077261\n",
      "Epoch 91, MSE, Train: 215.792 Valid: 220.155\n",
      "Time elapsed: 0:06:19.170189\n",
      "Epoch 92, MSE, Train: 216.073 Valid: 220.582\n",
      "Time elapsed: 0:06:23.247114\n",
      "Epoch 93, MSE, Train: 239.688 Valid: 224.404\n",
      "Time elapsed: 0:06:27.334041\n",
      "Epoch 94, MSE, Train: 222.795 Valid: 225.577\n",
      "Time elapsed: 0:06:31.430971\n",
      "Epoch 95, MSE, Train: 221.086 Valid: 224.210\n",
      "Time elapsed: 0:06:35.513889\n",
      "Epoch 96, MSE, Train: 220.264 Valid: 222.038\n",
      "Time elapsed: 0:06:39.599823\n",
      "Epoch 97, MSE, Train: 219.003 Valid: 223.179\n",
      "Time elapsed: 0:06:43.675749\n",
      "Epoch 98, MSE, Train: 218.963 Valid: 222.298\n",
      "Time elapsed: 0:06:47.751673\n",
      "Epoch 99, MSE, Train: 218.079 Valid: 221.834\n",
      "Time elapsed: 0:06:51.832618\n",
      "Epoch 100, MSE, Train: 218.276 Valid: 220.392\n",
      "Time elapsed: 0:06:55.901522\n",
      "Epoch 101, MSE, Train: 217.643 Valid: 220.851\n",
      "Time elapsed: 0:06:59.987449\n",
      "Epoch 102, MSE, Train: 217.162 Valid: 220.115\n",
      "Time elapsed: 0:07:04.046361\n",
      "Epoch 103, MSE, Train: 217.265 Valid: 222.370\n",
      "Time elapsed: 0:07:08.113293\n",
      "Epoch 104, MSE, Train: 217.268 Valid: 225.759\n",
      "Time elapsed: 0:07:12.214223\n",
      "Epoch 105, MSE, Train: 216.906 Valid: 221.475\n",
      "Time elapsed: 0:07:16.301142\n",
      "Epoch 106, MSE, Train: 217.420 Valid: 219.742\n",
      "Time elapsed: 0:07:20.370073\n",
      "Epoch 107, MSE, Train: 216.412 Valid: 223.504\n",
      "Time elapsed: 0:07:24.449999\n",
      "Epoch 108, MSE, Train: 216.674 Valid: 220.571\n",
      "Time elapsed: 0:07:28.521923\n",
      "Epoch 109, MSE, Train: 216.547 Valid: 220.710\n",
      "Time elapsed: 0:07:32.590846\n",
      "Epoch 110, MSE, Train: 216.244 Valid: 220.878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:07:36.686766\n",
      "Epoch 111, MSE, Train: 216.540 Valid: 220.467\n",
      "Time elapsed: 0:07:40.770695\n",
      "Epoch 112, MSE, Train: 216.460 Valid: 219.617\n",
      "Time elapsed: 0:07:44.879625\n",
      "Epoch 113, MSE, Train: 216.194 Valid: 221.313\n",
      "Time elapsed: 0:07:48.959567\n",
      "Epoch 114, MSE, Train: 216.097 Valid: 220.103\n",
      "Time elapsed: 0:07:53.026473\n",
      "Epoch 115, MSE, Train: 216.665 Valid: 220.854\n",
      "Time elapsed: 0:07:57.124412\n",
      "Epoch 116, MSE, Train: 216.468 Valid: 223.196\n",
      "Time elapsed: 0:08:01.212339\n",
      "Epoch 117, MSE, Train: 216.203 Valid: 226.661\n",
      "Time elapsed: 0:08:05.308268\n",
      "Epoch 118, MSE, Train: 216.227 Valid: 224.378\n",
      "Time elapsed: 0:08:09.406190\n",
      "Epoch 119, MSE, Train: 216.007 Valid: 219.573\n",
      "Time elapsed: 0:08:13.494126\n",
      "Epoch 120, MSE, Train: 216.329 Valid: 220.175\n",
      "Time elapsed: 0:08:17.577052\n",
      "Epoch 121, MSE, Train: 216.196 Valid: 222.368\n",
      "Time elapsed: 0:08:21.663971\n",
      "Epoch 122, MSE, Train: 215.613 Valid: 220.334\n",
      "Time elapsed: 0:08:25.732903\n",
      "Epoch 123, MSE, Train: 215.972 Valid: 219.348\n",
      "Time elapsed: 0:08:29.828823\n",
      "Epoch 124, MSE, Train: 215.836 Valid: 227.165\n",
      "Time elapsed: 0:08:33.896747\n",
      "Epoch 125, MSE, Train: 216.584 Valid: 221.209\n",
      "Time elapsed: 0:08:37.977680\n",
      "Epoch 126, MSE, Train: 215.782 Valid: 221.812\n",
      "Time elapsed: 0:08:42.060598\n",
      "Epoch 127, MSE, Train: 215.723 Valid: 220.167\n",
      "Time elapsed: 0:08:46.142533\n",
      "Epoch 128, MSE, Train: 215.593 Valid: 221.437\n",
      "Time elapsed: 0:08:50.230460\n",
      "Epoch 129, MSE, Train: 215.496 Valid: 219.599\n",
      "Time elapsed: 0:08:54.310386\n",
      "Epoch 130, MSE, Train: 215.943 Valid: 222.408\n",
      "Time elapsed: 0:08:58.399306\n",
      "Epoch 131, MSE, Train: 216.075 Valid: 226.390\n",
      "Time elapsed: 0:09:02.494257\n",
      "Epoch 132, MSE, Train: 215.678 Valid: 221.407\n",
      "Time elapsed: 0:09:06.575161\n",
      "Epoch 133, MSE, Train: 216.363 Valid: 228.356\n",
      "Time elapsed: 0:09:10.682100\n",
      "Epoch 134, MSE, Train: 216.294 Valid: 220.009\n",
      "Time elapsed: 0:09:14.777029\n",
      "Epoch 135, MSE, Train: 215.814 Valid: 219.497\n",
      "Time elapsed: 0:09:18.881960\n",
      "Epoch 136, MSE, Train: 215.723 Valid: 219.549\n",
      "Time elapsed: 0:09:22.971880\n",
      "Epoch 137, MSE, Train: 215.976 Valid: 219.732\n",
      "Time elapsed: 0:09:27.080821\n",
      "Epoch 138, MSE, Train: 215.363 Valid: 226.531\n",
      "Time elapsed: 0:09:31.184752\n",
      "Epoch 139, MSE, Train: 218.294 Valid: 248.100\n",
      "Time elapsed: 0:09:35.308687\n",
      "Epoch 140, MSE, Train: 221.291 Valid: 220.163\n",
      "Time elapsed: 0:09:39.393614\n",
      "Epoch 141, MSE, Train: 216.508 Valid: 219.736\n",
      "Time elapsed: 0:09:43.499546\n",
      "Epoch 142, MSE, Train: 216.290 Valid: 222.785\n",
      "Time elapsed: 0:09:47.565468\n",
      "Epoch 143, MSE, Train: 216.362 Valid: 220.396\n",
      "Time elapsed: 0:09:51.659389\n",
      "Epoch 144, MSE, Train: 215.905 Valid: 220.842\n",
      "Time elapsed: 0:09:55.734321\n",
      "Epoch 145, MSE, Train: 215.830 Valid: 220.186\n",
      "Time elapsed: 0:09:59.828241\n",
      "Epoch 146, MSE, Train: 215.840 Valid: 220.011\n",
      "Time elapsed: 0:10:03.933182\n",
      "Epoch 147, MSE, Train: 215.434 Valid: 222.882\n",
      "Time elapsed: 0:10:08.026110\n",
      "Epoch 148, MSE, Train: 215.790 Valid: 219.805\n",
      "Time elapsed: 0:10:12.107028\n",
      "Epoch 149, MSE, Train: 215.408 Valid: 221.100\n",
      "Time elapsed: 0:10:16.202965\n",
      "Epoch 150, MSE, Train: 215.618 Valid: 220.056\n",
      "---Finished training results---\n",
      "Time elapsed: 0:10:16.202965\n",
      "---Training for quadratic deep hedging end---\n",
      "INFO:tensorflow:Restoring parameters from /Users/alexa/Github files/Long-term hedging paper example/Models/Yearly_underlying_MSE/models.ckpt\n",
      "-------------------------------\n",
      "Results on the TRAIN SET:\n",
      "Model was trained with the loss function: MSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -0.619217228586391\n",
      "CVaR_95: 40.9899, CVaR_99: 67.6135\n",
      "VaR_95: 25.5910, VaR_99: 50.0212\n",
      "MSE: 214.6137, RMSE: 14.6497\n",
      "Semi-MSE: 137.9313, Semi-RMSE: 11.7444\n",
      "Skew: 1.8131\n",
      "-------------------------------\n",
      "Results on the VALID SET:\n",
      "Model was trained with the loss function: MSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -0.5667378932625922\n",
      "CVaR_95: 41.8086, CVaR_99: 69.6916\n",
      "VaR_95: 25.8563, VaR_99: 51.0415\n",
      "MSE: 219.2461, RMSE: 14.8070\n",
      "Semi-MSE: 142.7914, Semi-RMSE: 11.9495\n",
      "Skew: 1.8604\n",
      "-------------------------------\n",
      "Results on the TEST SET:\n",
      "Model was trained with the loss function: MSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -0.6156766071133927\n",
      "CVaR_95: 41.2078, CVaR_99: 68.1837\n",
      "VaR_95: 25.6635, VaR_99: 50.3521\n",
      "MSE: 215.8881, RMSE: 14.6931\n",
      "Semi-MSE: 139.0573, Semi-RMSE: 11.7923\n",
      "Skew: 1.8182\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "END OF QUADRATIC DEEP HEDGING\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "Hyperparameters: learning rate=0.0017, LSTM cells=2, neurons=24\n",
      "---Training for semi-quadratic deep hedging start---\n",
      "Time elapsed: 0:00:04.921156\n",
      "Epoch 1, SMSE, Train: 54.079 Valid: 31.322\n",
      "Time elapsed: 0:00:09.174121\n",
      "Epoch 2, SMSE, Train: 29.939 Valid: 29.717\n",
      "Time elapsed: 0:00:13.412082\n",
      "Epoch 3, SMSE, Train: 29.190 Valid: 28.437\n",
      "Time elapsed: 0:00:17.643074\n",
      "Epoch 4, SMSE, Train: 28.250 Valid: 27.164\n",
      "Time elapsed: 0:00:21.882037\n",
      "Epoch 5, SMSE, Train: 26.473 Valid: 26.004\n",
      "Time elapsed: 0:00:26.136994\n",
      "Epoch 6, SMSE, Train: 25.308 Valid: 25.030\n",
      "Time elapsed: 0:00:30.491989\n",
      "Epoch 7, SMSE, Train: 24.448 Valid: 23.794\n",
      "Time elapsed: 0:00:34.738986\n",
      "Epoch 8, SMSE, Train: 23.593 Valid: 23.731\n",
      "Time elapsed: 0:00:38.980948\n",
      "Epoch 9, SMSE, Train: 23.257 Valid: 22.651\n",
      "Time elapsed: 0:00:43.228912\n",
      "Epoch 10, SMSE, Train: 22.614 Valid: 22.340\n",
      "Time elapsed: 0:00:47.452870\n",
      "Epoch 11, SMSE, Train: 22.446 Valid: 22.309\n",
      "Time elapsed: 0:00:51.699834\n",
      "Epoch 12, SMSE, Train: 22.312 Valid: 21.641\n",
      "Time elapsed: 0:00:55.780760\n",
      "Epoch 13, SMSE, Train: 22.373 Valid: 22.563\n",
      "Time elapsed: 0:01:00.005718\n",
      "Epoch 14, SMSE, Train: 21.384 Valid: 21.042\n",
      "Time elapsed: 0:01:04.231677\n",
      "Epoch 15, SMSE, Train: 21.422 Valid: 21.000\n",
      "Time elapsed: 0:01:08.299600\n",
      "Epoch 16, SMSE, Train: 21.493 Valid: 22.134\n",
      "Time elapsed: 0:01:12.528559\n",
      "Epoch 17, SMSE, Train: 20.822 Valid: 20.846\n",
      "Time elapsed: 0:01:16.770521\n",
      "Epoch 18, SMSE, Train: 20.944 Valid: 20.720\n",
      "Time elapsed: 0:01:20.868452\n",
      "Epoch 19, SMSE, Train: 20.826 Valid: 20.943\n",
      "Time elapsed: 0:01:24.970382\n",
      "Epoch 20, SMSE, Train: 20.874 Valid: 21.018\n",
      "Time elapsed: 0:01:29.195340\n",
      "Epoch 21, SMSE, Train: 20.924 Valid: 20.539\n",
      "Time elapsed: 0:01:33.266265\n",
      "Epoch 22, SMSE, Train: 20.178 Valid: 20.861\n",
      "Time elapsed: 0:01:37.503225\n",
      "Epoch 23, SMSE, Train: 20.849 Valid: 20.311\n",
      "Time elapsed: 0:01:41.736217\n",
      "Epoch 24, SMSE, Train: 20.108 Valid: 19.946\n",
      "Time elapsed: 0:01:45.835148\n",
      "Epoch 25, SMSE, Train: 20.166 Valid: 19.975\n",
      "Time elapsed: 0:01:50.086111\n",
      "Epoch 26, SMSE, Train: 20.218 Valid: 19.813\n",
      "Time elapsed: 0:01:54.347078\n",
      "Epoch 27, SMSE, Train: 20.085 Valid: 19.805\n",
      "Time elapsed: 0:01:58.592041\n",
      "Epoch 28, SMSE, Train: 19.787 Valid: 19.751\n",
      "Time elapsed: 0:02:02.675968\n",
      "Epoch 29, SMSE, Train: 19.548 Valid: 20.053\n",
      "Time elapsed: 0:02:06.782900\n",
      "Epoch 30, SMSE, Train: 19.547 Valid: 20.108\n",
      "Time elapsed: 0:02:10.866818\n",
      "Epoch 31, SMSE, Train: 19.657 Valid: 19.834\n",
      "Time elapsed: 0:02:15.243819\n",
      "Epoch 32, SMSE, Train: 19.386 Valid: 19.704\n",
      "Time elapsed: 0:02:19.373756\n",
      "Epoch 33, SMSE, Train: 19.965 Valid: 19.895\n",
      "Time elapsed: 0:02:23.626721\n",
      "Epoch 34, SMSE, Train: 19.525 Valid: 19.576\n",
      "Time elapsed: 0:02:27.707647\n",
      "Epoch 35, SMSE, Train: 19.360 Valid: 20.654\n",
      "Time elapsed: 0:02:31.958611\n",
      "Epoch 36, SMSE, Train: 19.359 Valid: 19.183\n",
      "Time elapsed: 0:02:36.082547\n",
      "Epoch 37, SMSE, Train: 19.259 Valid: 19.347\n",
      "Time elapsed: 0:02:40.186478\n",
      "Epoch 38, SMSE, Train: 19.300 Valid: 19.448\n",
      "Time elapsed: 0:02:44.285408\n",
      "Epoch 39, SMSE, Train: 19.061 Valid: 19.556\n",
      "Time elapsed: 0:02:48.376336\n",
      "Epoch 40, SMSE, Train: 19.049 Valid: 20.302\n",
      "Time elapsed: 0:02:52.471257\n",
      "Epoch 41, SMSE, Train: 19.067 Valid: 20.655\n",
      "Time elapsed: 0:02:56.594201\n",
      "Epoch 42, SMSE, Train: 19.133 Valid: 19.451\n",
      "Time elapsed: 0:03:00.718137\n",
      "Epoch 43, SMSE, Train: 18.966 Valid: 19.291\n",
      "Time elapsed: 0:03:04.985104\n",
      "Epoch 44, SMSE, Train: 18.942 Valid: 19.015\n",
      "Time elapsed: 0:03:09.106040\n",
      "Epoch 45, SMSE, Train: 18.937 Valid: 19.192\n",
      "Time elapsed: 0:03:13.211971\n",
      "Epoch 46, SMSE, Train: 18.947 Valid: 19.829\n",
      "Time elapsed: 0:03:17.479938\n",
      "Epoch 47, SMSE, Train: 19.023 Valid: 18.852\n",
      "Time elapsed: 0:03:21.575868\n",
      "Epoch 48, SMSE, Train: 18.843 Valid: 19.078\n",
      "Time elapsed: 0:03:25.674798\n",
      "Epoch 49, SMSE, Train: 18.999 Valid: 19.061\n",
      "Time elapsed: 0:03:29.800726\n",
      "Epoch 50, SMSE, Train: 18.808 Valid: 18.969\n",
      "Time elapsed: 0:03:33.908666\n",
      "Epoch 51, SMSE, Train: 18.742 Valid: 19.088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:03:38.003595\n",
      "Epoch 52, SMSE, Train: 18.706 Valid: 19.204\n",
      "Time elapsed: 0:03:42.086521\n",
      "Epoch 53, SMSE, Train: 18.796 Valid: 19.064\n",
      "Time elapsed: 0:03:46.349489\n",
      "Epoch 54, SMSE, Train: 18.620 Valid: 19.435\n",
      "Time elapsed: 0:03:50.496420\n",
      "Epoch 55, SMSE, Train: 18.536 Valid: 19.534\n",
      "Time elapsed: 0:03:54.600361\n",
      "Epoch 56, SMSE, Train: 18.702 Valid: 18.890\n",
      "Time elapsed: 0:03:58.741300\n",
      "Epoch 57, SMSE, Train: 18.677 Valid: 19.115\n",
      "Time elapsed: 0:04:02.988327\n",
      "Epoch 58, SMSE, Train: 18.636 Valid: 18.796\n",
      "Time elapsed: 0:04:07.247293\n",
      "Epoch 59, SMSE, Train: 18.657 Valid: 18.762\n",
      "Time elapsed: 0:04:11.355225\n",
      "Epoch 60, SMSE, Train: 18.755 Valid: 18.987\n",
      "Time elapsed: 0:04:15.457156\n",
      "Epoch 61, SMSE, Train: 18.581 Valid: 19.148\n",
      "Time elapsed: 0:04:19.558086\n",
      "Epoch 62, SMSE, Train: 18.560 Valid: 19.103\n",
      "Time elapsed: 0:04:23.810050\n",
      "Epoch 63, SMSE, Train: 18.673 Valid: 18.701\n",
      "Time elapsed: 0:04:27.902979\n",
      "Epoch 64, SMSE, Train: 18.466 Valid: 19.133\n",
      "Time elapsed: 0:04:32.009911\n",
      "Epoch 65, SMSE, Train: 18.383 Valid: 19.370\n",
      "Time elapsed: 0:04:36.125845\n",
      "Epoch 66, SMSE, Train: 18.631 Valid: 18.724\n",
      "Time elapsed: 0:04:40.231776\n",
      "Epoch 67, SMSE, Train: 18.295 Valid: 18.764\n",
      "Time elapsed: 0:04:44.329706\n",
      "Epoch 68, SMSE, Train: 18.451 Valid: 19.081\n",
      "Time elapsed: 0:04:48.429636\n",
      "Epoch 69, SMSE, Train: 18.375 Valid: 19.793\n",
      "Time elapsed: 0:04:52.532559\n",
      "Epoch 70, SMSE, Train: 18.327 Valid: 19.173\n",
      "Time elapsed: 0:04:56.622495\n",
      "Epoch 71, SMSE, Train: 18.397 Valid: 19.263\n",
      "Time elapsed: 0:05:00.724426\n",
      "Epoch 72, SMSE, Train: 18.312 Valid: 19.601\n",
      "Time elapsed: 0:05:04.823355\n",
      "Epoch 73, SMSE, Train: 18.216 Valid: 21.273\n",
      "Time elapsed: 0:05:08.922285\n",
      "Epoch 74, SMSE, Train: 18.405 Valid: 19.230\n",
      "Time elapsed: 0:05:13.012213\n",
      "Epoch 75, SMSE, Train: 18.121 Valid: 19.205\n",
      "Time elapsed: 0:05:17.268243\n",
      "Epoch 76, SMSE, Train: 18.353 Valid: 18.667\n",
      "Time elapsed: 0:05:21.354170\n",
      "Epoch 77, SMSE, Train: 18.284 Valid: 19.303\n",
      "Time elapsed: 0:05:25.449099\n",
      "Epoch 78, SMSE, Train: 18.176 Valid: 18.902\n",
      "Time elapsed: 0:05:29.565033\n",
      "Epoch 79, SMSE, Train: 18.124 Valid: 18.894\n",
      "Time elapsed: 0:05:33.683968\n",
      "Epoch 80, SMSE, Train: 18.345 Valid: 18.794\n",
      "Time elapsed: 0:05:37.776896\n",
      "Epoch 81, SMSE, Train: 18.146 Valid: 19.104\n",
      "Time elapsed: 0:05:41.887829\n",
      "Epoch 82, SMSE, Train: 18.172 Valid: 18.835\n",
      "Time elapsed: 0:05:46.137858\n",
      "Epoch 83, SMSE, Train: 18.217 Valid: 18.590\n",
      "Time elapsed: 0:05:50.259794\n",
      "Epoch 84, SMSE, Train: 18.078 Valid: 19.041\n",
      "Time elapsed: 0:05:54.366716\n",
      "Epoch 85, SMSE, Train: 18.069 Valid: 18.781\n",
      "Time elapsed: 0:05:58.471647\n",
      "Epoch 86, SMSE, Train: 18.146 Valid: 18.871\n",
      "Time elapsed: 0:06:02.564585\n",
      "Epoch 87, SMSE, Train: 18.124 Valid: 18.726\n",
      "Time elapsed: 0:06:06.652512\n",
      "Epoch 88, SMSE, Train: 18.108 Valid: 18.782\n",
      "Time elapsed: 0:06:10.760435\n",
      "Epoch 89, SMSE, Train: 18.173 Valid: 19.725\n",
      "Time elapsed: 0:06:14.839361\n",
      "Epoch 90, SMSE, Train: 18.113 Valid: 19.055\n",
      "Time elapsed: 0:06:19.083333\n",
      "Epoch 91, SMSE, Train: 18.020 Valid: 18.588\n",
      "Time elapsed: 0:06:23.189264\n",
      "Epoch 92, SMSE, Train: 17.995 Valid: 18.860\n",
      "Time elapsed: 0:06:27.300197\n",
      "Epoch 93, SMSE, Train: 18.153 Valid: 18.736\n",
      "Time elapsed: 0:06:31.375122\n",
      "Epoch 94, SMSE, Train: 17.973 Valid: 20.017\n",
      "Time elapsed: 0:06:35.458048\n",
      "Epoch 95, SMSE, Train: 17.945 Valid: 19.612\n",
      "Time elapsed: 0:06:39.547975\n",
      "Epoch 96, SMSE, Train: 17.885 Valid: 19.747\n",
      "Time elapsed: 0:06:43.634894\n",
      "Epoch 97, SMSE, Train: 17.973 Valid: 19.004\n",
      "Time elapsed: 0:06:47.747836\n",
      "Epoch 98, SMSE, Train: 17.968 Valid: 19.441\n",
      "Time elapsed: 0:06:51.822760\n",
      "Epoch 99, SMSE, Train: 17.931 Valid: 18.820\n",
      "Time elapsed: 0:06:55.892684\n",
      "Epoch 100, SMSE, Train: 17.943 Valid: 19.147\n",
      "Time elapsed: 0:06:59.982612\n",
      "Epoch 101, SMSE, Train: 17.906 Valid: 18.797\n",
      "Time elapsed: 0:07:04.071539\n",
      "Epoch 102, SMSE, Train: 17.855 Valid: 19.409\n",
      "Time elapsed: 0:07:08.178461\n",
      "Epoch 103, SMSE, Train: 17.879 Valid: 18.909\n",
      "Time elapsed: 0:07:12.266399\n",
      "Epoch 104, SMSE, Train: 17.788 Valid: 18.896\n",
      "Time elapsed: 0:07:16.364328\n",
      "Epoch 105, SMSE, Train: 17.761 Valid: 19.252\n",
      "Time elapsed: 0:07:20.487254\n",
      "Epoch 106, SMSE, Train: 17.769 Valid: 19.112\n",
      "Time elapsed: 0:07:24.586193\n",
      "Epoch 107, SMSE, Train: 17.761 Valid: 18.886\n",
      "Time elapsed: 0:07:28.684123\n",
      "Epoch 108, SMSE, Train: 17.769 Valid: 18.729\n",
      "Time elapsed: 0:07:32.788054\n",
      "Epoch 109, SMSE, Train: 17.857 Valid: 20.643\n",
      "Time elapsed: 0:07:36.894986\n",
      "Epoch 110, SMSE, Train: 17.627 Valid: 20.012\n",
      "Time elapsed: 0:07:40.980904\n",
      "Epoch 111, SMSE, Train: 17.644 Valid: 18.996\n",
      "Time elapsed: 0:07:45.070841\n",
      "Epoch 112, SMSE, Train: 17.595 Valid: 18.721\n",
      "Time elapsed: 0:07:49.146766\n",
      "Epoch 113, SMSE, Train: 18.210 Valid: 19.183\n",
      "Time elapsed: 0:07:53.244695\n",
      "Epoch 114, SMSE, Train: 17.787 Valid: 19.068\n",
      "Time elapsed: 0:07:57.333623\n",
      "Epoch 115, SMSE, Train: 17.513 Valid: 19.324\n",
      "Time elapsed: 0:08:01.422551\n",
      "Epoch 116, SMSE, Train: 17.663 Valid: 19.625\n",
      "Time elapsed: 0:08:05.500476\n",
      "Epoch 117, SMSE, Train: 17.674 Valid: 19.213\n",
      "Time elapsed: 0:08:09.584402\n",
      "Epoch 118, SMSE, Train: 17.802 Valid: 19.108\n",
      "Time elapsed: 0:08:13.669329\n",
      "Epoch 119, SMSE, Train: 17.602 Valid: 19.001\n",
      "Time elapsed: 0:08:17.747254\n",
      "Epoch 120, SMSE, Train: 17.560 Valid: 19.650\n",
      "Time elapsed: 0:08:21.839173\n",
      "Epoch 121, SMSE, Train: 17.809 Valid: 19.253\n",
      "Time elapsed: 0:08:25.935112\n",
      "Epoch 122, SMSE, Train: 17.801 Valid: 18.713\n",
      "Time elapsed: 0:08:30.040034\n",
      "Epoch 123, SMSE, Train: 17.648 Valid: 20.745\n",
      "Time elapsed: 0:08:34.118960\n",
      "Epoch 124, SMSE, Train: 17.508 Valid: 19.459\n",
      "Time elapsed: 0:08:38.213888\n",
      "Epoch 125, SMSE, Train: 17.544 Valid: 19.067\n",
      "Time elapsed: 0:08:42.337834\n",
      "Epoch 126, SMSE, Train: 17.451 Valid: 19.636\n",
      "Time elapsed: 0:08:46.465770\n",
      "Epoch 127, SMSE, Train: 17.386 Valid: 19.702\n",
      "Time elapsed: 0:08:50.590696\n",
      "Epoch 128, SMSE, Train: 17.446 Valid: 21.557\n",
      "Time elapsed: 0:08:54.693637\n",
      "Epoch 129, SMSE, Train: 17.676 Valid: 19.124\n",
      "Time elapsed: 0:08:58.784556\n",
      "Epoch 130, SMSE, Train: 17.428 Valid: 19.284\n",
      "Time elapsed: 0:09:02.877493\n",
      "Epoch 131, SMSE, Train: 17.407 Valid: 19.536\n",
      "Time elapsed: 0:09:06.982424\n",
      "Epoch 132, SMSE, Train: 17.263 Valid: 19.886\n",
      "Time elapsed: 0:09:11.107361\n",
      "Epoch 133, SMSE, Train: 17.369 Valid: 20.185\n",
      "Time elapsed: 0:09:15.200289\n",
      "Epoch 134, SMSE, Train: 17.428 Valid: 19.437\n",
      "Time elapsed: 0:09:19.307220\n",
      "Epoch 135, SMSE, Train: 17.283 Valid: 20.534\n",
      "Time elapsed: 0:09:23.411151\n",
      "Epoch 136, SMSE, Train: 17.691 Valid: 20.033\n",
      "Time elapsed: 0:09:27.510072\n",
      "Epoch 137, SMSE, Train: 17.316 Valid: 20.212\n",
      "Time elapsed: 0:09:31.609002\n",
      "Epoch 138, SMSE, Train: 17.211 Valid: 20.223\n",
      "Time elapsed: 0:09:35.719944\n",
      "Epoch 139, SMSE, Train: 17.242 Valid: 19.655\n",
      "Time elapsed: 0:09:39.823866\n",
      "Epoch 140, SMSE, Train: 17.241 Valid: 19.385\n",
      "Time elapsed: 0:09:43.914803\n",
      "Epoch 141, SMSE, Train: 17.227 Valid: 19.593\n",
      "Time elapsed: 0:09:48.012733\n",
      "Epoch 142, SMSE, Train: 17.346 Valid: 21.783\n",
      "Time elapsed: 0:09:52.089658\n",
      "Epoch 143, SMSE, Train: 17.273 Valid: 19.839\n",
      "Time elapsed: 0:09:56.190589\n",
      "Epoch 144, SMSE, Train: 17.211 Valid: 19.623\n",
      "Time elapsed: 0:10:00.267505\n",
      "Epoch 145, SMSE, Train: 17.173 Valid: 20.843\n",
      "Time elapsed: 0:10:04.365443\n",
      "Epoch 146, SMSE, Train: 17.266 Valid: 19.493\n",
      "Time elapsed: 0:10:08.463372\n",
      "Epoch 147, SMSE, Train: 17.343 Valid: 19.590\n",
      "Time elapsed: 0:10:12.553300\n",
      "Epoch 148, SMSE, Train: 17.033 Valid: 20.612\n",
      "Time elapsed: 0:10:16.641228\n",
      "Epoch 149, SMSE, Train: 16.935 Valid: 21.820\n",
      "Time elapsed: 0:10:20.746152\n",
      "Epoch 150, SMSE, Train: 17.168 Valid: 20.869\n",
      "---Finished training results---\n",
      "Time elapsed: 0:10:20.746152\n",
      "---Training for semi-quadratic deep hedging end---\n",
      "INFO:tensorflow:Restoring parameters from /Users/alexa/Github files/Long-term hedging paper example/Models/Yearly_underlying_SMSE/models.ckpt\n",
      "-------------------------------\n",
      "Results on the TRAIN SET:\n",
      "Model was trained with the loss function: SMSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -29.453986510285382\n",
      "CVaR_95: 15.6749, CVaR_99: 30.0812\n",
      "VaR_95: 6.9333, VaR_99: 20.5914\n",
      "MSE: 1600.4167, RMSE: 40.0052\n",
      "Semi-MSE: 17.5615, Semi-RMSE: 4.1906\n",
      "Skew: -0.8764\n",
      "-------------------------------\n",
      "Results on the VALID SET:\n",
      "Model was trained with the loss function: SMSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -29.394494751201023\n",
      "CVaR_95: 15.9938, CVaR_99: 30.7877\n",
      "VaR_95: 6.9778, VaR_99: 20.9259\n",
      "MSE: 1596.1854, RMSE: 39.9523\n",
      "Semi-MSE: 18.5885, Semi-RMSE: 4.3114\n",
      "Skew: -0.8568\n",
      "-------------------------------\n",
      "Results on the TEST SET:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with the loss function: SMSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -29.255898467657502\n",
      "CVaR_95: 16.1038, CVaR_99: 31.1355\n",
      "VaR_95: 7.1293, VaR_99: 21.0139\n",
      "MSE: 1586.7958, RMSE: 39.8346\n",
      "Semi-MSE: 19.2353, Semi-RMSE: 4.3858\n",
      "Skew: -0.8432\n",
      " ----------------------- \n",
      "Average exposure QDH: -0.0943\n",
      " ----------------------- \n",
      "Average exposure SQDH: 0.1620\n"
     ]
    }
   ],
   "source": [
    "nbs_assets          = 1\n",
    "hedging_instruments = \"Stock\"\n",
    "freq_obs            = \"Yearly\"\n",
    "\n",
    "# A) Part 1: MSE\n",
    "loss_type  = 'MSE'\n",
    "model_name = 'Yearly_underlying_MSE'\n",
    "lr         = 0.01   # learning rate of the Adam optimizer\n",
    "print(\"Hyperparameters: learning rate=%.4f, LSTM cells=%d, neurons=%d\" %(lr, hidden_layers, nbs_units))\n",
    "LSTM_underlying = DeepAgent(train_stock_year_input.shape[0], batch_size, train_stock_year_input.shape[2], \n",
    "        loss_type, nbs_assets, hidden_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments, \n",
    "        freq_obs, name = model_name)\n",
    "    \n",
    "# Start training \n",
    "start = dt.datetime.now()\n",
    "print('---Training for quadratic deep hedging start---')\n",
    "with tf.Session() as sess:           \n",
    "    loss_epoch = LSTM_underlying.training(train_stock_year_input, V_0_batch, disc_batch_year, valid_stock_year_input, \n",
    "                                          sess, epochs)\n",
    "    print('---Training for quadratic deep hedging end---')\n",
    "    \n",
    "# Compute measured risk exposure on train, valid and test set with the optimized LSTM\n",
    "model_predict = DeepAgent(test_stock_year_input.shape[0], batch_size, test_stock_year_input.shape[2], loss_type, \n",
    "        nbs_assets, hidden_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments, \n",
    "        freq_obs, name = model_name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Load the saved model\n",
    "    model_predict.restore(sess, r\"/Users/alexa/Github files/Long-term hedging paper example/Models/%s/models.ckpt\" % model_name)\n",
    "\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the TRAIN SET:\")\n",
    "    # Compute hedging strategies on the training set\n",
    "    deltas = model_predict.predict(train_stock_year_input, V_0_batch, disc_batch_year, sess, loss_type)    \n",
    "    hedging_stats(deltas, train_stock_year_input, disc_train_year, V_0_train, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the VALID SET:\")\n",
    "    # Compute hedging strategies on the valid set\n",
    "    deltas = model_predict.predict(valid_stock_year_input, V_0_batch, disc_batch_year, sess, loss_type)\n",
    "    hedging_stats(deltas, valid_stock_year_input, disc_valid_year, V_0_valid, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the TEST SET:\")\n",
    "    # Compute hedging strategies on the test set\n",
    "    deltas_MSE = model_predict.predict(test_stock_year_input, V_0_batch, disc_batch_year, sess, loss_type)\n",
    "    hedging_stats(deltas_MSE, test_stock_year_input, disc_test_year, V_0_test, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"END OF QUADRATIC DEEP HEDGING\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "# B) Part 2: SMSE\n",
    "loss_type  = 'SMSE'\n",
    "model_name = 'Yearly_underlying_SMSE'\n",
    "lr         = 0.01/6   # learning rate of the Adam optimizer\n",
    "print(\"Hyperparameters: learning rate=%.4f, LSTM cells=%d, neurons=%d\" %(lr, hidden_layers, nbs_units))\n",
    "LSTM_underlying = DeepAgent(train_stock_year_input.shape[0], batch_size, train_stock_year_input.shape[2], \n",
    "        loss_type, nbs_assets, hidden_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments, \n",
    "        freq_obs, name = model_name)\n",
    "    \n",
    "# Start training \n",
    "start = dt.datetime.now()\n",
    "print('---Training for semi-quadratic deep hedging start---')\n",
    "with tf.Session() as sess:           \n",
    "    loss_epoch = LSTM_underlying.training(train_stock_year_input, V_0_batch, disc_batch_year, valid_stock_year_input, \n",
    "                                          sess, epochs)\n",
    "    print('---Training for semi-quadratic deep hedging end---')\n",
    "    \n",
    "# Compute measured risk exposure on train, valid and test set with the optimized LSTM\n",
    "model_predict = DeepAgent(test_stock_year_input.shape[0], batch_size, test_stock_year_input.shape[2], loss_type, \n",
    "        nbs_assets, hidden_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments, \n",
    "        freq_obs, name = model_name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Load the saved model\n",
    "    model_predict.restore(sess, r\"/Users/alexa/Github files/Long-term hedging paper example/Models/%s/models.ckpt\" % model_name)\n",
    "\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the TRAIN SET:\")\n",
    "    # Compute hedging strategies on the training set\n",
    "    deltas = model_predict.predict(train_stock_year_input, V_0_batch, disc_batch_year, sess, loss_type)    \n",
    "    hedging_stats(deltas, train_stock_year_input, disc_train_year, V_0_train, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the VALID SET:\")\n",
    "    # Compute hedging strategies on the valid set\n",
    "    deltas = model_predict.predict(valid_stock_year_input, V_0_batch, disc_batch_year, sess, loss_type)\n",
    "    hedging_stats(deltas, valid_stock_year_input, disc_valid_year, V_0_valid, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the TEST SET:\")\n",
    "    # Compute hedging strategies on the test set\n",
    "    deltas_SMSE = model_predict.predict(test_stock_year_input, V_0_batch, disc_batch_year, sess, loss_type)\n",
    "    hedging_stats(deltas_SMSE, test_stock_year_input, disc_test_year, V_0_test, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "# Compute average equity risk exposure\n",
    "stock_price_unorm = np.exp(test_stock_year_input[:,:,0])\n",
    "portfolio_exposure_QDH  = deltas_MSE\n",
    "portfolio_exposure_SQDH = deltas_SMSE\n",
    "print(\" ----------------------- \")\n",
    "print(\"Average exposure QDH: %.4f\" %(np.mean(portfolio_exposure_QDH)))\n",
    "print(\" ----------------------- \")\n",
    "print(\"Average exposure SQDH: %.4f\" %(np.mean(portfolio_exposure_SQDH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Training of LSTM - ATM call and puts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: learning rate=0.0100, LSTM cells=2, neurons=24\n",
      "---Training for quadratic deep hedging start---\n",
      "Time elapsed: 0:00:05.345213\n",
      "Epoch 1, MSE, Train: 112.306 Valid: 27.502\n",
      "Time elapsed: 0:00:09.829221\n",
      "Epoch 2, MSE, Train: 25.157 Valid: 23.589\n",
      "Time elapsed: 0:00:14.312247\n",
      "Epoch 3, MSE, Train: 21.173 Valid: 19.185\n",
      "Time elapsed: 0:00:18.787262\n",
      "Epoch 4, MSE, Train: 20.116 Valid: 18.804\n",
      "Time elapsed: 0:00:23.272271\n",
      "Epoch 5, MSE, Train: 19.333 Valid: 17.930\n",
      "Time elapsed: 0:00:27.790305\n",
      "Epoch 6, MSE, Train: 19.194 Valid: 17.901\n",
      "Time elapsed: 0:00:32.129289\n",
      "Epoch 7, MSE, Train: 18.792 Valid: 21.181\n",
      "Time elapsed: 0:00:36.463273\n",
      "Epoch 8, MSE, Train: 18.950 Valid: 18.640\n",
      "Time elapsed: 0:00:40.801248\n",
      "Epoch 9, MSE, Train: 18.843 Valid: 18.206\n",
      "Time elapsed: 0:00:45.135230\n",
      "Epoch 10, MSE, Train: 19.064 Valid: 19.694\n",
      "Time elapsed: 0:00:49.481226\n",
      "Epoch 11, MSE, Train: 18.777 Valid: 21.135\n",
      "Time elapsed: 0:00:53.827202\n",
      "Epoch 12, MSE, Train: 18.874 Valid: 18.259\n",
      "Time elapsed: 0:00:58.159195\n",
      "Epoch 13, MSE, Train: 18.742 Valid: 17.915\n",
      "Time elapsed: 0:01:02.645212\n",
      "Epoch 14, MSE, Train: 18.562 Valid: 17.430\n",
      "Time elapsed: 0:01:06.994199\n",
      "Epoch 15, MSE, Train: 18.808 Valid: 18.715\n",
      "Time elapsed: 0:01:11.350187\n",
      "Epoch 16, MSE, Train: 18.533 Valid: 17.695\n",
      "Time elapsed: 0:01:15.716178\n",
      "Epoch 17, MSE, Train: 18.408 Valid: 17.633\n",
      "Time elapsed: 0:01:20.232202\n",
      "Epoch 18, MSE, Train: 18.583 Valid: 17.345\n",
      "Time elapsed: 0:01:24.571187\n",
      "Epoch 19, MSE, Train: 18.326 Valid: 17.595\n",
      "Time elapsed: 0:01:28.916173\n",
      "Epoch 20, MSE, Train: 18.304 Valid: 17.758\n",
      "Time elapsed: 0:01:33.247147\n",
      "Epoch 21, MSE, Train: 18.219 Valid: 17.667\n",
      "Time elapsed: 0:01:37.622148\n",
      "Epoch 22, MSE, Train: 18.364 Valid: 17.787\n",
      "Time elapsed: 0:01:42.145174\n",
      "Epoch 23, MSE, Train: 18.264 Valid: 17.264\n",
      "Time elapsed: 0:01:46.516160\n",
      "Epoch 24, MSE, Train: 18.280 Valid: 18.364\n",
      "Time elapsed: 0:01:50.852140\n",
      "Epoch 25, MSE, Train: 18.349 Valid: 17.794\n",
      "Time elapsed: 0:01:55.241145\n",
      "Epoch 26, MSE, Train: 18.231 Valid: 17.841\n",
      "Time elapsed: 0:01:59.625140\n",
      "Epoch 27, MSE, Train: 17.931 Valid: 18.097\n",
      "Time elapsed: 0:02:03.979128\n",
      "Epoch 28, MSE, Train: 18.044 Valid: 18.529\n",
      "Time elapsed: 0:02:08.333115\n",
      "Epoch 29, MSE, Train: 17.913 Valid: 17.897\n",
      "Time elapsed: 0:02:12.692104\n",
      "Epoch 30, MSE, Train: 17.975 Valid: 18.248\n",
      "Time elapsed: 0:02:17.064087\n",
      "Epoch 31, MSE, Train: 17.815 Valid: 17.353\n",
      "Time elapsed: 0:02:21.570118\n",
      "Epoch 32, MSE, Train: 17.799 Valid: 16.901\n",
      "Time elapsed: 0:02:25.921096\n",
      "Epoch 33, MSE, Train: 17.812 Valid: 18.376\n",
      "Time elapsed: 0:02:30.282095\n",
      "Epoch 34, MSE, Train: 17.530 Valid: 17.193\n",
      "Time elapsed: 0:02:34.638083\n",
      "Epoch 35, MSE, Train: 17.566 Valid: 17.676\n",
      "Time elapsed: 0:02:38.992062\n",
      "Epoch 36, MSE, Train: 17.502 Valid: 17.803\n",
      "Time elapsed: 0:02:43.351060\n",
      "Epoch 37, MSE, Train: 17.599 Valid: 17.232\n",
      "Time elapsed: 0:02:47.684043\n",
      "Epoch 38, MSE, Train: 17.390 Valid: 17.504\n",
      "Time elapsed: 0:02:52.017016\n",
      "Epoch 39, MSE, Train: 17.731 Valid: 17.340\n",
      "Time elapsed: 0:02:56.359011\n",
      "Epoch 40, MSE, Train: 17.551 Valid: 17.234\n",
      "Time elapsed: 0:03:00.698995\n",
      "Epoch 41, MSE, Train: 17.454 Valid: 17.341\n",
      "Time elapsed: 0:03:05.184004\n",
      "Epoch 42, MSE, Train: 17.433 Valid: 16.660\n",
      "Time elapsed: 0:03:09.494991\n",
      "Epoch 43, MSE, Train: 17.439 Valid: 17.044\n",
      "Time elapsed: 0:03:13.826965\n",
      "Epoch 44, MSE, Train: 17.534 Valid: 17.363\n",
      "Time elapsed: 0:03:18.152955\n",
      "Epoch 45, MSE, Train: 17.332 Valid: 17.112\n",
      "Time elapsed: 0:03:22.487939\n",
      "Epoch 46, MSE, Train: 17.379 Valid: 16.888\n",
      "Time elapsed: 0:03:26.827924\n",
      "Epoch 47, MSE, Train: 17.277 Valid: 17.094\n",
      "Time elapsed: 0:03:31.189913\n",
      "Epoch 48, MSE, Train: 17.400 Valid: 17.739\n",
      "Time elapsed: 0:03:35.533890\n",
      "Epoch 49, MSE, Train: 17.302 Valid: 16.663\n",
      "Time elapsed: 0:03:39.848878\n",
      "Epoch 50, MSE, Train: 17.393 Valid: 18.707\n",
      "Time elapsed: 0:03:44.177851\n",
      "Epoch 51, MSE, Train: 17.426 Valid: 16.887\n",
      "Time elapsed: 0:03:48.515844\n",
      "Epoch 52, MSE, Train: 17.299 Valid: 16.832\n",
      "Time elapsed: 0:03:53.021858\n",
      "Epoch 53, MSE, Train: 18.446 Valid: 16.648\n",
      "Time elapsed: 0:03:57.380846\n",
      "Epoch 54, MSE, Train: 17.151 Valid: 16.707\n",
      "Time elapsed: 0:04:01.730843\n",
      "Epoch 55, MSE, Train: 17.106 Valid: 17.795\n",
      "Time elapsed: 0:04:06.064826\n",
      "Epoch 56, MSE, Train: 17.330 Valid: 16.654\n",
      "Time elapsed: 0:04:10.422805\n",
      "Epoch 57, MSE, Train: 17.204 Valid: 16.791\n",
      "Time elapsed: 0:04:14.759798\n",
      "Epoch 58, MSE, Train: 17.236 Valid: 16.677\n",
      "Time elapsed: 0:04:19.105784\n",
      "Epoch 59, MSE, Train: 17.121 Valid: 17.585\n",
      "Time elapsed: 0:04:23.448760\n",
      "Epoch 60, MSE, Train: 17.205 Valid: 17.166\n",
      "Time elapsed: 0:04:27.789754\n",
      "Epoch 61, MSE, Train: 17.185 Valid: 16.706\n",
      "Time elapsed: 0:04:32.113735\n",
      "Epoch 62, MSE, Train: 16.983 Valid: 17.175\n",
      "Time elapsed: 0:04:36.424713\n",
      "Epoch 63, MSE, Train: 17.200 Valid: 17.149\n",
      "Time elapsed: 0:04:40.768699\n",
      "Epoch 64, MSE, Train: 17.131 Valid: 17.564\n",
      "Time elapsed: 0:04:45.117685\n",
      "Epoch 65, MSE, Train: 17.226 Valid: 17.009\n",
      "Time elapsed: 0:04:49.459661\n",
      "Epoch 66, MSE, Train: 17.116 Valid: 16.700\n",
      "Time elapsed: 0:04:53.800647\n",
      "Epoch 67, MSE, Train: 17.107 Valid: 17.056\n",
      "Time elapsed: 0:04:58.141640\n",
      "Epoch 68, MSE, Train: 17.028 Valid: 16.656\n",
      "Time elapsed: 0:05:02.484625\n",
      "Epoch 69, MSE, Train: 17.020 Valid: 17.005\n",
      "Time elapsed: 0:05:06.803605\n",
      "Epoch 70, MSE, Train: 17.455 Valid: 16.796\n",
      "Time elapsed: 0:05:11.294670\n",
      "Epoch 71, MSE, Train: 17.147 Valid: 16.597\n",
      "Time elapsed: 0:05:15.660660\n",
      "Epoch 72, MSE, Train: 17.024 Valid: 18.017\n",
      "Time elapsed: 0:05:20.008638\n",
      "Epoch 73, MSE, Train: 17.161 Valid: 16.909\n",
      "Time elapsed: 0:05:24.349632\n",
      "Epoch 74, MSE, Train: 16.826 Valid: 16.702\n",
      "Time elapsed: 0:05:28.811644\n",
      "Epoch 75, MSE, Train: 17.016 Valid: 16.494\n",
      "Time elapsed: 0:05:33.131615\n",
      "Epoch 76, MSE, Train: 17.255 Valid: 16.953\n",
      "Time elapsed: 0:05:37.497615\n",
      "Epoch 77, MSE, Train: 17.145 Valid: 17.030\n",
      "Time elapsed: 0:05:41.835598\n",
      "Epoch 78, MSE, Train: 16.915 Valid: 16.608\n",
      "Time elapsed: 0:05:46.208591\n",
      "Epoch 79, MSE, Train: 16.866 Valid: 16.800\n",
      "Time elapsed: 0:05:50.533572\n",
      "Epoch 80, MSE, Train: 16.951 Valid: 18.197\n",
      "Time elapsed: 0:05:54.860554\n",
      "Epoch 81, MSE, Train: 16.981 Valid: 16.689\n",
      "Time elapsed: 0:05:59.190536\n",
      "Epoch 82, MSE, Train: 16.909 Valid: 17.679\n",
      "Time elapsed: 0:06:03.514517\n",
      "Epoch 83, MSE, Train: 17.336 Valid: 17.011\n",
      "Time elapsed: 0:06:07.847491\n",
      "Epoch 84, MSE, Train: 16.903 Valid: 16.542\n",
      "Time elapsed: 0:06:12.187485\n",
      "Epoch 85, MSE, Train: 16.997 Valid: 16.802\n",
      "Time elapsed: 0:06:16.517467\n",
      "Epoch 86, MSE, Train: 16.759 Valid: 17.479\n",
      "Time elapsed: 0:06:20.840448\n",
      "Epoch 87, MSE, Train: 16.929 Valid: 16.691\n",
      "Time elapsed: 0:06:25.179432\n",
      "Epoch 88, MSE, Train: 16.797 Valid: 17.196\n",
      "Time elapsed: 0:06:29.521408\n",
      "Epoch 89, MSE, Train: 17.184 Valid: 17.044\n",
      "Time elapsed: 0:06:34.318506\n",
      "Epoch 90, MSE, Train: 17.057 Valid: 17.043\n",
      "Time elapsed: 0:06:38.791520\n",
      "Epoch 91, MSE, Train: 16.732 Valid: 17.472\n",
      "Time elapsed: 0:06:43.469582\n",
      "Epoch 92, MSE, Train: 16.801 Valid: 16.560\n",
      "Time elapsed: 0:06:47.863579\n",
      "Epoch 93, MSE, Train: 16.978 Valid: 16.758\n",
      "Time elapsed: 0:06:52.206564\n",
      "Epoch 94, MSE, Train: 16.887 Valid: 17.121\n",
      "Time elapsed: 0:06:56.589558\n",
      "Epoch 95, MSE, Train: 16.966 Valid: 17.157\n",
      "Time elapsed: 0:07:00.963541\n",
      "Epoch 96, MSE, Train: 16.842 Valid: 17.074\n",
      "Time elapsed: 0:07:05.324540\n",
      "Epoch 97, MSE, Train: 16.757 Valid: 17.018\n",
      "Time elapsed: 0:07:09.672518\n",
      "Epoch 98, MSE, Train: 16.885 Valid: 16.847\n",
      "Time elapsed: 0:07:14.010502\n",
      "Epoch 99, MSE, Train: 16.726 Valid: 16.902\n",
      "Time elapsed: 0:07:18.359498\n",
      "Epoch 100, MSE, Train: 16.884 Valid: 17.325\n",
      "Time elapsed: 0:07:22.713485\n",
      "Epoch 101, MSE, Train: 16.785 Valid: 17.134\n",
      "Time elapsed: 0:07:27.069464\n",
      "Epoch 102, MSE, Train: 16.696 Valid: 17.399\n",
      "Time elapsed: 0:07:31.389444\n",
      "Epoch 103, MSE, Train: 16.813 Valid: 16.617\n",
      "Time elapsed: 0:07:35.726428\n",
      "Epoch 104, MSE, Train: 16.775 Valid: 16.798\n",
      "Time elapsed: 0:07:40.047410\n",
      "Epoch 105, MSE, Train: 16.736 Valid: 16.553\n",
      "Time elapsed: 0:07:44.386402\n",
      "Epoch 106, MSE, Train: 16.861 Valid: 17.184\n",
      "Time elapsed: 0:07:48.906459\n",
      "Epoch 107, MSE, Train: 16.642 Valid: 16.359\n",
      "Time elapsed: 0:07:53.254445\n",
      "Epoch 108, MSE, Train: 16.835 Valid: 17.102\n",
      "Time elapsed: 0:07:57.625437\n",
      "Epoch 109, MSE, Train: 16.648 Valid: 16.611\n",
      "Time elapsed: 0:08:01.962421\n",
      "Epoch 110, MSE, Train: 16.790 Valid: 17.113\n",
      "Time elapsed: 0:08:06.314400\n",
      "Epoch 111, MSE, Train: 16.786 Valid: 18.669\n",
      "Time elapsed: 0:08:10.639390\n",
      "Epoch 112, MSE, Train: 16.671 Valid: 17.436\n",
      "Time elapsed: 0:08:14.995378\n",
      "Epoch 113, MSE, Train: 16.699 Valid: 16.873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:08:19.343355\n",
      "Epoch 114, MSE, Train: 16.817 Valid: 16.782\n",
      "Time elapsed: 0:08:23.709355\n",
      "Epoch 115, MSE, Train: 17.428 Valid: 17.194\n",
      "Time elapsed: 0:08:28.069344\n",
      "Epoch 116, MSE, Train: 16.644 Valid: 17.266\n",
      "Time elapsed: 0:08:32.391325\n",
      "Epoch 117, MSE, Train: 16.735 Valid: 17.589\n",
      "Time elapsed: 0:08:36.739302\n",
      "Epoch 118, MSE, Train: 16.608 Valid: 16.693\n",
      "Time elapsed: 0:08:41.112303\n",
      "Epoch 119, MSE, Train: 16.630 Valid: 16.592\n",
      "Time elapsed: 0:08:45.466291\n",
      "Epoch 120, MSE, Train: 16.654 Valid: 17.205\n",
      "Time elapsed: 0:08:49.809276\n",
      "Epoch 121, MSE, Train: 17.042 Valid: 16.812\n",
      "Time elapsed: 0:08:54.148261\n",
      "Epoch 122, MSE, Train: 16.786 Valid: 16.889\n",
      "Time elapsed: 0:08:58.470232\n",
      "Epoch 123, MSE, Train: 16.667 Valid: 17.514\n",
      "Time elapsed: 0:09:02.799223\n",
      "Epoch 124, MSE, Train: 16.788 Valid: 17.940\n",
      "Time elapsed: 0:09:07.136207\n",
      "Epoch 125, MSE, Train: 16.677 Valid: 16.905\n",
      "Time elapsed: 0:09:11.468190\n",
      "Epoch 126, MSE, Train: 16.730 Valid: 16.606\n",
      "Time elapsed: 0:09:15.799173\n",
      "Epoch 127, MSE, Train: 16.559 Valid: 17.144\n",
      "Time elapsed: 0:09:20.119153\n",
      "Epoch 128, MSE, Train: 16.415 Valid: 16.841\n",
      "Time elapsed: 0:09:24.457137\n",
      "Epoch 129, MSE, Train: 16.669 Valid: 17.209\n",
      "Time elapsed: 0:09:28.783110\n",
      "Epoch 130, MSE, Train: 16.691 Valid: 16.564\n",
      "Time elapsed: 0:09:33.135106\n",
      "Epoch 131, MSE, Train: 16.580 Valid: 16.766\n",
      "Time elapsed: 0:09:37.483092\n",
      "Epoch 132, MSE, Train: 16.616 Valid: 18.157\n",
      "Time elapsed: 0:09:41.824067\n",
      "Epoch 133, MSE, Train: 16.538 Valid: 16.653\n",
      "Time elapsed: 0:09:46.158061\n",
      "Epoch 134, MSE, Train: 16.568 Valid: 16.690\n",
      "Time elapsed: 0:09:50.488033\n",
      "Epoch 135, MSE, Train: 16.464 Valid: 16.682\n",
      "Time elapsed: 0:09:54.832028\n",
      "Epoch 136, MSE, Train: 16.895 Valid: 17.305\n",
      "Time elapsed: 0:09:59.176013\n",
      "Epoch 137, MSE, Train: 17.097 Valid: 16.854\n",
      "Time elapsed: 0:10:03.534002\n",
      "Epoch 138, MSE, Train: 16.496 Valid: 17.096\n",
      "Time elapsed: 0:10:07.885990\n",
      "Epoch 139, MSE, Train: 16.491 Valid: 17.165\n",
      "Time elapsed: 0:10:12.217964\n",
      "Epoch 140, MSE, Train: 16.549 Valid: 16.895\n",
      "Time elapsed: 0:10:16.560959\n",
      "Epoch 141, MSE, Train: 16.510 Valid: 16.969\n",
      "Time elapsed: 0:10:20.904943\n",
      "Epoch 142, MSE, Train: 16.524 Valid: 17.618\n",
      "Time elapsed: 0:10:25.239927\n",
      "Epoch 143, MSE, Train: 16.611 Valid: 17.281\n",
      "Time elapsed: 0:10:29.574910\n",
      "Epoch 144, MSE, Train: 16.650 Valid: 17.345\n",
      "Time elapsed: 0:10:33.912894\n",
      "Epoch 145, MSE, Train: 16.508 Valid: 17.138\n",
      "Time elapsed: 0:10:38.235875\n",
      "Epoch 146, MSE, Train: 16.645 Valid: 16.725\n",
      "Time elapsed: 0:10:42.569849\n",
      "Epoch 147, MSE, Train: 16.663 Valid: 16.910\n",
      "Time elapsed: 0:10:46.904842\n",
      "Epoch 148, MSE, Train: 16.457 Valid: 16.854\n",
      "Time elapsed: 0:10:51.255829\n",
      "Epoch 149, MSE, Train: 16.783 Valid: 17.432\n",
      "Time elapsed: 0:10:55.589803\n",
      "Epoch 150, MSE, Train: 16.472 Valid: 17.884\n",
      "---Finished training results---\n",
      "Time elapsed: 0:10:55.589803\n",
      "---Training for quadratic deep hedging end---\n",
      "INFO:tensorflow:Restoring parameters from /Users/alexa/Github files/Long-term hedging paper example/Models/Two_opts_MSE/models.ckpt\n",
      "-------------------------------\n",
      "Results on the TRAIN SET:\n",
      "Model was trained with the loss function: MSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -0.2230786875647204\n",
      "CVaR_95: 10.3362, CVaR_99: 19.0941\n",
      "VaR_95: 5.7018, VaR_99: 12.5582\n",
      "MSE: 16.1968, RMSE: 4.0245\n",
      "Semi-MSE: 8.4363, Semi-RMSE: 2.9045\n",
      "Skew: 1.3674\n",
      "-------------------------------\n",
      "Results on the VALID SET:\n",
      "Model was trained with the loss function: MSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -0.20238574699337783\n",
      "CVaR_95: 10.5158, CVaR_99: 19.5194\n",
      "VaR_95: 5.7463, VaR_99: 12.9077\n",
      "MSE: 16.3590, RMSE: 4.0446\n",
      "Semi-MSE: 8.7147, Semi-RMSE: 2.9521\n",
      "Skew: 1.4718\n",
      "-------------------------------\n",
      "Results on the TEST SET:\n",
      "Model was trained with the loss function: MSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -0.19743046339546935\n",
      "CVaR_95: 10.7390, CVaR_99: 20.5360\n",
      "VaR_95: 5.7671, VaR_99: 12.9952\n",
      "MSE: 17.3569, RMSE: 4.1662\n",
      "Semi-MSE: 9.6789, Semi-RMSE: 3.1111\n",
      "Skew: 2.6547\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "END OF QUADRATIC DEEP HEDGING\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "Hyperparameters: learning rate=0.0017, LSTM cells=2, neurons=24\n",
      "---Training for semi-quadratic deep hedging start---\n",
      "Time elapsed: 0:00:05.222179\n",
      "Epoch 1, SMSE, Train: 18.389 Valid: 7.854\n",
      "Time elapsed: 0:00:09.742210\n",
      "Epoch 2, SMSE, Train: 6.039 Valid: 4.587\n",
      "Time elapsed: 0:00:14.272238\n",
      "Epoch 3, SMSE, Train: 3.753 Valid: 3.130\n",
      "Time elapsed: 0:00:18.799265\n",
      "Epoch 4, SMSE, Train: 2.979 Valid: 3.104\n",
      "Time elapsed: 0:00:23.346393\n",
      "Epoch 5, SMSE, Train: 2.756 Valid: 2.746\n",
      "Time elapsed: 0:00:27.880422\n",
      "Epoch 6, SMSE, Train: 2.570 Valid: 2.374\n",
      "Time elapsed: 0:00:32.271419\n",
      "Epoch 7, SMSE, Train: 2.416 Valid: 2.413\n",
      "Time elapsed: 0:00:36.774440\n",
      "Epoch 8, SMSE, Train: 2.354 Valid: 2.284\n",
      "Time elapsed: 0:00:41.311469\n",
      "Epoch 9, SMSE, Train: 2.312 Valid: 2.151\n",
      "Time elapsed: 0:00:45.713467\n",
      "Epoch 10, SMSE, Train: 2.371 Valid: 3.174\n",
      "Time elapsed: 0:00:50.250489\n",
      "Epoch 11, SMSE, Train: 2.194 Valid: 2.090\n",
      "Time elapsed: 0:00:54.667499\n",
      "Epoch 12, SMSE, Train: 2.115 Valid: 2.262\n",
      "Time elapsed: 0:00:59.195526\n",
      "Epoch 13, SMSE, Train: 2.208 Valid: 2.055\n",
      "Time elapsed: 0:01:03.574521\n",
      "Epoch 14, SMSE, Train: 2.265 Valid: 2.318\n",
      "Time elapsed: 0:01:07.957505\n",
      "Epoch 15, SMSE, Train: 2.072 Valid: 2.103\n",
      "Time elapsed: 0:01:12.344509\n",
      "Epoch 16, SMSE, Train: 2.038 Valid: 2.118\n",
      "Time elapsed: 0:01:16.895542\n",
      "Epoch 17, SMSE, Train: 2.073 Valid: 2.014\n",
      "Time elapsed: 0:01:21.282529\n",
      "Epoch 18, SMSE, Train: 2.110 Valid: 2.099\n",
      "Time elapsed: 0:01:25.847573\n",
      "Epoch 19, SMSE, Train: 2.014 Valid: 1.985\n",
      "Time elapsed: 0:01:30.370599\n",
      "Epoch 20, SMSE, Train: 2.072 Valid: 1.975\n",
      "Time elapsed: 0:01:34.743582\n",
      "Epoch 21, SMSE, Train: 1.941 Valid: 2.101\n",
      "Time elapsed: 0:01:39.121584\n",
      "Epoch 22, SMSE, Train: 2.029 Valid: 2.223\n",
      "Time elapsed: 0:01:43.667616\n",
      "Epoch 23, SMSE, Train: 2.027 Valid: 1.964\n",
      "Time elapsed: 0:01:48.211647\n",
      "Epoch 24, SMSE, Train: 2.002 Valid: 1.919\n",
      "Time elapsed: 0:01:52.586631\n",
      "Epoch 25, SMSE, Train: 1.942 Valid: 1.969\n",
      "Time elapsed: 0:01:56.973627\n",
      "Epoch 26, SMSE, Train: 1.923 Valid: 1.988\n",
      "Time elapsed: 0:02:01.369632\n",
      "Epoch 27, SMSE, Train: 1.951 Valid: 2.017\n",
      "Time elapsed: 0:02:05.775631\n",
      "Epoch 28, SMSE, Train: 1.927 Valid: 1.941\n",
      "Time elapsed: 0:02:10.181623\n",
      "Epoch 29, SMSE, Train: 1.964 Valid: 2.471\n",
      "Time elapsed: 0:02:14.565626\n",
      "Epoch 30, SMSE, Train: 1.944 Valid: 1.989\n",
      "Time elapsed: 0:02:18.974626\n",
      "Epoch 31, SMSE, Train: 1.904 Valid: 1.966\n",
      "Time elapsed: 0:02:23.494651\n",
      "Epoch 32, SMSE, Train: 1.883 Valid: 1.888\n",
      "Time elapsed: 0:02:27.886648\n",
      "Epoch 33, SMSE, Train: 1.872 Valid: 2.585\n",
      "Time elapsed: 0:02:32.282645\n",
      "Epoch 34, SMSE, Train: 1.937 Valid: 2.030\n",
      "Time elapsed: 0:02:36.682636\n",
      "Epoch 35, SMSE, Train: 1.900 Valid: 1.958\n",
      "Time elapsed: 0:02:41.081641\n",
      "Epoch 36, SMSE, Train: 1.888 Valid: 2.016\n",
      "Time elapsed: 0:02:45.482640\n",
      "Epoch 37, SMSE, Train: 1.888 Valid: 1.993\n",
      "Time elapsed: 0:02:49.862633\n",
      "Epoch 38, SMSE, Train: 1.880 Valid: 1.925\n",
      "Time elapsed: 0:02:54.417667\n",
      "Epoch 39, SMSE, Train: 1.864 Valid: 1.851\n",
      "Time elapsed: 0:02:58.820666\n",
      "Epoch 40, SMSE, Train: 1.928 Valid: 1.949\n",
      "Time elapsed: 0:03:03.188657\n",
      "Epoch 41, SMSE, Train: 1.818 Valid: 1.989\n",
      "Time elapsed: 0:03:07.584654\n",
      "Epoch 42, SMSE, Train: 1.819 Valid: 1.969\n",
      "Time elapsed: 0:03:11.966649\n",
      "Epoch 43, SMSE, Train: 1.782 Valid: 1.889\n",
      "Time elapsed: 0:03:16.335631\n",
      "Epoch 44, SMSE, Train: 1.816 Valid: 1.919\n",
      "Time elapsed: 0:03:20.706631\n",
      "Epoch 45, SMSE, Train: 1.832 Valid: 1.893\n",
      "Time elapsed: 0:03:25.079624\n",
      "Epoch 46, SMSE, Train: 1.819 Valid: 1.884\n",
      "Time elapsed: 0:03:29.615652\n",
      "Epoch 47, SMSE, Train: 1.802 Valid: 1.839\n",
      "Time elapsed: 0:03:33.967631\n",
      "Epoch 48, SMSE, Train: 1.760 Valid: 1.909\n",
      "Time elapsed: 0:03:38.369638\n",
      "Epoch 49, SMSE, Train: 1.788 Valid: 1.853\n",
      "Time elapsed: 0:03:42.885663\n",
      "Epoch 50, SMSE, Train: 1.775 Valid: 1.835\n",
      "Time elapsed: 0:03:47.258647\n",
      "Epoch 51, SMSE, Train: 1.788 Valid: 2.012\n",
      "Time elapsed: 0:03:51.784682\n",
      "Epoch 52, SMSE, Train: 1.748 Valid: 1.801\n",
      "Time elapsed: 0:03:56.193682\n",
      "Epoch 53, SMSE, Train: 1.800 Valid: 1.981\n",
      "Time elapsed: 0:04:00.577668\n",
      "Epoch 54, SMSE, Train: 1.798 Valid: 1.923\n",
      "Time elapsed: 0:04:05.112720\n",
      "Epoch 55, SMSE, Train: 1.742 Valid: 1.790\n",
      "Time elapsed: 0:04:09.491713\n",
      "Epoch 56, SMSE, Train: 1.823 Valid: 1.897\n",
      "Time elapsed: 0:04:13.849703\n",
      "Epoch 57, SMSE, Train: 1.726 Valid: 1.804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:04:18.239719\n",
      "Epoch 58, SMSE, Train: 1.738 Valid: 1.831\n",
      "Time elapsed: 0:04:22.616692\n",
      "Epoch 59, SMSE, Train: 1.749 Valid: 1.907\n",
      "Time elapsed: 0:04:27.004686\n",
      "Epoch 60, SMSE, Train: 1.772 Valid: 1.823\n",
      "Time elapsed: 0:04:31.402684\n",
      "Epoch 61, SMSE, Train: 1.715 Valid: 1.921\n",
      "Time elapsed: 0:04:35.765674\n",
      "Epoch 62, SMSE, Train: 1.724 Valid: 1.810\n",
      "Time elapsed: 0:04:40.145667\n",
      "Epoch 63, SMSE, Train: 1.734 Valid: 1.963\n",
      "Time elapsed: 0:04:44.531662\n",
      "Epoch 64, SMSE, Train: 1.739 Valid: 1.878\n",
      "Time elapsed: 0:04:48.931661\n",
      "Epoch 65, SMSE, Train: 1.713 Valid: 1.825\n",
      "Time elapsed: 0:04:53.322657\n",
      "Epoch 66, SMSE, Train: 1.712 Valid: 1.871\n",
      "Time elapsed: 0:04:57.877764\n",
      "Epoch 67, SMSE, Train: 1.709 Valid: 1.788\n",
      "Time elapsed: 0:05:02.233753\n",
      "Epoch 68, SMSE, Train: 1.697 Valid: 1.858\n",
      "Time elapsed: 0:05:06.616739\n",
      "Epoch 69, SMSE, Train: 1.734 Valid: 1.903\n",
      "Time elapsed: 0:05:11.016745\n",
      "Epoch 70, SMSE, Train: 1.679 Valid: 2.003\n",
      "Time elapsed: 0:05:15.581773\n",
      "Epoch 71, SMSE, Train: 1.696 Valid: 1.748\n",
      "Time elapsed: 0:05:19.983771\n",
      "Epoch 72, SMSE, Train: 1.664 Valid: 1.833\n",
      "Time elapsed: 0:05:24.374776\n",
      "Epoch 73, SMSE, Train: 1.690 Valid: 1.852\n",
      "Time elapsed: 0:05:28.751759\n",
      "Epoch 74, SMSE, Train: 1.683 Valid: 2.127\n",
      "Time elapsed: 0:05:33.141765\n",
      "Epoch 75, SMSE, Train: 1.684 Valid: 1.812\n",
      "Time elapsed: 0:05:37.536762\n",
      "Epoch 76, SMSE, Train: 1.669 Valid: 1.899\n",
      "Time elapsed: 0:05:41.935760\n",
      "Epoch 77, SMSE, Train: 1.659 Valid: 1.787\n",
      "Time elapsed: 0:05:46.337759\n",
      "Epoch 78, SMSE, Train: 1.686 Valid: 1.848\n",
      "Time elapsed: 0:05:50.748759\n",
      "Epoch 79, SMSE, Train: 1.667 Valid: 1.875\n",
      "Time elapsed: 0:05:55.115741\n",
      "Epoch 80, SMSE, Train: 1.675 Valid: 1.844\n",
      "Time elapsed: 0:05:59.532752\n",
      "Epoch 81, SMSE, Train: 1.653 Valid: 1.828\n",
      "Time elapsed: 0:06:03.915747\n",
      "Epoch 82, SMSE, Train: 1.649 Valid: 1.844\n",
      "Time elapsed: 0:06:08.297732\n",
      "Epoch 83, SMSE, Train: 1.656 Valid: 1.773\n",
      "Time elapsed: 0:06:12.675725\n",
      "Epoch 84, SMSE, Train: 1.664 Valid: 1.824\n",
      "Time elapsed: 0:06:17.066730\n",
      "Epoch 85, SMSE, Train: 1.624 Valid: 1.851\n",
      "Time elapsed: 0:06:21.449725\n",
      "Epoch 86, SMSE, Train: 1.633 Valid: 1.872\n",
      "Time elapsed: 0:06:25.848723\n",
      "Epoch 87, SMSE, Train: 1.630 Valid: 1.914\n",
      "Time elapsed: 0:06:30.236718\n",
      "Epoch 88, SMSE, Train: 1.650 Valid: 1.823\n",
      "Time elapsed: 0:06:34.634716\n",
      "Epoch 89, SMSE, Train: 1.616 Valid: 1.843\n",
      "Time elapsed: 0:06:39.023712\n",
      "Epoch 90, SMSE, Train: 1.599 Valid: 1.941\n",
      "Time elapsed: 0:06:43.415708\n",
      "Epoch 91, SMSE, Train: 1.653 Valid: 1.789\n",
      "Time elapsed: 0:06:47.787700\n",
      "Epoch 92, SMSE, Train: 1.592 Valid: 1.952\n",
      "Time elapsed: 0:06:52.224707\n",
      "Epoch 93, SMSE, Train: 1.581 Valid: 1.944\n",
      "Time elapsed: 0:06:56.606701\n",
      "Epoch 94, SMSE, Train: 1.593 Valid: 1.865\n",
      "Time elapsed: 0:07:01.002699\n",
      "Epoch 95, SMSE, Train: 1.619 Valid: 2.067\n",
      "Time elapsed: 0:07:05.400697\n",
      "Epoch 96, SMSE, Train: 1.612 Valid: 1.846\n",
      "Time elapsed: 0:07:09.813688\n",
      "Epoch 97, SMSE, Train: 1.586 Valid: 1.942\n",
      "Time elapsed: 0:07:14.180688\n",
      "Epoch 98, SMSE, Train: 1.633 Valid: 2.236\n",
      "Time elapsed: 0:07:18.571675\n",
      "Epoch 99, SMSE, Train: 1.595 Valid: 1.789\n",
      "Time elapsed: 0:07:22.979684\n",
      "Epoch 100, SMSE, Train: 1.576 Valid: 1.947\n",
      "Time elapsed: 0:07:27.379673\n",
      "Epoch 101, SMSE, Train: 1.596 Valid: 2.100\n",
      "Time elapsed: 0:07:31.776680\n",
      "Epoch 102, SMSE, Train: 1.574 Valid: 2.121\n",
      "Time elapsed: 0:07:36.178679\n",
      "Epoch 103, SMSE, Train: 1.576 Valid: 1.918\n",
      "Time elapsed: 0:07:40.562664\n",
      "Epoch 104, SMSE, Train: 1.573 Valid: 1.909\n",
      "Time elapsed: 0:07:44.958671\n",
      "Epoch 105, SMSE, Train: 1.539 Valid: 1.847\n",
      "Time elapsed: 0:07:49.342665\n",
      "Epoch 106, SMSE, Train: 1.539 Valid: 1.877\n",
      "Time elapsed: 0:07:53.748655\n",
      "Epoch 107, SMSE, Train: 1.521 Valid: 1.860\n",
      "Time elapsed: 0:07:58.143653\n",
      "Epoch 108, SMSE, Train: 1.522 Valid: 1.814\n",
      "Time elapsed: 0:08:02.528657\n",
      "Epoch 109, SMSE, Train: 1.507 Valid: 1.998\n",
      "Time elapsed: 0:08:06.899649\n",
      "Epoch 110, SMSE, Train: 1.535 Valid: 2.069\n",
      "Time elapsed: 0:08:11.290645\n",
      "Epoch 111, SMSE, Train: 1.558 Valid: 2.021\n",
      "Time elapsed: 0:08:15.699645\n",
      "Epoch 112, SMSE, Train: 1.623 Valid: 6.481\n",
      "Time elapsed: 0:08:20.097643\n",
      "Epoch 113, SMSE, Train: 2.404 Valid: 1.882\n",
      "Time elapsed: 0:08:24.466634\n",
      "Epoch 114, SMSE, Train: 1.710 Valid: 1.808\n",
      "Time elapsed: 0:08:28.867632\n",
      "Epoch 115, SMSE, Train: 1.583 Valid: 1.826\n",
      "Time elapsed: 0:08:33.246626\n",
      "Epoch 116, SMSE, Train: 1.500 Valid: 1.911\n",
      "Time elapsed: 0:08:37.635622\n",
      "Epoch 117, SMSE, Train: 1.491 Valid: 1.964\n",
      "Time elapsed: 0:08:42.049614\n",
      "Epoch 118, SMSE, Train: 1.490 Valid: 2.075\n",
      "Time elapsed: 0:08:46.445612\n",
      "Epoch 119, SMSE, Train: 1.539 Valid: 2.014\n",
      "Time elapsed: 0:08:50.813612\n",
      "Epoch 120, SMSE, Train: 1.454 Valid: 2.117\n",
      "Time elapsed: 0:08:55.206599\n",
      "Epoch 121, SMSE, Train: 1.500 Valid: 2.137\n",
      "Time elapsed: 0:08:59.657618\n",
      "Epoch 122, SMSE, Train: 1.477 Valid: 2.033\n",
      "Time elapsed: 0:09:04.062617\n",
      "Epoch 123, SMSE, Train: 1.461 Valid: 2.187\n",
      "Time elapsed: 0:09:08.451613\n",
      "Epoch 124, SMSE, Train: 1.769 Valid: 1.852\n",
      "Time elapsed: 0:09:12.851611\n",
      "Epoch 125, SMSE, Train: 1.483 Valid: 2.266\n",
      "Time elapsed: 0:09:17.243608\n",
      "Epoch 126, SMSE, Train: 1.421 Valid: 2.284\n",
      "Time elapsed: 0:09:21.666611\n",
      "Epoch 127, SMSE, Train: 1.431 Valid: 2.041\n",
      "Time elapsed: 0:09:26.047605\n",
      "Epoch 128, SMSE, Train: 1.463 Valid: 2.081\n",
      "Time elapsed: 0:09:30.443594\n",
      "Epoch 129, SMSE, Train: 1.448 Valid: 2.576\n",
      "Time elapsed: 0:09:34.847593\n",
      "Epoch 130, SMSE, Train: 1.487 Valid: 2.123\n",
      "Time elapsed: 0:09:39.239598\n",
      "Epoch 131, SMSE, Train: 1.478 Valid: 2.417\n",
      "Time elapsed: 0:09:43.650599\n",
      "Epoch 132, SMSE, Train: 1.441 Valid: 2.429\n",
      "Time elapsed: 0:09:48.075603\n",
      "Epoch 133, SMSE, Train: 1.709 Valid: 1.871\n",
      "Time elapsed: 0:09:52.471591\n",
      "Epoch 134, SMSE, Train: 1.444 Valid: 2.540\n",
      "Time elapsed: 0:09:56.877591\n",
      "Epoch 135, SMSE, Train: 1.402 Valid: 2.386\n",
      "Time elapsed: 0:10:01.274597\n",
      "Epoch 136, SMSE, Train: 1.701 Valid: 2.125\n",
      "Time elapsed: 0:10:05.690599\n",
      "Epoch 137, SMSE, Train: 1.369 Valid: 2.210\n",
      "Time elapsed: 0:10:10.072593\n",
      "Epoch 138, SMSE, Train: 1.382 Valid: 2.255\n",
      "Time elapsed: 0:10:14.459579\n",
      "Epoch 139, SMSE, Train: 1.370 Valid: 2.659\n",
      "Time elapsed: 0:10:18.837582\n",
      "Epoch 140, SMSE, Train: 2.714 Valid: 2.117\n",
      "Time elapsed: 0:10:23.236580\n",
      "Epoch 141, SMSE, Train: 1.848 Valid: 1.849\n",
      "Time elapsed: 0:10:27.646572\n",
      "Epoch 142, SMSE, Train: 1.760 Valid: 1.947\n",
      "Time elapsed: 0:10:32.068575\n",
      "Epoch 143, SMSE, Train: 1.584 Valid: 2.068\n",
      "Time elapsed: 0:10:36.449578\n",
      "Epoch 144, SMSE, Train: 1.507 Valid: 2.266\n",
      "Time elapsed: 0:10:40.836573\n",
      "Epoch 145, SMSE, Train: 1.489 Valid: 2.154\n",
      "Time elapsed: 0:10:45.220568\n",
      "Epoch 146, SMSE, Train: 1.414 Valid: 2.616\n",
      "Time elapsed: 0:10:49.629559\n",
      "Epoch 147, SMSE, Train: 1.363 Valid: 2.383\n",
      "Time elapsed: 0:10:54.009561\n",
      "Epoch 148, SMSE, Train: 1.354 Valid: 2.285\n",
      "Time elapsed: 0:10:58.400548\n",
      "Epoch 149, SMSE, Train: 1.560 Valid: 2.823\n",
      "Time elapsed: 0:11:02.809558\n",
      "Epoch 150, SMSE, Train: 2.186 Valid: 1.815\n",
      "---Finished training results---\n",
      "Time elapsed: 0:11:02.810558\n",
      "---Training for semi-quadratic deep hedging end---\n",
      "INFO:tensorflow:Restoring parameters from /Users/alexa/Github files/Long-term hedging paper example/Models/Two_opts_SMSE/models.ckpt\n",
      "-------------------------------\n",
      "Results on the TRAIN SET:\n",
      "Model was trained with the loss function: SMSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -5.066555755826894\n",
      "CVaR_95: 4.4140, CVaR_99: 9.4591\n",
      "VaR_95: 1.5873, VaR_99: 6.1112\n",
      "MSE: 93.4725, RMSE: 9.6681\n",
      "Semi-MSE: 1.5738, Semi-RMSE: 1.2545\n",
      "Skew: -2.4241\n",
      "-------------------------------\n",
      "Results on the VALID SET:\n",
      "Model was trained with the loss function: SMSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -5.027044708308892\n",
      "CVaR_95: 4.5931, CVaR_99: 9.9228\n",
      "VaR_95: 1.6568, VaR_99: 6.2840\n",
      "MSE: 92.0152, RMSE: 9.5925\n",
      "Semi-MSE: 1.7482, Semi-RMSE: 1.3222\n",
      "Skew: -2.3478\n",
      "-------------------------------\n",
      "Results on the TEST SET:\n",
      "Model was trained with the loss function: SMSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -5.011424139913897\n",
      "CVaR_95: 4.6513, CVaR_99: 10.1585\n",
      "VaR_95: 1.6701, VaR_99: 6.3102\n",
      "MSE: 91.2617, RMSE: 9.5531\n",
      "Semi-MSE: 1.8585, Semi-RMSE: 1.3633\n",
      "Skew: -2.2937\n",
      " ----------------------- \n",
      "Portfolio total exposure - QDH\n",
      "-0.11928877400767436\n",
      " ----------------------- \n",
      "Portfolio total exposure - SQDH\n",
      "-0.07043991533469794\n"
     ]
    }
   ],
   "source": [
    "nbs_assets          = 2\n",
    "hedging_instruments = \"ATM call and put\" \n",
    "freq_obs            = \"Yearly\"\n",
    "\n",
    "# A) Part 1: MSE\n",
    "loss_type  = 'MSE'\n",
    "model_name = 'Two_opts_MSE'\n",
    "lr         = 0.01   # learning rate of the Adam optimizer\n",
    "print(\"Hyperparameters: learning rate=%.4f, LSTM cells=%d, neurons=%d\" %(lr, hidden_layers, nbs_units))\n",
    "LSTM_underlying = DeepAgent(train_two_opts_input.shape[0], batch_size, train_two_opts_input.shape[2], \n",
    "        loss_type, nbs_assets, hidden_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments, \n",
    "        freq_obs, name = model_name)\n",
    "    \n",
    "# Start training \n",
    "start = dt.datetime.now()\n",
    "print('---Training for quadratic deep hedging start---')\n",
    "with tf.Session() as sess:           \n",
    "    loss_epoch = LSTM_underlying.training(train_two_opts_input, V_0_batch, disc_batch_year, valid_two_opts_input, \n",
    "                                          sess, epochs)\n",
    "    print('---Training for quadratic deep hedging end---')\n",
    "    \n",
    "# Compute measured risk exposure on train, valid and test set with the optimized LSTM\n",
    "model_predict = DeepAgent(test_two_opts_input.shape[0], batch_size, test_two_opts_input.shape[2], loss_type, \n",
    "        nbs_assets, hidden_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments, \n",
    "        freq_obs, name = model_name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Load the saved model\n",
    "    model_predict.restore(sess, r\"/Users/alexa/Github files/Long-term hedging paper example/Models/%s/models.ckpt\" % model_name)\n",
    "\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the TRAIN SET:\")\n",
    "    # Compute hedging strategies on the training set\n",
    "    deltas = model_predict.predict(train_two_opts_input, V_0_batch, disc_batch_year, sess, loss_type)    \n",
    "    hedging_stats(deltas, train_two_opts_input, disc_train_year, V_0_train, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the VALID SET:\")\n",
    "    # Compute hedging strategies on the valid set\n",
    "    deltas = model_predict.predict(valid_two_opts_input, V_0_batch, disc_batch_year, sess, loss_type)\n",
    "    hedging_stats(deltas, valid_two_opts_input, disc_valid_year, V_0_valid, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the TEST SET:\")\n",
    "    # Compute hedging strategies on the test set\n",
    "    deltas_MSE = model_predict.predict(test_two_opts_input, V_0_batch, disc_batch_year, sess, loss_type)\n",
    "    hedging_stats(deltas_MSE, test_two_opts_input, disc_test_year, V_0_test, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"END OF QUADRATIC DEEP HEDGING\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "# B) Part 2: SMSE\n",
    "loss_type  = 'SMSE'\n",
    "model_name = 'Two_opts_SMSE'\n",
    "lr         = 0.01/6   # learning rate of the Adam optimizer\n",
    "print(\"Hyperparameters: learning rate=%.4f, LSTM cells=%d, neurons=%d\" %(lr, hidden_layers, nbs_units))\n",
    "LSTM_underlying = DeepAgent(train_two_opts_input.shape[0], batch_size, train_two_opts_input.shape[2], \n",
    "        loss_type, nbs_assets, hidden_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments, \n",
    "        freq_obs, name = model_name)\n",
    "    \n",
    "# Start training \n",
    "start = dt.datetime.now()\n",
    "print('---Training for semi-quadratic deep hedging start---')\n",
    "with tf.Session() as sess:           \n",
    "    loss_epoch = LSTM_underlying.training(train_two_opts_input, V_0_batch, disc_batch_year, valid_two_opts_input, \n",
    "                                          sess, epochs)\n",
    "    print('---Training for semi-quadratic deep hedging end---')\n",
    "    \n",
    "# Compute measured risk exposure on train, valid and test set with the optimized LSTM\n",
    "model_predict = DeepAgent(test_two_opts_input.shape[0], batch_size, test_two_opts_input.shape[2], loss_type, \n",
    "        nbs_assets, hidden_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments, \n",
    "        freq_obs, name = model_name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Load the saved model\n",
    "    model_predict.restore(sess, r\"/Users/alexa/Github files/Long-term hedging paper example/Models/%s/models.ckpt\" % model_name)\n",
    "\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the TRAIN SET:\")\n",
    "    # Compute hedging strategies on the training set\n",
    "    deltas = model_predict.predict(train_two_opts_input, V_0_batch, disc_batch_year, sess, loss_type)    \n",
    "    hedging_stats(deltas, train_two_opts_input, disc_train_year, V_0_train, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the VALID SET:\")\n",
    "    # Compute hedging strategies on the valid set\n",
    "    deltas = model_predict.predict(valid_two_opts_input, V_0_batch, disc_batch_year, sess, loss_type)\n",
    "    hedging_stats(deltas, valid_two_opts_input, disc_valid_year, V_0_valid, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the TEST SET:\")\n",
    "    # Compute hedging strategies on the test set\n",
    "    deltas_SMSE = model_predict.predict(test_two_opts_input, V_0_batch, disc_batch_year, sess, loss_type)\n",
    "    hedging_stats(deltas_SMSE, test_two_opts_input, disc_test_year, V_0_test, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "# Compute average equity risk exposure\n",
    "stock_price_unorm       = S_0*np.exp(test_two_opts_input[:,:,0])\n",
    "portfolio_exposure_QDH  = np.zeros((test_two_opts_input.shape[0]-1, test_two_opts_input.shape[1], 2)) # no exposure at close contract\n",
    "portfolio_exposure_SQDH = np.zeros((test_two_opts_input.shape[0]-1, test_two_opts_input.shape[1], 2)) # no exposure at close contract \n",
    "delta_call_put          = np.zeros((stock_price_unorm.shape[0]-1, stock_price_unorm.shape[1],2)) # deltas across all paths for calls and puts\n",
    "delta_call_put[:,:,0]   = BS_delta(stock_price_unorm[:-1,:], 1, r, 0.15, stock_price_unorm[:-1,:], 1)  # call deltas \n",
    "delta_call_put[:,:,1]   = BS_delta(stock_price_unorm[:-1,:], 1, r, 0.15, stock_price_unorm[:-1,:], -1) # put deltas\n",
    "\n",
    "portfolio_exposure_QDH[:,:,0]  = deltas_MSE[:,:,0]*delta_call_put[:,:,0]  # call option\n",
    "portfolio_exposure_QDH[:,:,1]  = deltas_MSE[:,:,1]*delta_call_put[:,:,1]  # put option\n",
    "    \n",
    "portfolio_exposure_SQDH[:,:,0] = deltas_SMSE[:,:,0]*delta_call_put[:,:,0]  # call option\n",
    "portfolio_exposure_SQDH[:,:,1] = deltas_SMSE[:,:,1]*delta_call_put[:,:,1]  # put option\n",
    "\n",
    "print(\" ----------------------- \")\n",
    "print(\"Portfolio total exposure - QDH\")\n",
    "print(np.sum(portfolio_exposure_QDH)/(portfolio_exposure_QDH.shape[0]*portfolio_exposure_QDH.shape[1]))   \n",
    "    \n",
    "print(\" ----------------------- \")\n",
    "print(\"Portfolio total exposure - SQDH\")\n",
    "print(np.sum(portfolio_exposure_SQDH)/(portfolio_exposure_SQDH.shape[0]*portfolio_exposure_SQDH.shape[1]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Training of LSTM - Six options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: learning rate=0.0100, LSTM cells=2, neurons=24\n",
      "---Training for quadratic deep hedging start---\n",
      "Time elapsed: 0:00:06.015364\n",
      "Epoch 1, MSE, Train: 114.817 Valid: 15.215\n",
      "Time elapsed: 0:00:11.174534\n",
      "Epoch 2, MSE, Train: 9.650 Valid: 7.839\n",
      "Time elapsed: 0:00:16.346708\n",
      "Epoch 3, MSE, Train: 7.087 Valid: 6.382\n",
      "Time elapsed: 0:00:21.518890\n",
      "Epoch 4, MSE, Train: 6.158 Valid: 5.425\n",
      "Time elapsed: 0:00:26.674059\n",
      "Epoch 5, MSE, Train: 5.561 Valid: 3.825\n",
      "Time elapsed: 0:00:31.836231\n",
      "Epoch 6, MSE, Train: 4.545 Valid: 3.301\n",
      "Time elapsed: 0:00:37.015406\n",
      "Epoch 7, MSE, Train: 4.162 Valid: 3.067\n",
      "Time elapsed: 0:00:42.042546\n",
      "Epoch 8, MSE, Train: 3.694 Valid: 6.040\n",
      "Time elapsed: 0:00:47.053674\n",
      "Epoch 9, MSE, Train: 3.749 Valid: 3.191\n",
      "Time elapsed: 0:00:52.171845\n",
      "Epoch 10, MSE, Train: 3.079 Valid: 2.689\n",
      "Time elapsed: 0:00:57.172979\n",
      "Epoch 11, MSE, Train: 3.096 Valid: 3.009\n",
      "Time elapsed: 0:01:02.211113\n",
      "Epoch 12, MSE, Train: 2.705 Valid: 3.368\n",
      "Time elapsed: 0:01:07.389296\n",
      "Epoch 13, MSE, Train: 2.734 Valid: 2.069\n",
      "Time elapsed: 0:01:12.584489\n",
      "Epoch 14, MSE, Train: 2.666 Valid: 1.815\n",
      "Time elapsed: 0:01:17.609629\n",
      "Epoch 15, MSE, Train: 2.031 Valid: 2.044\n",
      "Time elapsed: 0:01:22.809809\n",
      "Epoch 16, MSE, Train: 2.123 Valid: 1.607\n",
      "Time elapsed: 0:01:27.982984\n",
      "Epoch 17, MSE, Train: 2.104 Valid: 1.317\n",
      "Time elapsed: 0:01:33.017115\n",
      "Epoch 18, MSE, Train: 1.779 Valid: 2.185\n",
      "Time elapsed: 0:01:38.334331\n",
      "Epoch 19, MSE, Train: 1.962 Valid: 1.313\n",
      "Time elapsed: 0:01:43.386491\n",
      "Epoch 20, MSE, Train: 1.614 Valid: 1.237\n",
      "Time elapsed: 0:01:48.273600\n",
      "Epoch 21, MSE, Train: 1.732 Valid: 1.893\n",
      "Time elapsed: 0:01:53.151707\n",
      "Epoch 22, MSE, Train: 1.820 Valid: 1.734\n",
      "Time elapsed: 0:01:58.023812\n",
      "Epoch 23, MSE, Train: 1.556 Valid: 1.269\n",
      "Time elapsed: 0:02:02.921924\n",
      "Epoch 24, MSE, Train: 1.610 Valid: 1.286\n",
      "Time elapsed: 0:02:07.785018\n",
      "Epoch 25, MSE, Train: 2.038 Valid: 1.757\n",
      "Time elapsed: 0:02:12.671126\n",
      "Epoch 26, MSE, Train: 1.432 Valid: 1.381\n",
      "Time elapsed: 0:02:17.531238\n",
      "Epoch 27, MSE, Train: 1.457 Valid: 1.311\n",
      "Time elapsed: 0:02:22.426349\n",
      "Epoch 28, MSE, Train: 1.562 Valid: 1.256\n",
      "Time elapsed: 0:02:27.457490\n",
      "Epoch 29, MSE, Train: 1.483 Valid: 1.237\n",
      "Time elapsed: 0:02:32.338597\n",
      "Epoch 30, MSE, Train: 1.531 Valid: 1.557\n",
      "Time elapsed: 0:02:37.406779\n",
      "Epoch 31, MSE, Train: 1.462 Valid: 1.188\n",
      "Time elapsed: 0:02:42.493958\n",
      "Epoch 32, MSE, Train: 1.422 Valid: 1.126\n",
      "Time elapsed: 0:02:47.391070\n",
      "Epoch 33, MSE, Train: 1.525 Valid: 1.624\n",
      "Time elapsed: 0:02:52.440222\n",
      "Epoch 34, MSE, Train: 1.471 Valid: 1.089\n",
      "Time elapsed: 0:02:57.323321\n",
      "Epoch 35, MSE, Train: 1.394 Valid: 1.122\n",
      "Time elapsed: 0:03:02.219432\n",
      "Epoch 36, MSE, Train: 1.403 Valid: 1.179\n",
      "Time elapsed: 0:03:07.118545\n",
      "Epoch 37, MSE, Train: 1.442 Valid: 1.114\n",
      "Time elapsed: 0:03:12.007662\n",
      "Epoch 38, MSE, Train: 1.408 Valid: 1.102\n",
      "Time elapsed: 0:03:16.909765\n",
      "Epoch 39, MSE, Train: 1.298 Valid: 1.237\n",
      "Time elapsed: 0:03:21.807885\n",
      "Epoch 40, MSE, Train: 1.437 Valid: 1.193\n",
      "Time elapsed: 0:03:26.703987\n",
      "Epoch 41, MSE, Train: 1.337 Valid: 1.556\n",
      "Time elapsed: 0:03:31.580095\n",
      "Epoch 42, MSE, Train: 1.371 Valid: 1.167\n",
      "Time elapsed: 0:03:36.476205\n",
      "Epoch 43, MSE, Train: 1.294 Valid: 1.292\n",
      "Time elapsed: 0:03:41.376324\n",
      "Epoch 44, MSE, Train: 1.362 Valid: 1.255\n",
      "Time elapsed: 0:03:46.258423\n",
      "Epoch 45, MSE, Train: 1.344 Valid: 1.519\n",
      "Time elapsed: 0:03:51.136530\n",
      "Epoch 46, MSE, Train: 1.386 Valid: 1.992\n",
      "Time elapsed: 0:03:56.017637\n",
      "Epoch 47, MSE, Train: 1.498 Valid: 1.450\n",
      "Time elapsed: 0:04:00.915749\n",
      "Epoch 48, MSE, Train: 1.302 Valid: 1.333\n",
      "Time elapsed: 0:04:05.814860\n",
      "Epoch 49, MSE, Train: 1.273 Valid: 1.213\n",
      "Time elapsed: 0:04:10.725974\n",
      "Epoch 50, MSE, Train: 1.317 Valid: 1.148\n",
      "Time elapsed: 0:04:15.627087\n",
      "Epoch 51, MSE, Train: 1.302 Valid: 1.169\n",
      "Time elapsed: 0:04:20.677241\n",
      "Epoch 52, MSE, Train: 1.300 Valid: 1.041\n",
      "Time elapsed: 0:04:25.554338\n",
      "Epoch 53, MSE, Train: 1.274 Valid: 1.147\n",
      "Time elapsed: 0:04:30.447449\n",
      "Epoch 54, MSE, Train: 1.255 Valid: 1.237\n",
      "Time elapsed: 0:04:35.317562\n",
      "Epoch 55, MSE, Train: 1.332 Valid: 1.275\n",
      "Time elapsed: 0:04:40.202670\n",
      "Epoch 56, MSE, Train: 1.241 Valid: 1.285\n",
      "Time elapsed: 0:04:45.105774\n",
      "Epoch 57, MSE, Train: 1.237 Valid: 1.261\n",
      "Time elapsed: 0:04:49.991882\n",
      "Epoch 58, MSE, Train: 1.307 Valid: 1.147\n",
      "Time elapsed: 0:04:54.883994\n",
      "Epoch 59, MSE, Train: 1.250 Valid: 1.074\n",
      "Time elapsed: 0:04:59.751097\n",
      "Epoch 60, MSE, Train: 1.259 Valid: 1.244\n",
      "Time elapsed: 0:05:04.638206\n",
      "Epoch 61, MSE, Train: 1.243 Valid: 1.041\n",
      "Time elapsed: 0:05:09.538318\n",
      "Epoch 62, MSE, Train: 1.226 Valid: 1.166\n",
      "Time elapsed: 0:05:14.433429\n",
      "Epoch 63, MSE, Train: 1.272 Valid: 1.517\n",
      "Time elapsed: 0:05:19.310534\n",
      "Epoch 64, MSE, Train: 1.247 Valid: 1.269\n",
      "Time elapsed: 0:05:24.193643\n",
      "Epoch 65, MSE, Train: 1.252 Valid: 1.056\n",
      "Time elapsed: 0:05:29.068758\n",
      "Epoch 66, MSE, Train: 1.268 Valid: 1.124\n",
      "Time elapsed: 0:05:33.957858\n",
      "Epoch 67, MSE, Train: 1.177 Valid: 1.442\n",
      "Time elapsed: 0:05:38.990051\n",
      "Epoch 68, MSE, Train: 1.212 Valid: 0.996\n",
      "Time elapsed: 0:05:43.903158\n",
      "Epoch 69, MSE, Train: 1.258 Valid: 1.336\n",
      "Time elapsed: 0:05:48.788265\n",
      "Epoch 70, MSE, Train: 1.213 Valid: 1.287\n",
      "Time elapsed: 0:05:53.807413\n",
      "Epoch 71, MSE, Train: 1.249 Valid: 0.957\n",
      "Time elapsed: 0:05:58.682519\n",
      "Epoch 72, MSE, Train: 1.252 Valid: 1.476\n",
      "Time elapsed: 0:06:03.559616\n",
      "Epoch 73, MSE, Train: 1.187 Valid: 1.070\n",
      "Time elapsed: 0:06:08.448726\n",
      "Epoch 74, MSE, Train: 1.205 Valid: 1.202\n",
      "Time elapsed: 0:06:13.348846\n",
      "Epoch 75, MSE, Train: 1.223 Valid: 1.205\n",
      "Time elapsed: 0:06:18.228953\n",
      "Epoch 76, MSE, Train: 1.201 Valid: 1.326\n",
      "Time elapsed: 0:06:23.102059\n",
      "Epoch 77, MSE, Train: 1.222 Valid: 1.093\n",
      "Time elapsed: 0:06:27.966154\n",
      "Epoch 78, MSE, Train: 1.224 Valid: 1.167\n",
      "Time elapsed: 0:06:32.862265\n",
      "Epoch 79, MSE, Train: 1.145 Valid: 0.995\n",
      "Time elapsed: 0:06:37.758376\n",
      "Epoch 80, MSE, Train: 1.200 Valid: 1.229\n",
      "Time elapsed: 0:06:42.644492\n",
      "Epoch 81, MSE, Train: 1.222 Valid: 1.307\n",
      "Time elapsed: 0:06:47.536602\n",
      "Epoch 82, MSE, Train: 1.217 Valid: 1.546\n",
      "Time elapsed: 0:06:52.415709\n",
      "Epoch 83, MSE, Train: 1.160 Valid: 1.105\n",
      "Time elapsed: 0:06:57.288807\n",
      "Epoch 84, MSE, Train: 1.225 Valid: 1.200\n",
      "Time elapsed: 0:07:02.195928\n",
      "Epoch 85, MSE, Train: 1.236 Valid: 1.090\n",
      "Time elapsed: 0:07:07.057023\n",
      "Epoch 86, MSE, Train: 1.166 Valid: 1.056\n",
      "Time elapsed: 0:07:11.949132\n",
      "Epoch 87, MSE, Train: 1.279 Valid: 1.167\n",
      "Time elapsed: 0:07:16.823247\n",
      "Epoch 88, MSE, Train: 1.160 Valid: 0.999\n",
      "Time elapsed: 0:07:21.698353\n",
      "Epoch 89, MSE, Train: 1.213 Valid: 1.079\n",
      "Time elapsed: 0:07:26.569458\n",
      "Epoch 90, MSE, Train: 1.104 Valid: 1.441\n",
      "Time elapsed: 0:07:31.433562\n",
      "Epoch 91, MSE, Train: 1.138 Valid: 1.080\n",
      "Time elapsed: 0:07:36.316669\n",
      "Epoch 92, MSE, Train: 1.145 Valid: 1.197\n",
      "Time elapsed: 0:07:41.181773\n",
      "Epoch 93, MSE, Train: 13.791 Valid: 1.591\n",
      "Time elapsed: 0:07:46.077884\n",
      "Epoch 94, MSE, Train: 1.533 Valid: 1.535\n",
      "Time elapsed: 0:07:50.943988\n",
      "Epoch 95, MSE, Train: 1.358 Valid: 1.334\n",
      "Time elapsed: 0:07:55.779084\n",
      "Epoch 96, MSE, Train: 1.261 Valid: 1.191\n",
      "Time elapsed: 0:08:00.655182\n",
      "Epoch 97, MSE, Train: 1.244 Valid: 1.139\n",
      "Time elapsed: 0:08:05.544301\n",
      "Epoch 98, MSE, Train: 1.185 Valid: 1.287\n",
      "Time elapsed: 0:08:10.446413\n",
      "Epoch 99, MSE, Train: 1.172 Valid: 1.249\n",
      "Time elapsed: 0:08:15.332521\n",
      "Epoch 100, MSE, Train: 1.178 Valid: 1.150\n",
      "Time elapsed: 0:08:20.202618\n",
      "Epoch 101, MSE, Train: 1.181 Valid: 1.180\n",
      "Time elapsed: 0:08:25.085734\n",
      "Epoch 102, MSE, Train: 1.184 Valid: 1.256\n",
      "Time elapsed: 0:08:29.975835\n",
      "Epoch 103, MSE, Train: 1.189 Valid: 1.422\n",
      "Time elapsed: 0:08:34.857942\n",
      "Epoch 104, MSE, Train: 1.176 Valid: 1.137\n",
      "Time elapsed: 0:08:39.748051\n",
      "Epoch 105, MSE, Train: 1.146 Valid: 1.459\n",
      "Time elapsed: 0:08:44.648164\n",
      "Epoch 106, MSE, Train: 1.209 Valid: 1.250\n",
      "Time elapsed: 0:08:49.509275\n",
      "Epoch 107, MSE, Train: 1.226 Valid: 1.226\n",
      "Time elapsed: 0:08:54.384381\n",
      "Epoch 108, MSE, Train: 1.160 Valid: 1.277\n",
      "Time elapsed: 0:08:59.279491\n",
      "Epoch 109, MSE, Train: 1.199 Valid: 1.165\n",
      "Time elapsed: 0:09:04.172601\n",
      "Epoch 110, MSE, Train: 1.148 Valid: 1.310\n",
      "Time elapsed: 0:09:09.049699\n",
      "Epoch 111, MSE, Train: 1.187 Valid: 1.270\n",
      "Time elapsed: 0:09:13.928815\n",
      "Epoch 112, MSE, Train: 1.131 Valid: 1.319\n",
      "Time elapsed: 0:09:18.769907\n",
      "Epoch 113, MSE, Train: 1.170 Valid: 1.610\n",
      "Time elapsed: 0:09:23.649012\n",
      "Epoch 114, MSE, Train: 1.267 Valid: 1.214\n",
      "Time elapsed: 0:09:28.539129\n",
      "Epoch 115, MSE, Train: 1.165 Valid: 1.381\n",
      "Time elapsed: 0:09:33.438241\n",
      "Epoch 116, MSE, Train: 1.179 Valid: 2.431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:09:38.355357\n",
      "Epoch 117, MSE, Train: 1.176 Valid: 1.846\n",
      "Time elapsed: 0:09:43.309472\n",
      "Epoch 118, MSE, Train: 1.133 Valid: 1.659\n",
      "Time elapsed: 0:09:48.209592\n",
      "Epoch 119, MSE, Train: 1.291 Valid: 1.126\n",
      "Time elapsed: 0:09:53.091700\n",
      "Epoch 120, MSE, Train: 1.137 Valid: 1.213\n",
      "Time elapsed: 0:09:57.983801\n",
      "Epoch 121, MSE, Train: 1.162 Valid: 1.064\n",
      "Time elapsed: 0:10:02.870918\n",
      "Epoch 122, MSE, Train: 1.150 Valid: 1.125\n",
      "Time elapsed: 0:10:07.770021\n",
      "Epoch 123, MSE, Train: 1.198 Valid: 1.432\n",
      "Time elapsed: 0:10:12.659139\n",
      "Epoch 124, MSE, Train: 9.108 Valid: 4.537\n",
      "Time elapsed: 0:10:17.550241\n",
      "Epoch 125, MSE, Train: 3.557 Valid: 2.011\n",
      "Time elapsed: 0:10:22.425355\n",
      "Epoch 126, MSE, Train: 1.851 Valid: 1.647\n",
      "Time elapsed: 0:10:27.307462\n",
      "Epoch 127, MSE, Train: 1.580 Valid: 1.394\n",
      "Time elapsed: 0:10:32.187570\n",
      "Epoch 128, MSE, Train: 1.488 Valid: 1.250\n",
      "Time elapsed: 0:10:37.112678\n",
      "Epoch 129, MSE, Train: 1.477 Valid: 1.215\n",
      "Time elapsed: 0:10:42.014799\n",
      "Epoch 130, MSE, Train: 1.340 Valid: 1.231\n",
      "Time elapsed: 0:10:46.887896\n",
      "Epoch 131, MSE, Train: 1.354 Valid: 1.173\n",
      "Time elapsed: 0:10:51.781005\n",
      "Epoch 132, MSE, Train: 1.295 Valid: 1.259\n",
      "Time elapsed: 0:10:56.655121\n",
      "Epoch 133, MSE, Train: 1.314 Valid: 1.487\n",
      "Time elapsed: 0:11:01.555224\n",
      "Epoch 134, MSE, Train: 1.296 Valid: 1.112\n",
      "Time elapsed: 0:11:06.487343\n",
      "Epoch 135, MSE, Train: 1.270 Valid: 1.293\n",
      "Time elapsed: 0:11:11.394456\n",
      "Epoch 136, MSE, Train: 1.251 Valid: 1.493\n",
      "Time elapsed: 0:11:16.260569\n",
      "Epoch 137, MSE, Train: 1.245 Valid: 1.425\n",
      "Time elapsed: 0:11:21.133676\n",
      "Epoch 138, MSE, Train: 1.211 Valid: 1.118\n",
      "Time elapsed: 0:11:26.012772\n",
      "Epoch 139, MSE, Train: 1.222 Valid: 1.050\n",
      "Time elapsed: 0:11:30.896881\n",
      "Epoch 140, MSE, Train: 1.240 Valid: 1.044\n",
      "Time elapsed: 0:11:35.816997\n",
      "Epoch 141, MSE, Train: 1.244 Valid: 1.493\n",
      "Time elapsed: 0:11:40.701105\n",
      "Epoch 142, MSE, Train: 1.308 Valid: 1.206\n",
      "Time elapsed: 0:11:45.569210\n",
      "Epoch 143, MSE, Train: 1.223 Valid: 1.357\n",
      "Time elapsed: 0:11:50.436314\n",
      "Epoch 144, MSE, Train: 1.266 Valid: 1.259\n",
      "Time elapsed: 0:11:55.323431\n",
      "Epoch 145, MSE, Train: 2.398 Valid: 1.220\n",
      "Time elapsed: 0:12:00.205530\n",
      "Epoch 146, MSE, Train: 1.206 Valid: 1.092\n",
      "Time elapsed: 0:12:05.085638\n",
      "Epoch 147, MSE, Train: 1.167 Valid: 1.079\n",
      "Time elapsed: 0:12:09.979757\n",
      "Epoch 148, MSE, Train: 1.244 Valid: 1.198\n",
      "Time elapsed: 0:12:14.854862\n",
      "Epoch 149, MSE, Train: 1.146 Valid: 1.342\n",
      "Time elapsed: 0:12:19.741971\n",
      "Epoch 150, MSE, Train: 1.166 Valid: 1.252\n",
      "---Finished training results---\n",
      "Time elapsed: 0:12:19.741971\n",
      "---Training for quadratic deep hedging end---\n",
      "INFO:tensorflow:Restoring parameters from /Users/alexa/Github files/Long-term hedging paper example/Models/Six_opts_MSE/models.ckpt\n",
      "-------------------------------\n",
      "Results on the TRAIN SET:\n",
      "Model was trained with the loss function: MSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -0.03360336896865021\n",
      "CVaR_95: 2.2616, CVaR_99: 4.4900\n",
      "VaR_95: 1.1872, VaR_99: 2.7425\n",
      "MSE: 0.9992, RMSE: 0.9996\n",
      "Semi-MSE: 0.4753, Semi-RMSE: 0.6894\n",
      "Skew: 2.0810\n",
      "-------------------------------\n",
      "Results on the VALID SET:\n",
      "Model was trained with the loss function: MSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -0.031104149762559173\n",
      "CVaR_95: 2.2447, CVaR_99: 4.3637\n",
      "VaR_95: 1.1935, VaR_99: 2.7319\n",
      "MSE: 0.9566, RMSE: 0.9780\n",
      "Semi-MSE: 0.4416, Semi-RMSE: 0.6645\n",
      "Skew: 0.8850\n",
      "-------------------------------\n",
      "Results on the TEST SET:\n",
      "Model was trained with the loss function: MSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -0.03221386829176117\n",
      "CVaR_95: 2.2824, CVaR_99: 4.6326\n",
      "VaR_95: 1.1855, VaR_99: 2.7088\n",
      "MSE: 1.0995, RMSE: 1.0486\n",
      "Semi-MSE: 0.5672, Semi-RMSE: 0.7531\n",
      "Skew: 5.8577\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "END OF QUADRATIC DEEP HEDGING\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "Hyperparameters: learning rate=0.0017, LSTM cells=2, neurons=24\n",
      "---Training for semi-quadratic deep hedging start---\n",
      "Time elapsed: 0:00:05.784319\n",
      "Epoch 1, SMSE, Train: 16.469 Valid: 7.035\n",
      "Time elapsed: 0:00:10.866472\n",
      "Epoch 2, SMSE, Train: 4.311 Valid: 2.990\n",
      "Time elapsed: 0:00:15.910649\n",
      "Epoch 3, SMSE, Train: 2.257 Valid: 1.644\n",
      "Time elapsed: 0:00:20.956794\n",
      "Epoch 4, SMSE, Train: 1.567 Valid: 1.148\n",
      "Time elapsed: 0:00:26.013955\n",
      "Epoch 5, SMSE, Train: 1.242 Valid: 0.988\n",
      "Time elapsed: 0:00:31.069102\n",
      "Epoch 6, SMSE, Train: 0.971 Valid: 0.794\n",
      "Time elapsed: 0:00:36.110245\n",
      "Epoch 7, SMSE, Train: 0.880 Valid: 0.712\n",
      "Time elapsed: 0:00:41.177395\n",
      "Epoch 8, SMSE, Train: 0.842 Valid: 0.598\n",
      "Time elapsed: 0:00:46.238543\n",
      "Epoch 9, SMSE, Train: 0.664 Valid: 0.503\n",
      "Time elapsed: 0:00:51.281687\n",
      "Epoch 10, SMSE, Train: 1.052 Valid: 0.426\n",
      "Time elapsed: 0:00:56.342835\n",
      "Epoch 11, SMSE, Train: 0.486 Valid: 0.393\n",
      "Time elapsed: 0:01:01.446993\n",
      "Epoch 12, SMSE, Train: 0.551 Valid: 0.369\n",
      "Time elapsed: 0:01:06.517144\n",
      "Epoch 13, SMSE, Train: 0.633 Valid: 0.306\n",
      "Time elapsed: 0:01:11.435259\n",
      "Epoch 14, SMSE, Train: 0.387 Valid: 0.363\n",
      "Time elapsed: 0:01:16.348365\n",
      "Epoch 15, SMSE, Train: 0.468 Valid: 0.391\n",
      "Time elapsed: 0:01:21.242485\n",
      "Epoch 16, SMSE, Train: 0.328 Valid: 0.342\n",
      "Time elapsed: 0:01:26.303632\n",
      "Epoch 17, SMSE, Train: 0.506 Valid: 0.263\n",
      "Time elapsed: 0:01:31.209746\n",
      "Epoch 18, SMSE, Train: 0.448 Valid: 0.359\n",
      "Time elapsed: 0:01:36.139855\n",
      "Epoch 19, SMSE, Train: 0.266 Valid: 0.277\n",
      "Time elapsed: 0:01:41.214015\n",
      "Epoch 20, SMSE, Train: 0.291 Valid: 0.222\n",
      "Time elapsed: 0:01:46.120128\n",
      "Epoch 21, SMSE, Train: 0.474 Valid: 0.308\n",
      "Time elapsed: 0:01:51.165273\n",
      "Epoch 22, SMSE, Train: 0.396 Valid: 0.209\n",
      "Time elapsed: 0:01:56.240425\n",
      "Epoch 23, SMSE, Train: 0.307 Valid: 0.203\n",
      "Time elapsed: 0:02:01.119525\n",
      "Epoch 24, SMSE, Train: 0.297 Valid: 0.220\n",
      "Time elapsed: 0:02:06.166676\n",
      "Epoch 25, SMSE, Train: 0.247 Valid: 0.191\n",
      "Time elapsed: 0:02:11.059786\n",
      "Epoch 26, SMSE, Train: 0.265 Valid: 0.538\n",
      "Time elapsed: 0:02:15.989905\n",
      "Epoch 27, SMSE, Train: 0.286 Valid: 0.203\n",
      "Time elapsed: 0:02:20.876014\n",
      "Epoch 28, SMSE, Train: 0.259 Valid: 0.557\n",
      "Time elapsed: 0:02:25.779117\n",
      "Epoch 29, SMSE, Train: 0.253 Valid: 0.200\n",
      "Time elapsed: 0:02:30.833272\n",
      "Epoch 30, SMSE, Train: 0.274 Valid: 0.171\n",
      "Time elapsed: 0:02:35.746387\n",
      "Epoch 31, SMSE, Train: 0.201 Valid: 0.188\n",
      "Time elapsed: 0:02:40.657501\n",
      "Epoch 32, SMSE, Train: 0.238 Valid: 0.384\n",
      "Time elapsed: 0:02:45.564614\n",
      "Epoch 33, SMSE, Train: 0.209 Valid: 0.181\n",
      "Time elapsed: 0:02:50.460725\n",
      "Epoch 34, SMSE, Train: 0.246 Valid: 0.208\n",
      "Time elapsed: 0:02:55.381842\n",
      "Epoch 35, SMSE, Train: 0.260 Valid: 0.198\n",
      "Time elapsed: 0:03:00.433988\n",
      "Epoch 36, SMSE, Train: 0.210 Valid: 0.146\n",
      "Time elapsed: 0:03:05.370110\n",
      "Epoch 37, SMSE, Train: 0.165 Valid: 0.170\n",
      "Time elapsed: 0:03:10.283215\n",
      "Epoch 38, SMSE, Train: 0.220 Valid: 0.164\n",
      "Time elapsed: 0:03:15.184326\n",
      "Epoch 39, SMSE, Train: 0.215 Valid: 0.281\n",
      "Time elapsed: 0:03:20.229479\n",
      "Epoch 40, SMSE, Train: 0.180 Valid: 0.142\n",
      "Time elapsed: 0:03:25.145595\n",
      "Epoch 41, SMSE, Train: 0.178 Valid: 0.151\n",
      "Time elapsed: 0:03:30.022692\n",
      "Epoch 42, SMSE, Train: 0.217 Valid: 0.177\n",
      "Time elapsed: 0:03:34.949819\n",
      "Epoch 43, SMSE, Train: 0.196 Valid: 0.150\n",
      "Time elapsed: 0:03:39.860925\n",
      "Epoch 44, SMSE, Train: 0.180 Valid: 0.145\n",
      "Time elapsed: 0:03:44.769046\n",
      "Epoch 45, SMSE, Train: 0.177 Valid: 0.144\n",
      "Time elapsed: 0:03:49.816192\n",
      "Epoch 46, SMSE, Train: 0.231 Valid: 0.133\n",
      "Time elapsed: 0:03:54.703300\n",
      "Epoch 47, SMSE, Train: 0.158 Valid: 0.155\n",
      "Time elapsed: 0:03:59.628418\n",
      "Epoch 48, SMSE, Train: 0.149 Valid: 0.173\n",
      "Time elapsed: 0:04:04.700568\n",
      "Epoch 49, SMSE, Train: 0.167 Valid: 0.122\n",
      "Time elapsed: 0:04:09.629678\n",
      "Epoch 50, SMSE, Train: 0.136 Valid: 0.138\n",
      "Time elapsed: 0:04:14.510794\n",
      "Epoch 51, SMSE, Train: 0.175 Valid: 0.688\n",
      "Time elapsed: 0:04:19.456907\n",
      "Epoch 52, SMSE, Train: 0.162 Valid: 0.125\n",
      "Time elapsed: 0:04:24.385025\n",
      "Epoch 53, SMSE, Train: 0.128 Valid: 0.159\n",
      "Time elapsed: 0:04:29.315153\n",
      "Epoch 54, SMSE, Train: 0.149 Valid: 0.160\n",
      "Time elapsed: 0:04:34.219266\n",
      "Epoch 55, SMSE, Train: 0.147 Valid: 0.231\n",
      "Time elapsed: 0:04:39.143383\n",
      "Epoch 56, SMSE, Train: 0.162 Valid: 0.131\n",
      "Time elapsed: 0:04:44.203530\n",
      "Epoch 57, SMSE, Train: 0.150 Valid: 0.114\n",
      "Time elapsed: 0:04:49.095640\n",
      "Epoch 58, SMSE, Train: 0.170 Valid: 0.129\n",
      "Time elapsed: 0:04:53.989742\n",
      "Epoch 59, SMSE, Train: 0.113 Valid: 0.159\n",
      "Time elapsed: 0:04:58.867858\n",
      "Epoch 60, SMSE, Train: 0.167 Valid: 0.114\n",
      "Time elapsed: 0:05:03.773962\n",
      "Epoch 61, SMSE, Train: 0.123 Valid: 0.135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:05:08.697088\n",
      "Epoch 62, SMSE, Train: 0.136 Valid: 0.118\n",
      "Time elapsed: 0:05:13.758236\n",
      "Epoch 63, SMSE, Train: 0.113 Valid: 0.111\n",
      "Time elapsed: 0:05:18.670350\n",
      "Epoch 64, SMSE, Train: 0.134 Valid: 0.140\n",
      "Time elapsed: 0:05:23.595459\n",
      "Epoch 65, SMSE, Train: 0.127 Valid: 0.185\n",
      "Time elapsed: 0:05:28.653615\n",
      "Epoch 66, SMSE, Train: 0.136 Valid: 0.104\n",
      "Time elapsed: 0:05:33.561719\n",
      "Epoch 67, SMSE, Train: 0.155 Valid: 0.151\n",
      "Time elapsed: 0:05:38.502850\n",
      "Epoch 68, SMSE, Train: 0.125 Valid: 0.105\n",
      "Time elapsed: 0:05:43.399961\n",
      "Epoch 69, SMSE, Train: 0.106 Valid: 0.111\n",
      "Time elapsed: 0:05:48.295063\n",
      "Epoch 70, SMSE, Train: 0.124 Valid: 0.165\n",
      "Time elapsed: 0:05:53.176179\n",
      "Epoch 71, SMSE, Train: 0.175 Valid: 0.112\n",
      "Time elapsed: 0:05:58.073290\n",
      "Epoch 72, SMSE, Train: 0.099 Valid: 0.109\n",
      "Time elapsed: 0:06:02.986404\n",
      "Epoch 73, SMSE, Train: 0.114 Valid: 0.106\n",
      "Time elapsed: 0:06:07.890517\n",
      "Epoch 74, SMSE, Train: 0.113 Valid: 0.154\n",
      "Time elapsed: 0:06:12.948697\n",
      "Epoch 75, SMSE, Train: 0.125 Valid: 0.098\n",
      "Time elapsed: 0:06:17.853801\n",
      "Epoch 76, SMSE, Train: 0.124 Valid: 0.100\n",
      "Time elapsed: 0:06:22.774918\n",
      "Epoch 77, SMSE, Train: 0.123 Valid: 0.103\n",
      "Time elapsed: 0:06:27.665027\n",
      "Epoch 78, SMSE, Train: 0.108 Valid: 0.115\n",
      "Time elapsed: 0:06:32.552135\n",
      "Epoch 79, SMSE, Train: 0.107 Valid: 0.115\n",
      "Time elapsed: 0:06:37.461250\n",
      "Epoch 80, SMSE, Train: 0.121 Valid: 0.117\n",
      "Time elapsed: 0:06:42.345357\n",
      "Epoch 81, SMSE, Train: 0.113 Valid: 0.107\n",
      "Time elapsed: 0:06:47.231466\n",
      "Epoch 82, SMSE, Train: 0.112 Valid: 0.145\n",
      "Time elapsed: 0:06:52.284621\n",
      "Epoch 83, SMSE, Train: 0.113 Valid: 0.091\n",
      "Time elapsed: 0:06:57.194727\n",
      "Epoch 84, SMSE, Train: 0.108 Valid: 0.107\n",
      "Time elapsed: 0:07:02.121844\n",
      "Epoch 85, SMSE, Train: 0.108 Valid: 0.131\n",
      "Time elapsed: 0:07:07.040961\n",
      "Epoch 86, SMSE, Train: 0.121 Valid: 0.126\n",
      "Time elapsed: 0:07:11.967078\n",
      "Epoch 87, SMSE, Train: 0.113 Valid: 0.113\n",
      "Time elapsed: 0:07:16.876191\n",
      "Epoch 88, SMSE, Train: 0.106 Valid: 0.110\n",
      "Time elapsed: 0:07:21.782305\n",
      "Epoch 89, SMSE, Train: 0.112 Valid: 0.136\n",
      "Time elapsed: 0:07:26.690419\n",
      "Epoch 90, SMSE, Train: 0.105 Valid: 0.125\n",
      "Time elapsed: 0:07:31.597531\n",
      "Epoch 91, SMSE, Train: 0.113 Valid: 0.117\n",
      "Time elapsed: 0:07:36.510647\n",
      "Epoch 92, SMSE, Train: 0.110 Valid: 0.111\n",
      "Time elapsed: 0:07:41.409759\n",
      "Epoch 93, SMSE, Train: 0.100 Valid: 0.101\n",
      "Time elapsed: 0:07:46.485949\n",
      "Epoch 94, SMSE, Train: 0.103 Valid: 0.090\n",
      "Time elapsed: 0:07:51.384051\n",
      "Epoch 95, SMSE, Train: 0.109 Valid: 0.140\n",
      "Time elapsed: 0:07:56.279171\n",
      "Epoch 96, SMSE, Train: 0.097 Valid: 0.139\n",
      "Time elapsed: 0:08:01.185275\n",
      "Epoch 97, SMSE, Train: 0.096 Valid: 0.115\n",
      "Time elapsed: 0:08:06.109392\n",
      "Epoch 98, SMSE, Train: 0.117 Valid: 0.151\n",
      "Time elapsed: 0:08:11.013514\n",
      "Epoch 99, SMSE, Train: 0.098 Valid: 0.111\n",
      "Time elapsed: 0:08:15.957626\n",
      "Epoch 100, SMSE, Train: 0.099 Valid: 0.104\n",
      "Time elapsed: 0:08:20.878752\n",
      "Epoch 101, SMSE, Train: 0.101 Valid: 0.109\n",
      "Time elapsed: 0:08:25.808862\n",
      "Epoch 102, SMSE, Train: 0.110 Valid: 0.177\n",
      "Time elapsed: 0:08:30.754993\n",
      "Epoch 103, SMSE, Train: 0.099 Valid: 0.129\n",
      "Time elapsed: 0:08:35.694104\n",
      "Epoch 104, SMSE, Train: 0.093 Valid: 0.093\n",
      "Time elapsed: 0:08:40.725255\n",
      "Epoch 105, SMSE, Train: 0.103 Valid: 0.084\n",
      "Time elapsed: 0:08:45.663366\n",
      "Epoch 106, SMSE, Train: 0.093 Valid: 0.109\n",
      "Time elapsed: 0:08:50.582491\n",
      "Epoch 107, SMSE, Train: 0.094 Valid: 0.104\n",
      "Time elapsed: 0:08:55.487594\n",
      "Epoch 108, SMSE, Train: 0.109 Valid: 0.140\n",
      "Time elapsed: 0:09:00.414722\n",
      "Epoch 109, SMSE, Train: 0.092 Valid: 0.114\n",
      "Time elapsed: 0:09:05.329828\n",
      "Epoch 110, SMSE, Train: 0.105 Valid: 0.120\n",
      "Time elapsed: 0:09:10.225948\n",
      "Epoch 111, SMSE, Train: 0.098 Valid: 0.130\n",
      "Time elapsed: 0:09:15.107046\n",
      "Epoch 112, SMSE, Train: 0.090 Valid: 0.116\n",
      "Time elapsed: 0:09:20.033164\n",
      "Epoch 113, SMSE, Train: 0.116 Valid: 0.094\n",
      "Time elapsed: 0:09:24.948278\n",
      "Epoch 114, SMSE, Train: 0.093 Valid: 0.094\n",
      "Time elapsed: 0:09:29.876397\n",
      "Epoch 115, SMSE, Train: 0.086 Valid: 0.096\n",
      "Time elapsed: 0:09:34.806515\n",
      "Epoch 116, SMSE, Train: 0.092 Valid: 0.110\n",
      "Time elapsed: 0:09:39.689632\n",
      "Epoch 117, SMSE, Train: 0.087 Valid: 0.101\n",
      "Time elapsed: 0:09:44.609749\n",
      "Epoch 118, SMSE, Train: 0.092 Valid: 0.107\n",
      "Time elapsed: 0:09:49.508851\n",
      "Epoch 119, SMSE, Train: 0.087 Valid: 0.156\n",
      "Time elapsed: 0:09:54.428968\n",
      "Epoch 120, SMSE, Train: 0.094 Valid: 0.205\n",
      "Time elapsed: 0:09:59.331088\n",
      "Epoch 121, SMSE, Train: 0.099 Valid: 0.275\n",
      "Time elapsed: 0:10:04.253196\n",
      "Epoch 122, SMSE, Train: 0.093 Valid: 0.147\n",
      "Time elapsed: 0:10:09.135313\n",
      "Epoch 123, SMSE, Train: 0.076 Valid: 0.137\n",
      "Time elapsed: 0:10:14.033414\n",
      "Epoch 124, SMSE, Train: 0.091 Valid: 0.117\n",
      "Time elapsed: 0:10:18.964542\n",
      "Epoch 125, SMSE, Train: 0.105 Valid: 0.094\n",
      "Time elapsed: 0:10:23.855643\n",
      "Epoch 126, SMSE, Train: 0.076 Valid: 0.125\n",
      "Time elapsed: 0:10:28.780760\n",
      "Epoch 127, SMSE, Train: 0.082 Valid: 0.100\n",
      "Time elapsed: 0:10:33.693884\n",
      "Epoch 128, SMSE, Train: 0.085 Valid: 0.213\n",
      "Time elapsed: 0:10:38.594996\n",
      "Epoch 129, SMSE, Train: 0.100 Valid: 0.142\n",
      "Time elapsed: 0:10:43.487096\n",
      "Epoch 130, SMSE, Train: 0.081 Valid: 0.154\n",
      "Time elapsed: 0:10:48.406222\n",
      "Epoch 131, SMSE, Train: 0.077 Valid: 0.185\n",
      "Time elapsed: 0:10:53.310327\n",
      "Epoch 132, SMSE, Train: 0.088 Valid: 0.138\n",
      "Time elapsed: 0:10:58.225441\n",
      "Epoch 133, SMSE, Train: 0.123 Valid: 0.088\n",
      "Time elapsed: 0:11:03.269603\n",
      "Epoch 134, SMSE, Train: 0.084 Valid: 0.077\n",
      "Time elapsed: 0:11:08.174716\n",
      "Epoch 135, SMSE, Train: 0.079 Valid: 0.106\n",
      "Time elapsed: 0:11:13.088831\n",
      "Epoch 136, SMSE, Train: 0.077 Valid: 0.153\n",
      "Time elapsed: 0:11:17.988943\n",
      "Epoch 137, SMSE, Train: 0.083 Valid: 0.131\n",
      "Time elapsed: 0:11:22.911060\n",
      "Epoch 138, SMSE, Train: 0.075 Valid: 0.136\n",
      "Time elapsed: 0:11:27.806161\n",
      "Epoch 139, SMSE, Train: 0.076 Valid: 0.139\n",
      "Time elapsed: 0:11:32.723286\n",
      "Epoch 140, SMSE, Train: 0.101 Valid: 0.098\n",
      "Time elapsed: 0:11:37.625398\n",
      "Epoch 141, SMSE, Train: 0.084 Valid: 0.086\n",
      "Time elapsed: 0:11:42.541513\n",
      "Epoch 142, SMSE, Train: 0.075 Valid: 0.125\n",
      "Time elapsed: 0:11:47.440625\n",
      "Epoch 143, SMSE, Train: 0.075 Valid: 0.114\n",
      "Time elapsed: 0:11:52.339736\n",
      "Epoch 144, SMSE, Train: 0.084 Valid: 0.157\n",
      "Time elapsed: 0:11:57.237847\n",
      "Epoch 145, SMSE, Train: 0.073 Valid: 0.184\n",
      "Time elapsed: 0:12:02.162965\n",
      "Epoch 146, SMSE, Train: 0.071 Valid: 0.116\n",
      "Time elapsed: 0:12:07.060076\n",
      "Epoch 147, SMSE, Train: 0.076 Valid: 0.204\n",
      "Time elapsed: 0:12:11.958187\n",
      "Epoch 148, SMSE, Train: 0.070 Valid: 0.142\n",
      "Time elapsed: 0:12:16.887296\n",
      "Epoch 149, SMSE, Train: 0.076 Valid: 0.214\n",
      "Time elapsed: 0:12:21.783416\n",
      "Epoch 150, SMSE, Train: 0.076 Valid: 0.239\n",
      "---Finished training results---\n",
      "Time elapsed: 0:12:21.783416\n",
      "---Training for semi-quadratic deep hedging end---\n",
      "INFO:tensorflow:Restoring parameters from /Users/alexa/Github files/Long-term hedging paper example/Models/Six_opts_SMSE/models.ckpt\n",
      "-------------------------------\n",
      "Results on the TRAIN SET:\n",
      "Model was trained with the loss function: SMSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -0.8386738068387521\n",
      "CVaR_95: 0.7670, CVaR_99: 2.0654\n",
      "VaR_95: 0.1538, VaR_99: 1.1407\n",
      "MSE: 4.6277, RMSE: 2.1512\n",
      "Semi-MSE: 0.0685, Semi-RMSE: 0.2618\n",
      "Skew: -7.3941\n",
      "-------------------------------\n",
      "Results on the VALID SET:\n",
      "Model was trained with the loss function: SMSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -0.8269038542169399\n",
      "CVaR_95: 0.7839, CVaR_99: 2.1347\n",
      "VaR_95: 0.1581, VaR_99: 1.1287\n",
      "MSE: 4.3986, RMSE: 2.0973\n",
      "Semi-MSE: 0.0774, Semi-RMSE: 0.2782\n",
      "Skew: -6.4406\n",
      "-------------------------------\n",
      "Results on the TEST SET:\n",
      "Model was trained with the loss function: SMSE\n",
      "Initial investment 17.68894582328168\n",
      "Mean Hedging error: -0.8276912634168118\n",
      "CVaR_95: 0.8638, CVaR_99: 2.3905\n",
      "VaR_95: 0.1642, VaR_99: 1.2817\n",
      "MSE: 4.6854, RMSE: 2.1646\n",
      "Semi-MSE: 0.1182, Semi-RMSE: 0.3438\n",
      "Skew: -7.5641\n",
      " ----------------------- \n",
      "Portfolio total exposure - QDH\n",
      "-0.12434417961764245\n",
      " ----------------------- \n",
      "Portfolio total exposure - SQDH\n",
      "-0.11501746183606887\n"
     ]
    }
   ],
   "source": [
    "nbs_assets          = 6\n",
    "hedging_instruments = \"Six options\"\n",
    "freq_obs            = \"Yearly\"\n",
    "\n",
    "# A) Part 1: MSE\n",
    "loss_type  = 'MSE'\n",
    "model_name = 'Six_opts_MSE'\n",
    "lr         = 0.01   # learning rate of the Adam optimizer\n",
    "print(\"Hyperparameters: learning rate=%.4f, LSTM cells=%d, neurons=%d\" %(lr, hidden_layers, nbs_units))\n",
    "LSTM_underlying = DeepAgent(train_six_opts_input.shape[0], batch_size, train_six_opts_input.shape[2], \n",
    "        loss_type, nbs_assets, hidden_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments, \n",
    "        freq_obs, name = model_name)\n",
    "    \n",
    "# Start training \n",
    "start = dt.datetime.now()\n",
    "print('---Training for quadratic deep hedging start---')\n",
    "with tf.Session() as sess:           \n",
    "    loss_epoch = LSTM_underlying.training(train_six_opts_input, V_0_batch, disc_batch_year, valid_six_opts_input, \n",
    "                                          sess, epochs)\n",
    "    print('---Training for quadratic deep hedging end---')\n",
    "    \n",
    "# Compute measured risk exposure on train, valid and test set with the optimized LSTM\n",
    "model_predict = DeepAgent(test_six_opts_input.shape[0], batch_size, test_six_opts_input.shape[2], loss_type, \n",
    "        nbs_assets, hidden_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments, \n",
    "        freq_obs, name = model_name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Load the saved model\n",
    "    model_predict.restore(sess, r\"/Users/alexa/Github files/Long-term hedging paper example/Models/%s/models.ckpt\" % model_name)\n",
    "\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the TRAIN SET:\")\n",
    "    # Compute hedging strategies on the training set\n",
    "    deltas = model_predict.predict(train_six_opts_input, V_0_batch, disc_batch_year, sess, loss_type)    \n",
    "    hedging_stats(deltas, train_six_opts_input, disc_train_year, V_0_train, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the VALID SET:\")\n",
    "    # Compute hedging strategies on the valid set\n",
    "    deltas = model_predict.predict(valid_six_opts_input, V_0_batch, disc_batch_year, sess, loss_type)\n",
    "    hedging_stats(deltas, valid_six_opts_input, disc_valid_year, V_0_valid, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the TEST SET:\")\n",
    "    # Compute hedging strategies on the test set\n",
    "    deltas_MSE = model_predict.predict(test_six_opts_input, V_0_batch, disc_batch_year, sess, loss_type)\n",
    "    hedging_stats(deltas_MSE, test_six_opts_input, disc_test_year, V_0_test, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"END OF QUADRATIC DEEP HEDGING\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "# B) Part 2: SMSE\n",
    "loss_type  = 'SMSE'\n",
    "model_name = 'Six_opts_SMSE'\n",
    "lr         = 0.01/6   # learning rate of the Adam optimizer\n",
    "print(\"Hyperparameters: learning rate=%.4f, LSTM cells=%d, neurons=%d\" %(lr, hidden_layers, nbs_units))\n",
    "LSTM_underlying = DeepAgent(train_six_opts_input.shape[0], batch_size, train_six_opts_input.shape[2], \n",
    "        loss_type, nbs_assets, hidden_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments, \n",
    "        freq_obs, name = model_name)\n",
    "    \n",
    "# Start training \n",
    "start = dt.datetime.now()\n",
    "print('---Training for semi-quadratic deep hedging start---')\n",
    "with tf.Session() as sess:           \n",
    "    loss_epoch = LSTM_underlying.training(train_six_opts_input, V_0_batch, disc_batch_year, valid_six_opts_input, \n",
    "                                          sess, epochs)\n",
    "    print('---Training for semi-quadratic deep hedging end---')\n",
    "    \n",
    "# Compute measured risk exposure on train, valid and test set with the optimized LSTM\n",
    "model_predict = DeepAgent(test_six_opts_input.shape[0], batch_size, test_six_opts_input.shape[2], loss_type, \n",
    "        nbs_assets, hidden_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments, \n",
    "        freq_obs, name = model_name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Load the saved model\n",
    "    model_predict.restore(sess, r\"/Users/alexa/Github files/Long-term hedging paper example/Models/%s/models.ckpt\" % model_name)\n",
    "\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the TRAIN SET:\")\n",
    "    # Compute hedging strategies on the training set\n",
    "    deltas = model_predict.predict(train_six_opts_input, V_0_batch, disc_batch_year, sess, loss_type)    \n",
    "    hedging_stats(deltas, train_six_opts_input, disc_train_year, V_0_train, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the VALID SET:\")\n",
    "    # Compute hedging strategies on the valid set\n",
    "    deltas = model_predict.predict(valid_six_opts_input, V_0_batch, disc_batch_year, sess, loss_type)\n",
    "    hedging_stats(deltas, valid_six_opts_input, disc_valid_year, V_0_valid, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Results on the TEST SET:\")\n",
    "    # Compute hedging strategies on the test set\n",
    "    deltas_SMSE = model_predict.predict(test_six_opts_input, V_0_batch, disc_batch_year, sess, loss_type)\n",
    "    hedging_stats(deltas_SMSE, test_six_opts_input, disc_test_year, V_0_test, loss_type, model_name, prepro_risky_assets, \n",
    "                  hedging_instruments, freq_obs)\n",
    "    \n",
    "# Compute average equity risk exposure\n",
    "stock_price_unorm       = S_0*np.exp(test_six_opts_input[:,:,0])\n",
    "portfolio_exposure_QDH  = np.zeros((test_six_opts_input.shape[0]-1, test_six_opts_input.shape[1], 6))      # no exposure at close contract\n",
    "portfolio_exposure_SQDH = np.zeros((test_six_opts_input.shape[0]-1, test_six_opts_input.shape[1], 6))      # no exposure at close contract \n",
    "delta_call_put          = np.zeros((stock_price_unorm.shape[0]-1, stock_price_unorm.shape[1],6))           # deltas across all paths for calls and puts\n",
    "delta_call_put[:,:,0]   = BS_delta(stock_price_unorm[:-1,:], 1, r, 0.15, stock_price_unorm[:-1,:], 1)      # ATM call deltas \n",
    "delta_call_put[:,:,1]   = BS_delta(stock_price_unorm[:-1,:], 1, r, 0.15, 1.1*stock_price_unorm[:-1,:], 1)  # OTM call deltas\n",
    "delta_call_put[:,:,2]   = BS_delta(stock_price_unorm[:-1,:], 1, r, 0.15, 1.2*stock_price_unorm[:-1,:], 1)  # DOTM call deltas\n",
    "delta_call_put[:,:,3]   = BS_delta(stock_price_unorm[:-1,:], 1, r, 0.15, stock_price_unorm[:-1,:], -1)     # ATM call deltas \n",
    "delta_call_put[:,:,4]   = BS_delta(stock_price_unorm[:-1,:], 1, r, 0.15, 0.9*stock_price_unorm[:-1,:], -1) # OTM call deltas\n",
    "delta_call_put[:,:,5]   = BS_delta(stock_price_unorm[:-1,:], 1, r, 0.15, 0.8*stock_price_unorm[:-1,:], -1) # DOTM call deltas\n",
    "\n",
    "portfolio_exposure_QDH[:,:,0]  = deltas_MSE[:,:,0]*delta_call_put[:,:,0]  # ATM call option\n",
    "portfolio_exposure_QDH[:,:,1]  = deltas_MSE[:,:,1]*delta_call_put[:,:,1]  # OTM call option\n",
    "portfolio_exposure_QDH[:,:,2]  = deltas_MSE[:,:,2]*delta_call_put[:,:,2]  # DOTM call option\n",
    "portfolio_exposure_QDH[:,:,3]  = deltas_MSE[:,:,3]*delta_call_put[:,:,3]  # ATM put option\n",
    "portfolio_exposure_QDH[:,:,4]  = deltas_MSE[:,:,4]*delta_call_put[:,:,4]  # OTM put option\n",
    "portfolio_exposure_QDH[:,:,5]  = deltas_MSE[:,:,5]*delta_call_put[:,:,5]  # DOTM put option\n",
    "\n",
    "portfolio_exposure_SQDH[:,:,0]  = deltas_SMSE[:,:,0]*delta_call_put[:,:,0]  # ATM call option\n",
    "portfolio_exposure_SQDH[:,:,1]  = deltas_SMSE[:,:,1]*delta_call_put[:,:,1]  # OTM call option\n",
    "portfolio_exposure_SQDH[:,:,2]  = deltas_SMSE[:,:,2]*delta_call_put[:,:,2]  # DOTM call option\n",
    "portfolio_exposure_SQDH[:,:,3]  = deltas_SMSE[:,:,3]*delta_call_put[:,:,3]  # ATM put option\n",
    "portfolio_exposure_SQDH[:,:,4]  = deltas_SMSE[:,:,4]*delta_call_put[:,:,4]  # OTM put option\n",
    "portfolio_exposure_SQDH[:,:,5]  = deltas_SMSE[:,:,5]*delta_call_put[:,:,5]  # DOTM put option\n",
    "\n",
    "print(\" ----------------------- \")\n",
    "print(\"Portfolio total exposure - QDH\")\n",
    "print(np.sum(portfolio_exposure_QDH)/(portfolio_exposure_QDH.shape[0]*portfolio_exposure_QDH.shape[1]))   \n",
    "    \n",
    "print(\" ----------------------- \")\n",
    "print(\"Portfolio total exposure - SQDH\")\n",
    "print(np.sum(portfolio_exposure_SQDH)/(portfolio_exposure_SQDH.shape[0]*portfolio_exposure_SQDH.shape[1]))   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
